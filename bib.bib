@article{Claypool2006a,
abstract = {The rates and resolutions for frames rendered in a computer game directly impact the player performance, influencing both the overall game playability and the game’s enjoyability. Insights into the effects of frame rates and resolutions can guide users in their choice for game settings and new hardware purchases, and inform system designers in their development of new hardware, especially for embedded devices that often must make tradeoffs between resolution and frame rate. While there have been studies detailing the effects of frame rate and resolution on streaming video and other multimedia applications, to the best of our knowledge, there have been no studies quantifying the effects of frame rate and resolution on user performance for computer games. This paper presents results of a carefully designed user study that measures the impact of frame rate and frame resolution on user performance in a first person shooter game. Contrary to previous results for streaming video, frame rate has a marked impact on both player performance and game enjoyment while resolution has little impact on performance and some impact on enjoyment.},
author = {Claypool, Mark and Claypool, Kajal and Damma, Feissal},
doi = {10.1117/12.648609},
isbn = {0819466174},
issn = {0277786X},
journal = {Multimedia Computing and Networking},
pages = {607101--1--607101--11},
pmid = {2578676},
title = {{The effects of frame rate and resolution on users playing First Person Shooter games}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=729328},
volume = {6071},
year = {2006}
}
@incollection{Giuseppe2014a,
author = {Giuseppe, Riva},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {39},
editor = {Grimshaw, M},
pages = {649--665},
publisher = {Oxford University Press},
title = {{Medical Clinical Uses of Virtual Worlds}},
year = {2014}
}
@incollection{Champion2014,
author = {Champion, Erik},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {16},
editor = {Grimshaw, M},
pages = {269--283},
publisher = {Oxford University Press},
title = {{History and Cultural Heritage in Virtual Environments}},
year = {2014}
}
@incollection{Green2014,
author = {Green, David and Chandler, Tom},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {33},
editor = {Grimshaw, M},
pages = {549--568},
publisher = {Oxford University Press},
title = {{Virtual Ecologies and Environments}},
year = {2014}
}
@incollection{Chalmers2014,
author = {Chalmers, Alan},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {36},
editor = {Grimshaw, M},
pages = {602--614},
publisher = {Oxford University Press},
title = {{Level of Realism: Feel, Smell and Taste in Virtual Environments}},
year = {2014}
}
@incollection{Lichty2014,
author = {Lichty, Patrick},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {27},
editor = {Grimshaw, M},
pages = {444--462},
publisher = {Oxford University Press},
title = {{The Translation of Art in Virtual Worlds}},
year = {2014}
}
@book{Kingslake1992,
author = {Kingslake, Rudolf},
isbn = {0819407631},
publisher = {SPIE Publications},
title = {{Optics in Photography}},
year = {1992}
}
@article{Chynoweth2014,
author = {Chynoweth, Paul},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chynoweth - 2014 - Professional doctorate research methodologies new possibilities from beyond the social sciences.pdf:pdf},
journal = {Proceedings of the 4th International Conference on Professional Doctorates (ICPD-2014)},
pages = {1--5},
title = {{Professional doctorate research methodologies : new possibilities from beyond the social sciences}},
year = {2014}
}
@article{Archer1995,
author = {Archer, Bruce},
journal = {Co-Design: the Interdisciplinary Journal of Design and Contextual Studies},
pages = {6--13},
title = {{The Nataure of Research}},
year = {1995}
}
@inproceedings{Steptoe2014,
author = {Steptoe, William and Julier, Simon and Steed, Anthony},
booktitle = {2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
file = {:home/cj/steptoe.pdf:pdf},
isbn = {9781479961849},
pages = {213--218},
title = {{Presence and Discernability in Conventional and Non-Photorealistic Immersive Augmented Reality}},
year = {2014}
}
@incollection{Billinghurst2014,
author = {Billinghurst, M and Bai, H and Lee, G and Lindeman, R},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {37},
editor = {Grimshaw, M},
pages = {615--635},
title = {{Developing Handheld Augmented Reality Interfaces}},
year = {2014}
}
@incollection{Adams2014,
author = {Adams, Paul C},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {14},
editor = {Grimshaw, M},
pages = {239--253},
publisher = {Oxford University Press},
title = {{Communication in Virtual Worlds}},
year = {2014}
}
@incollection{Giuseppe2014,
author = {Giuseppe, Riva and Waterworth, J A},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {12},
editor = {Grimshaw, M},
pages = {205--221},
publisher = {Oxford University Press},
title = {{Being Present in a Virtual World}},
year = {2014}
}
@incollection{Calleja2014,
author = {Calleja, G},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {13},
editor = {Grimshaw, M},
pages = {222--236},
publisher = {Oxford University Press},
title = {{Immersion in Virtual Worlds}},
year = {2014}
}
@incollection{Heim2014,
author = {Heim, Michael R},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {6},
editor = {Grimshaw, M},
pages = {111--125},
publisher = {Oxford University Press},
title = {{The Paradox of Virtuality}},
year = {2014}
}
@article{Damasio1999,
abstract = {How is it that we know what we know? How is it that our conscious and private minds have a sense of self? A gifted medical clinician and scientific thinker, Damasio helps readers to ask and answer questions about what it is to be human. His elegant investigation of feeling and emotion offers a new understanding of the conscious mind and, as the New York Times has noted, will change your experience of yourself.},
author = {a.R. Damasio},
issn = {10752730},
journal = {Nature},
number = {6756},
pages = {386},
pmid = {3279},
title = {{The feeling of what happens}},
volume = {401},
year = {1999}
}
@article{Mantovani2010,
author = {Mantovani, F},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mantovani - 2010 - On feeling (the) present An evolutionary account of the sense of presence in physical and electronically-mediated env.pdf:pdf},
issn = {13558250},
journal = {Journal of Consciousness Studies},
number = {1},
pages = {167--178},
title = {{On feeling (the) present: An evolutionary account of the sense of presence in physical and electronically-mediated environments}},
url = {http://boa.cilea.it/handle/10281/22522$\backslash$npapers2://publication/uuid/C07F1CC2-C4B4-4010-9E61-F7AD0772E5F2},
volume = {17},
year = {2010}
}
@article{Davies2014,
author = {Davies, C J and Miller, Alan and Allison, Colin},
file = {:home/cj/Downloads/vrst.pdf:pdf},
isbn = {9781450332538},
journal = {Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology},
keywords = {cross reality,head mounted display,indoor positioning},
title = {{A View from the Hill : Where Cross Reality Meets Virtual Worlds}},
year = {2014}
}
@article{Allison2013,
author = {Allison, Colin and Davies, Christopher John and Miller, Alan},
file = {:home/cj/Downloads/IEDMiller.pdf:pdf},
journal = {Proceedings of the Immersive Education Summit Boston 2013},
pages = {12},
title = {{PolySocial Reality for Education: Addressing the Vacancy Problem with Mobile Cross Reality}},
year = {2013}
}
@inproceedings{Davies2013,
abstract = {Widespread adoption of smartphones and tablets has enabled people to multiplex their physical reality, where they engage in face-to-face social interaction, with Web-based social networks and apps, whilst emerging 3D Web technologies hold promise for networks of parallel 3D virtual environments to emerge. Although current technologies allow this multiplexing of physical reality and 2D Web, in a situation called PolySocial Reality, the same cannot yet be achieved with 3D content. Cross Reality was proposed to address this issue; however so far it has focused on the use of fixed links between physical and virtual environments in closed lab settings, limiting investigation of the explorative and social aspects. This paper presents an architecture and implementation that addresses these shortcomings using a tablet computer and the Pangolin virtual world viewer to provide a mobile interface to a corresponding 3D virtual environment. Motivation for this project stemmed from a desire to enable students to interact with existing virtual reconstructions of cultural heritage sites in tandem with exploration of the corresponding real locations, avoiding the adverse temporal separation caused otherwise by interacting with the virtual content only within the classroom. The accuracy of GPS tracking emerged as a constraint on this style of interaction.},
author = {Davies, Chris and Miller, Alan and Allison, Colin},
booktitle = {Proceedings of the DigitalHeritage 2013 - Federating the 19th Int'l VSMM, 10th Eurographics GCH, and 2nd UNESCO Memory of the World Conferences, Plus Special Sessions fromCAA, Arqueologica 2.0 et al.},
pages = {331--338},
title = {{Mobile Cross Reality for cultural heritage}},
volume = {1},
year = {2013}
}
@inproceedings{Davies2012,
abstract = {Virtual worlds have proven popular in academia as extensible multi-user 3D virtual environments capable of hosting a wide range of experimental scenarios. One of the products of virtual worlds research is the cross reality paradigm; the fusion of ubiquitous sensor/actuator infrastructure and virtual worlds facilitating synchronous bidirectional intercommunication between real and virtual environments, allowing each to reflect, influence and merge with the other. We introduce the ongoing Virtual Time Window project, an application of cross reality to the domain of cultural heritage, that promises to further existing alternate reality work in the field by allowing simultaneous exploration of real and virtual environments; visitors to a cultural heritage site can simultane- ously explore its virtual reconstruction via a tablet computer. Unlike previous augmented reality and virtual reality projects in the field, the virtual reconstruction is also accessible to persons remote to the real site, affording intriguing interactions between visitors at the site and those exploring it from elsewhere.},
author = {Davies, C J and Miller, Alan and Allison, Colin},
booktitle = {Proceedings of the Postgraduate Conference on the Convergence of Networking and Telecomunications},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davies, Miller, Allison - 2012 - Virtual Time Windows Applying Cross Reality to Cultural Heritage(2).pdf:pdf},
title = {{Virtual Time Windows : Applying Cross Reality to Cultural Heritage}},
year = {2012}
}
@incollection{Liestøl2014,
author = {Liest{\o}l, Gunnar and Morrison, A},
booktitle = {Mobility and Locative Media: Mobile Communication in Hybrid Space (Changing Mobilities)},
chapter = {12},
editor = {{de Souza e Silva}, A and Sheller, M},
pages = {207--222},
publisher = {Routledge},
title = {{The power of place and perspective: sensory media and situated simulations in urban design}},
year = {2014}
}
@incollection{Liestøl2012,
author = {Liest{\o}l, Gunnar},
booktitle = {Progress in Cultural Heritage Preservation},
doi = {10.1007/978-3-642-34234-9{\_}64},
editor = {Ioannides, M and Fritsch, D and Leissner, J and Davies, R and Remondino, F and Caffo, R},
isbn = {978-3-642-34233-2},
pages = {618--627},
publisher = {Springer Berlin Heidelberg},
title = {{Solving the Centre–Periphery Problem in Cultural Heritage by Means of Situated Simulations}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-34234-9{\_}64},
year = {2012}
}
@article{Wither2011,
abstract = {Developing augmented reality (AR) applications for mobile devices and outdoor environments has historically required a number of technical trade-offs related to tracking. One approach is to rely on computer vision which provides very accurate tracking, but can be brittle, and limits the generality of the application. Another approach is to rely on sensor-based tracking which enables widespread use, but at the cost of generally poor tracking performance. In this paper we present and evaluate a new approach, which we call Indirect AR, that enables perfect alignment of virtual content in a much greater number of application scenarios. To achieve this improved performance we replace the live camera view used in video see through AR with a previously captured panoramic image. By doing this we improve the perceived quality of the tracking while still maintaining a similar overall experience. There are some limitations of this technique, however, related to the use of panoramas. We evaluate these boundaries conditions on both a performance and experiential basis through two user studies. The result of these studies indicates that users preferred Indirect AR over traditional AR in most conditions, and when conditions do degrade to the point the experience changes, Indirect AR can still be a very useful tool in many outdoor application scenarios. © 2011 Elsevier Ltd. All rights reserved.},
author = {Wither, Jason and Tsai, Yun Ta and Azuma, Ronald},
doi = {10.1016/j.cag.2011.04.010},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wither, Tsai, Azuma - 2011 - Indirect augmented reality.pdf:pdf},
isbn = {0097-8493},
issn = {00978493},
journal = {Computers and Graphics (Pergamon)},
keywords = {Evaluation,Information Presentation,Mixed Reality,User Interface},
number = {4},
pages = {810--822},
publisher = {Elsevier},
title = {{Indirect augmented reality}},
url = {http://dx.doi.org/10.1016/j.cag.2011.04.010},
volume = {35},
year = {2011}
}
@inproceedings{Liestøl2009,
abstract = {In digital media - including augmented reality research - rapid change continue to take place at the levels of hardware and software. This paper focus on a third layer in a hierarchy of digital media - meaningware. Meaningware is the domain of digital textuality, its genres and conventions - all key subject matters of the humanities. To prevent cultural lag at the textual level the conduct of genre design is suggested as a methodological approach. The potential 'genre' experimented with here is a type of augmented reality system we have named Situated Simulations. The system takes advantage of the convergence of mobility, broadband, rich graphics capabilities and positioning/orientation technologies, on off the shelf mobile phones. The current platform applied is Apple's iPhone. The paper describes the development of three prototyped situated simulations designed for use in both learning and tourism. Interface and design issues are discussed, and a perspective on the epistemological increment of augmented reality and situated simulations is related to Bateson's notion of double descriptions.},
author = {Liest{\o}l, Gunnar},
booktitle = {Arts, Media and Humanities Proceedings - IEEE 2009 International Symposium on Mixed and Augmented Reality, ISMAR-AMH 2009},
doi = {10.1109/ISMAR-AMH.2009.5336730},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liest{\o}l - 2009 - Augmented reality and digital genre design - Situated simulations on the iPhone.pdf:pdf},
isbn = {9781424455089},
keywords = {Augmented reality,Digital genre design,Meaningware,Situated simulation,iPhone},
pages = {29--34},
title = {{Augmented reality and digital genre design - Situated simulations on the iPhone}},
year = {2009}
}
@incollection{Liestøl2011,
author = {Liest{\o}l, Gunnar},
booktitle = {Handbook of Augmented Reality},
doi = {10.1007/978-1-4614-0064-6{\_}14},
editor = {Furht, Borko},
isbn = {978-1-4614-0063-9},
pages = {309--319},
publisher = {Springer New York},
title = {{Situated Simulations Between Virtual Reality and Mobile Augmented Reality: Designing a Narrative Space}},
url = {http://link.springer.com/chapter/10.1007{\%}2F978-1-4614-0064-6{\_}14},
year = {2011}
}
@inproceedings{Liestøl2010,
author = {Liest{\o}l, Gunnar and Rasmussen, Terje},
booktitle = {Media Inspirations for Learning. Proceedings of EDEN 2010},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liest{\o}l, Rasmussen - 2010 - In the Presence of the Past. A field trial evaluation of a situated simulation design reconstructing a viki.pdf:pdf},
isbn = {9789630694308},
number = {October 2009},
title = {{In the Presence of the Past. A field trial evaluation of a situated simulation design reconstructing a viking burial scene}},
url = {http://www.academia.edu/4403434/In{\_}the{\_}Presence{\_}of{\_}the{\_}Past.{\_}A{\_}field{\_}trial{\_}evalutation{\_}of{\_}a{\_}situated{\_}simulation{\_}design{\_}reconstructing{\_}a{\_}viking{\_}burial{\_}scene},
year = {2010}
}
@phdthesis{Soraker2010,
author = {Soraker, J.H.},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soraker - 2010 - The value of virtual worlds A Philosophical Analysis of Virtual Worlds and their Potential Impact on Well-Being.pdf:pdf},
isbn = {9789036530101},
title = {{The value of virtual worlds: A Philosophical Analysis of Virtual Worlds and their Potential Impact on Well-Being}},
year = {2010}
}
@incollection{Brey2014,
author = {Brey, Philip},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {2},
editor = {Grimshaw, Mark},
pages = {42--54},
publisher = {Oxford University Press},
title = {{The Physical and Social Reality of Virtual Worlds}},
year = {2014}
}
@inproceedings{Simeone2015,
author = {Simeone, Adalberto L and Velloso, Eduardo and Gellersen, Hans},
booktitle = {Proceedings of SIGCHI Conference on Human Factors in Computing Systems (CHI 2015)},
isbn = {9781450331456},
keywords = {Passive Haptics,Substitutional Reality,Virtual Reality},
title = {{Substitutional Reality : Using the Physical Environment to Design Virtual Reality Experiences}},
year = {2015}
}
@incollection{Orlan2002,
author = {Orlan},
booktitle = {The Cyborg Experiments: the extensions of the body in the media age},
chapter = {10},
editor = {Zylinska, Joanna},
pages = {168--171},
publisher = {Continuum},
title = {{The Virtual and/or the Real}},
year = {2002}
}
@book{Vinge2006,
author = {Vinge, Vernor},
isbn = {0-312-85684-9},
pages = {368},
publisher = {Tor Books},
title = {{Rainbows End}},
year = {2006}
}
@incollection{Damer2014,
author = {Damer, Bruce and Hinrichs, Randy},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {1},
editor = {Grimshaw, Mark},
pages = {17--41},
publisher = {Oxford University Press},
title = {{The Virtuality and Reality of Avatar Cyberspace}},
year = {2014}
}
@incollection{Sterling1988,
author = {Sterling, Bruce},
booktitle = {Mirrorshades: The Cyberpunk Anthology},
chapter = {preface},
editor = {Sterling, Bruce},
pages = {vii--xiv},
publisher = {Paladin Grafton Books},
title = {{Preface}},
year = {1988}
}
@article{Heim1998,
abstract = {"Virtual Realism" is an art form and a way of living with technology. To explain the concept, the author begins with the conflict inherent in the philosophy of technology (Unabomber and the computer culture). The article draws on interactive art, software engineering, and popular culture to clarify the issue of lifestyles. Twelve suggestions are made to develop a harmony of technology and lifestyle. The article is a chapter in a book by the same title (Oxford U. Press, 1998)>},
author = {Heim, Michael},
journal = {Bridges},
keywords = {Cyberspace,Ellul, J,Ethics,Realism,Technology,Toffler, H,Toffler, a,Virtual Reality},
pages = {5(3--4) 175--195},
pmid = {1164349},
title = {{Virtual Realism}},
year = {1998}
}
@article{Azuma1997,
abstract = {This paper surveys the field of Augmented Reality, in which 3-D virtual $\backslash$nobjects are integrated into a 3-D real environment in real time. It describes the $\backslash$nmedical, manufacturing, visualization, path planning, entertainment and military $\backslash$napplications that have been explored. This paper describes the characteristics of $\backslash$nAugmented Reality systems, including a detailed discussion of the tradeoffs between $\backslash$noptical and video blending approaches. Registration and sensing errors are two of the $\backslash$nbiggest problems in building effective Augmented Reality systems, so this paper $\backslash$nsummarizes current efforts to overcome these problems. Future directions and areas $\backslash$nrequiring further research are discussed. This survey provides a starting point for $\backslash$nanyone interested in researching or using Augmented Reality.},
author = {Azuma, Ronald},
issn = {10547460},
journal = {Presence: Teleoperators and Virtual Environments},
number = {4},
pages = {355--385},
pmid = {9708264137},
title = {{A survey of augmented reality}},
url = {http://scholar.google.com/scholar?q=intitle:A+Survey+of+Augmented+Reality{\#}0},
volume = {6},
year = {1997}
}
@incollection{Waterworth2014,
author = {Waterworth, J A and Waterworth, E L},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {35},
editor = {Grimshaw, M},
pages = {589--601},
publisher = {Oxford University Press},
title = {{Distributed Embodiment: Real Presence in Virtual Bodies}},
year = {2014}
}
@incollection{Steed2014,
author = {Steed, A},
booktitle = {The Oxford Handbook of Virtuality},
chapter = {26},
editor = {Grimshaw, M},
pages = {420--443},
publisher = {Oxford University Press},
title = {{Recreating Visual Reality in Virtuality}},
year = {2014}
}
@article{Lucas1951,
author = {Lucas, Darrell Blaine and Britt, Steuart Henderson},
journal = {Journal of Marketing},
number = {1},
pages = {118--120},
title = {{Advertising Psychology and Research}},
volume = {16},
year = {1951}
}
@book{Jones2006,
author = {Jones, Caroline A},
doi = {10.1093/llc/fqn008},
isbn = {0262101173},
issn = {0268-1145},
pages = {268},
pmid = {14318938},
publisher = {The MIT Press},
title = {{Sensorium: Embodied Experience, Technology, and Contemporary Art}},
year = {2006}
}
@article{Slater1998,
abstract = {We describe an experiment to assess the influence of body movements on presence in a virtual environment. In the experiment 20 participants were to walk through a virtual field of trees and count the trees with diseased leaves. A 2 x 2 between subjects design was used to assess the influence of two factors on presence: tree height variation and task complexity. The field with greater variation in tree height required participants to bend down and look up more than in the lower variation tree height field. In the higher complexity task participants were told to remember the distribution of diseased trees in the field as well as to count them. The results showed a significant positive association between reported presence and the amount of body movement in particular, head yaw--and the extent to which participants bent down and stood up. There was also a strong interaction effect between task complexity and gender: Women in the more-complex task reported a much lower sense of presence than in the simpler task. For applications in which presence is an important requirement, the research in this paper suggests that presence will be increased when interaction techniques are employed that permit the user to engage in whole-body movement.},
author = {Slater, M and Steed, A and McCarthy, J and Maringelli, F},
doi = {10.1518/001872098779591368},
institution = {Department of Computer Science, University College London, England, UK.},
isbn = {0018-7208},
issn = {0018-7208; 0018-7208},
journal = {Human factors},
number = {3},
pages = {469--477},
pmid = {9849105},
title = {{The influence of body movement on subjective presence in virtual environments.}},
volume = {40},
year = {1998}
}
@article{Boles2003,
abstract = {Animals are capable of true navigation if, after displacement to a location where they have never been, they can determine their position relative to a goal without relying on familiar surroundings, cues that emanate from the destination, or information collected during the outward journey. So far, only a few animals, all vertebrates, have been shown to possess true navigation. Those few invertebrates that have been carefully studied return to target areas using path integration, landmark recognition, compass orientation and other mechanisms that cannot compensate for displacements into unfamiliar territory. Here we report, however, that the spiny lobster Panulirus argus oriented reliably towards a capture site when displaced 12-37 km to unfamiliar locations, even when deprived of all known orientation cues en route. Little is known about how lobsters and other animals determine position during true navigation. To test the hypothesis that lobsters derive positional information from the Earth's magnetic field, lobsters were exposed to fields replicating those that exist at specific locations in their environment. Lobsters tested in a field north of the capture site oriented themselves southwards, whereas those tested in a field south of the capture site oriented themselves northwards. These results imply that true navigation in spiny lobsters, and perhaps in other animals, is based on a magnetic map sense.},
author = {Boles, Larry C and Lohmann, Kenneth J},
institution = {Department of Biology, University of North Carolina, Chapel Hill, North Carolina 27599, USA. LBoles@email.unc.edu},
issn = {0028-0836},
journal = {Nature},
number = {6918},
pages = {60--63},
pmid = {12511953},
title = {{True navigation and magnetic maps in spiny lobsters.}},
volume = {421},
year = {2003}
}
@book{Fawcett2011,
author = {Fawcett, R.},
isbn = {978-0300170498},
publisher = {Yale University Press},
title = {{The Architecture of the Scottish Medieval Church}},
year = {2011}
}
@book{VanBrummelen2012,
author = {{Van Brummelen}, Glen},
isbn = {9780691148922},
pages = {208},
title = {{Heavenly Mathematics: The Forgotten Art of Spherical Trigonometry}},
year = {2012}
}
@inproceedings{Getchell2007,
author = {Getchell, K and Nicoll, J and Kerbey, C and Miller, A and Sweetman, R and Michaelson, R},
booktitle = {WBED'07 Proceedings of the sixth conference on IASTED International Conference Web-Based Education},
pages = {561--567},
title = {{Evaluating exploratory learning in LAVA}},
url = {http://portal.acm.org/citation.cfm?id=1323159.1323258},
year = {2007}
}
@inproceedings{Kennedy2013,
abstract = {St Andrews Cathedral is located on the East Coast of Scotland. Construction started in 1160 and spanned Romanesque and Gothic architectural styles. It was consecrated in 1318, four years after the battle of Bannockburn in the presence of King Robert I. For several hundred years, the Cathedral was one of the most important religious buildings in Europe and the centre of religious life in Scotland. During the Reformation, John Knox himself lead reformers in divesting the Cathedral of all its finery. Thereafter it fell into disuse and decline. Today the remains hint at its former glory. Here the use of Open Virtual Worlds (OVW) to support new modes of engagement with cultural heritage is presented through the example of St Andrews Cathedral. Open Virtual Worlds offer an extensible collaborative environment for developing historical scenes against which background material and intangible aspects of cultural heritage associated with a site may be explored. They offer the potential to reconstruct within a 3D computer environment both the physical structures of the past and important aspects of the lighting, sounds and lifestyles that once existed within those structures. Bringing together architecture, sculpture, illumination, stained-glass, music, procession and lighting into a scene, which can be explored from multiple spatial perspectives enables holistic appreciations to be developed.},
author = {Kennedy, S. and Fawcett, R. and Miller, A. and Dow, L. and Sweetman, R. and Field, A. and Campbell, A. and Oliver, I. and McCaffery, J. and Allison, C.},
booktitle = {Proceedings of the DigitalHeritage 2013 - Federating the 19th Int'l VSMM, 10th Eurographics GCH, and 2nd UNESCO Memory of the World Conferences, Plus Special Sessions fromCAA, Arqueologica 2.0 et al.},
pages = {273--280},
title = {{Exploring canons {\&} cathedrals with open virtual worlds: The recreation of St Andrews Cathedral, St Andrews day, 1318}},
volume = {2},
year = {2013}
}
@inproceedings{Scherrer2008,
abstract = {This paper describes an artwork that relies on recent computer vision and augmented reality techniques to animate the illustrations of a poetry book. Because we donpsilat need markers, we can achieve seamless integration of real and virtual elements to create the desired atmosphere. The visualization is done on a computer screen to avoid cumbersome head-mounted displays. The camera is hidden into a desk lamp for easing even more the spectator immersion.},
author = {Scherrer, Camille and Pilet, Julien and Fua, Pascal and Lepetit, Vincent},
booktitle = {Proceedings - 7th IEEE International Symposium on Mixed and Augmented Reality 2008, ISMAR 2008},
pages = {163--164},
title = {{The haunted book}},
year = {2008}
}
@article{Rolland1994,
abstract = {One of the most promising and challenging future uses of head-mounted displays (HMDs) is in applications where virtual environments enhance rather than replace real environments. To obtain an enhanced view of the real environment, the user wears a see-through HMD to see 3D computergenerated objects superimposed on his/her real-world view. This see-through capability can be accomplished using either an optical or a video see-through HMD. We discuss the tradeoffs between optical and video see-through HMDs with respect to technological, perceptual, and human factors issues, and discuss our experience designing, building, using, and testing these HMDs.},
author = {Rolland, Jannick P. and Holloway, Richard and Fuchs, Henry},
issn = {0277786X},
journal = {International Society for Optics and Photonics},
keywords = {augmented reality,optics,see-through head-mounted displays,superimposition,video cameras},
pages = {293--307},
title = {{Comparison of optical and video see-through, head-mounted displays}},
url = {http://www.creol.ucf.edu/Research/Publications/1505.PDF},
volume = {2351},
year = {1994}
}
@book{Cline2012,
author = {Cline, Ernest},
isbn = {0099560437},
pages = {384},
publisher = {Arrow},
title = {{Ready Player One}},
year = {2012}
}
@book{Turkle1997,
author = {Turkle, Sherry},
edition = {1st Touchs},
isbn = {0684833484},
pages = {354},
publisher = {Simon {\&} Schuster},
title = {{Life on the Screen}},
year = {1997}
}
@book{Baudrillard1994,
abstract = {The first full-length translation in English of an essential work of postmodernist thought},
author = {Baudrillard, Jean},
booktitle = {Idea},
editor = {Glaser, Sheila F},
number = {4},
pages = {164},
pmid = {4434685},
publisher = {University of Michigan Press},
series = {The Body, in theory},
title = {{Simulacra and Simulation}},
url = {http://www.amazon.com/dp/0472065211},
volume = {29},
year = {1994}
}
@book{Turkle2011,
author = {Turkle, Sherry},
pages = {384},
publisher = {Basic Books},
title = {{Alone Together: Why We Expect More From Technology And Less From Each Other}},
year = {2011}
}
@misc{Schofield2012,
author = {Schofield, Jack},
booktitle = {The Guardian Technology Blog},
title = {{Google Project Glass: will we really wear digital goggles?}},
url = {http://www.theguardian.com/technology/2012/apr/05/google-project-glass-digital-goggles},
urldate = {2014-12-22},
year = {2012}
}
@book{Terashima2001,
editor = {Terashima, Nobuyoshi and Tiffin, John},
isbn = {041526104X},
publisher = {Routledge},
title = {{HyperReality: Paradigm for the Third Millenium}},
year = {2001}
}
@article{Hill2004,
abstract = { Realtime image processing provides a general framework for robust mediated reality problems. This paper presents a realtime mediated reality system that is built upon realtime image processing algorithms. It has been shown that the graphics processing unit (GPU) is capable of efficiently performing image processing tasks. The system presented uses a parallel GPU architecture for image processing that enables realtime mediated reality. Our implementation has many benefits; the graphics hardware has high throughput and low latency; the GPU's are not prone to jitter. Additionally, the CPU is kept available for user applications. The system is easily constructed, consisting of readily available commodity hardware.},
author = {Hill, R. and Fung, J. and Mann, S.},
issn = {1522-4880},
journal = {2004 International Conference on Image Processing, 2004. ICIP '04.},
title = {{A parallel mediated reality platform}},
volume = {5},
year = {2004}
}
@incollection{Schubert1999,
abstract = {Schubert, T.W., Friedman, F., {\&} Regenbrecht, H.T. (1999). Embodied presence in virtual environments. In: Paton R, Neilson I (Eds.). Visual representations and interpretations. Springer-Verlag, London, pp. 268–278.},
author = {Schubert, Thomas and Friedmann, Frank and Regenbrecht, Holger},
booktitle = {Visual representations and interpretations},
doi = {10.1007/978-1-4471-0563-3{\_}30},
editor = {{Paton R}, Neilson I},
isbn = {9781441909183},
pages = {268--278},
publisher = {Springer-Verlag},
title = {{Embodied presence in virtual environments}},
url = {http://link.springer.com/chapter/10.1007/978-1-4471-0563-3{\_}30},
year = {1999}
}
@misc{Regenbrecht2002a,
abstract = {It has long been argued that the possibility to interact in and with a virtual environment (VE) enhances the sense of pres- ence. On the basis of a three-component model of presence, we specify this hypothesis and argue that the mental represen- tation of possible actions should especially enhance spatial presence, and to a lesser extent the involvement and realness of a VE. We support this hypothesis in three studies. A corre- lative study showed that self-reported interaction possibilities correlated significantly with spatial presence, but not with the other two factors. A first experimental study showed that pos- sible self-movement significantly increased spatial presence and realness. A second experimental study showed that even the illusion of interaction, with no actual interaction taking place, significantly increased spatial presence.},
author = {Regenbrecht, Holger and Schubert, Thomas},
booktitle = {Presence: Teleoperators and Virtual Environments},
issn = {1054-7460},
number = {4},
pages = {425--434},
title = {{Real and Illusory Interactions Enhance Presence in Virtual Environments}},
volume = {11},
year = {2002}
}
@article{Brooke1996,
abstract = {Previous studies showed that neurons in the monkey premotor cortex became active when performing a particular action and also when observing the same action performed by others. These findings suggest a mirror system for action observation. Recently, bimodal neurons, sensitive both to visual and tactile stimulation, were reported in the parietal cortex, suggesting a potential mirror neuron system for observing and experiencing tactile stimulation. Subsequently, a mirror neuron system for observed touch has been suggested. The current study was designed to determine whether the activation of a sensory mirror system during touch observation is affected by possible attributions of the observed touch to oneself (subjective view) or to somebody else (objective view). In the study, healthy volunteers observed video clips of a touched or nontouched hand either in an egocentric or in an allocentric perspective during functional magnetic resonance imaging. Results showed activation of somatosensory cortices when observing the hand being touched in egocentric as well as in the allocentric perspectives. Moreover, somatosensory responses differed depending on the perspective of the observed touch. We discuss the results in terms of a possible mirror neuron system for observed and experienced touch.},
author = {Brooke, John},
doi = {10.1002/hbm.20701},
isbn = {0748404600},
issn = {1097-0193},
journal = {Usability evaluation in industry},
keywords = {Adult,Brain Mapping,Brain Mapping: methods,Computer-Assisted,Computer-Assisted: methods,Ego,Evoked Potentials,Female,Functional Laterality,Functional Laterality: physiology,Humans,Image Processing,Imagination,Imagination: physiology,Imaging,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Motion Perception,Motion Perception: physiology,Neural Pathways,Neural Pathways: anatomy {\&} histology,Neural Pathways: physiology,Neurons,Neurons: physiology,Observation,Observation: methods,Orientation,Orientation: physiology,Parietal Lobe,Parietal Lobe: anatomy {\&} histology,Parietal Lobe: physiology,Pattern Recognition,Physical Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Psychophysics,Psychophysics: methods,Somatosensory,Somatosensory Cortex,Somatosensory Cortex: physiology,Somatosensory: physiology,Space Perception,Space Perception: physiology,Three-Dimensional,Three-Dimensional: methods,Touch,Touch Perception,Touch Perception: physiology,Touch: physiology,Visual,Visual Perception,Visual Perception: physiology,Visual: physiology},
pages = {194},
pmid = {19172650},
title = {{SUS-A quick and dirty usability scale}},
url = {B5{\_}During{\_}the{\_}trial{\_}usability{\_}scale{\_}V1{\_}09Aug11.pdf$\backslash$nhttp://www.ncbi.nlm.nih.gov/pubmed/19172650},
volume = {189},
year = {1996}
}
@incollection{Andersen,
author = {Andersen, Peter B{\o}gh},
booktitle = {Virtual Space: Spatiality in Virtual Inhabited 3D Worlds},
chapter = {3},
editor = {Qvortrup, L and Jensen, J and Kjems, E and Lehmann, N and Madsen, C},
file = {:array{\_}z/Downloads/TangObj.pdf:pdf},
pages = {190--210},
publisher = {Springer London},
title = {{Tangible Objects : Connecting Informational and Physical space}},
year = {2002}
}
@incollection{Qvortrup2002,
author = {Qvortrup, Lars},
booktitle = {Virtual Space: Spatiality in Virtual Inhabited 3D Worlds},
chapter = {1},
editor = {Qvortrup, Lars},
isbn = {978-1-4471-1100-9},
pages = {5--24},
publisher = {Springer-Verlag},
title = {{Cyberspace as Representation of Space Experience: In Defence of a Phenomenological Approach}},
year = {2002}
}
@incollection{Tzortzaki2002,
author = {Tzortzaki, Delia},
booktitle = {Virtual Space: Spatiality in Virtual Inhabited 3D Worlds},
editor = {Qvortrup, Lars},
isbn = {978-1-4471-0225-0},
pages = {258--284},
publisher = {Springer-Verlag},
title = {{Virtual Reality as Simulation: The CAVE as ``Space of Illusion'' in Museum Displays}},
year = {2002}
}
@incollection{Turkle2004,
author = {Turkle, Sherry},
booktitle = {Community in the Digital Age: Philosophy and Practice},
chapter = {6},
editor = {Feenberg, Andrew and Barney, Darin},
pages = {101--117},
publisher = {Rowman {\&} Littlefield},
title = {{Our Split Screens}},
year = {2004}
}
@article{Schubert2001,
abstract = {Within an embodied cognition framework, it is argued that presence in a virtual environment (VE) develops from the construction of a spatial-functional mental model of the VE. Two cognitive processes lead to this model: the representation of bodily actions as possible actions in the VE, and the suppression of incompatible sensory input. It is hypothesized that the conscious sense of presence reflects these two components as spatial presence and involvement. This prediction was con- firmed in two studies (N ? 246 and N ? 296) assessing self-reports of presence and immersion experiences. Additionally, judgments of “realness” were observed as a third presence component. A second-order factor analysis showed a distinction between presence, immersion, and interaction factors. Building on these results, a thirteen-item presence scale consisting of three independent components was de- veloped and verified using confirmatory factor analyses across the two studies. Presence is a construct, a variable with various levels and dimensions. Biocca and Delaney (1995, p. 62)},
author = {Schubert, Thomas and Friedmann, Frank and Regenbrecht, Holger},
doi = {10.1162/105474601300343603},
isbn = {1054-7460},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
number = {3},
pages = {266--281},
pmid = {18368863},
title = {{The Experience of Presence: Factor Analytic Insights}},
volume = {10},
year = {2001}
}
@article{Laureys2009,
author = {Laureys, S and Boly, M and Moonen, G and Maquet, P},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laureys et al. - 2009 - Two Dimensions of Consciousness Arousal and Awareness.pdf:pdf},
pages = {1133--1142},
title = {{Two Dimensions of Consciousness: Arousal and Awareness}},
volume = {2},
year = {2009}
}
@article{Ijsselsteijn1998,
abstract = {The present study investigates the subjective feeling of presence elicited by 3DTV and its relationship to perceived depth and image content. Subjective methods of assessing presence that have been used or proposed to date do not provide a measure of temporal variation. To overcome this limitation, we have applied the continuous assessment methodology (ITU-R, BT 500-7) to the assessment of presence, perceived depth and naturalness of depth. Twelve observers continuously rated their instantaneous perception of presence, depth and naturalness of depth when viewing stereoscopic footage. The results indicate that subjective presence ratings are subject to considerable temporal variation depending on the image content and camera techniques used. The correlations between the different attributes suggest that an increase in depth may lead to an enhanced sense of presence, provided depth is perceived as natural. A qualitative analysis of the data in relation to the image content provides evidence for the hypothesis that the extent of sensory information available to an observer is a determinant of presence, as proposed by T.B. Sheridan, Musings on telepresence and virtual presence, Presence: Teleoperators and Virtual Environments 1 (1992) 120-125. © 1998 Elsevier Science B.V.},
author = {Ijsselsteijn, Wijnand and de Ridder, Huib and Hamberg, Roelof and Bouwhuis, Don and Freeman, Jonathan},
doi = {10.1016/S0141-9382(98)00022-5},
issn = {01419382},
journal = {Displays},
number = {4},
pages = {207--214},
title = {{Perceived depth and the feeling of presence in 3DTV}},
volume = {18},
year = {1998}
}
@article{Slater2000,
author = {Slater, Mel and Steed, Anthony},
doi = {10.1162/105474600566925},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Slater, Steed - 2000 - A Virtual Presence Counter.pdf:pdf},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
keywords = {gestalt psychology,interaction,presence,tele-presence,virtual environments},
month = {oct},
number = {5},
pages = {413--434},
title = {{A Virtual Presence Counter}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/105474600566925},
volume = {9},
year = {2000}
}
@article{Waterworth2001,
abstract = {A model of virtual/physical experience is presented, which provides a three dimensional conceptual space for virtual and augmented reality (VR and AR) comprising the dimensions of focus, locus, and sensus. Focus is most closely related to what is generally termed presence in the VR literature. When in a virtual environment, presence is typically shared between the VR and the physical world. "Breaks in presence" are actually shifts of presence away from the VR and toward the external environment. But we can also have "breaks in presence" when attention moves toward absence--when an observer is not attending to stimuli present in the virtual environment, nor to stimuli present in the surrounding physical environment--when the observer is present in neither the virtual nor the physical world. We thus have two dimensions of presence: focus of attention (between presence and absence) and the locus of attention (the virtual vs. the physical world). A third dimension is the sensus of attention--the level of arousal determining whether the observer is highly conscious or relatively unconscious while interacting with the environment. After expanding on each of these three dimensions of experience in relation to VR, we present a couple of educational examples as illustrations, and also relate our model to a suggested spectrum of evaluation methods for virtual environments.},
author = {Waterworth, E L and Waterworth, J A},
institution = {Interactive Institute Tools for Creativity Studio, Ume{\aa}, Sweden. eva.lindh.waterworth@interactiveinstitute.se},
journal = {Cyberpsychology {\&} behavior : the impact of the Internet, multimedia and virtual reality on behavior and society},
number = {2},
pages = {203--213},
pmid = {11710247},
title = {{Focus, locus, and sensus: the three dimensions of virtual experience.}},
volume = {4},
year = {2001}
}
@article{Heeter2003,
abstract = {I have lived in San Francisco while working as a full-time virtual faculty member for Michigan State University for nearly six years. Unlike most humans, I spend a larger proportion of every day as a virtual person than as a physical person. This article is adapted from a keynote speech I delivered at the Fourth International Workshop on Presence in Philadelphia in May of 2001. I use a personal narrative style to explore issues and to question some of the research community's prevailing assumptions about presence. Lombard and Ditton's (1997) frequently cited conceptualization defines presence as a “perceptual illusion of nonmediation” that occurs “when a person fails to perceive or acknowledge the existence of a medium in his/her communication environment and responds as he/she would if the medium were not there.” The underlying assumption is that, in the absence of technology, everyone experiences continuous presence at a constant intensity throughout their lives. Instead, this article suggests that presence is not a constant of everyday nonmediated experience. Careful consideration of unmediated (real) presence might help the conceptualization and study of mediated presence.},
author = {Heeter, Carrie},
journal = {Presence: Teleoperators and Virtual Environments},
number = {4},
pages = {335--345},
title = {{Reflections on Real Presence by a Virtual Person}},
volume = {12},
year = {2003}
}
@article{Regenbrecht1992,
author = {Regenbrecht, Holger and Schubert, Thomas},
keywords = {augmented reality,sense of presence},
title = {{Measuring Presence in Augmented Reality Environments : Design and a First Test of a Questionnaire}},
year = {1992}
}
@article{Slater,
author = {Slater, M and Sadagic, A and Usoh, M and Schroeder, R},
title = {{Small Group Behaviour in a Virtual and Real Environment : A Comparative Study}}
}
@article{Slater2002,
author = {Slater, Mel},
doi = {10.1162/105474602760204327},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
month = {aug},
number = {4},
pages = {435--439},
title = {{Presence and The Sixth Sense}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/105474602760204327},
volume = {11},
year = {2002}
}
@article{Keogh1998,
author = {Keogh, Edmund},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keogh - 1998 - A Cross-Media Presence Questionnaire The ITC-Sense of Presence Inventory.pdf:pdf},
number = {3},
pages = {282--297},
title = {{A Cross-Media Presence Questionnaire : The ITC-Sense of Presence Inventory}},
volume = {10},
year = {1998}
}
@article{Usoh2000,
author = {Usoh, Martin and Catena, Ernest and Arman, Sima and Slater, Mel},
doi = {10.1162/105474600566989},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Usoh et al. - 2000 - Using Presence Questionnaires in Reality.pdf:pdf},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
month = {oct},
number = {5},
pages = {497--503},
title = {{Using Presence Questionnaires in Reality}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/105474600566989},
volume = {9},
year = {2000}
}
@article{Lessiter2001,
abstract = {The presence research community would benefit from a reliable and valid cross- media presence measure that allows results from different laboratories to be compared and a more comprehensive knowledge base to be developed. The ITC-Sense of Presence Inventory (ITC-SOPI) is a new state questionnaire measure whose development has been informed by previous research on the determinants of precence and current self-report measures. It focuses on users’ experiences of media, with no reference to objective system parameters. More than 600 people completed the ITC-SOPI following an experience with one of a range of noninteractive and interactive media. Exploratory analysis (principal axis factoring) revealed four factors: Sense of Physical Space, Engagement, Ecological Validity, and Negative Effects. Relations between the factors and the consistency of the factor structure with others reported in the literature are discussed. Preliminary analyses described here demonstrate that the ITC-SOPI is reliable and valid, but more rigorous testing of its psychometric properties and applicability to interactive virtual environments is required. Subject to satisfactory confirmatory analyses, the ITC-SOPI will offer researchers using a range of media systems a tool with which to measure four facets of a media experience that are putatively related to presence.},
author = {Lessiter, Jane and Freeman, Jonathan and Keogh, Ed and Davidoff, Jules},
journal = {Presence Teleoperators and Virtual Environments},
number = {3},
pages = {282--297},
title = {{Development of a new cross-media questionnaire: the ITC sense of presence inventory}},
url = {http://eprints.gold.ac.uk/483/},
volume = {10},
year = {2001}
}
@incollection{Insko2003,
abstract = {Virtual reality (VR) systems enable the user to feel as if they are present in a computer generated environment. But how do we determine the extent to which a user feels present in the virtual environment? This chapter examines three categories of methods commonly used for measuring presence; their use in the field, advantages, and disadvantages. Subjective measures rely on self-assessment by the user. Users answer questions such as "How real did the environment seem to you?", "Was the environment like a place you visited, or a series of images presented to you?". Behavioral measures examine actions or manners exhibited by the user that are responses to objects or events in the virtual environment. For example, does the user duck if a virtual object is thrown at his head. Physiological methods attempt to measure presence by gauging changes in the subject's heart rate, skin temperature, skin conductance, breathing rate, etc. In a stress-inducing virtual environment does the user exhibit physiological signs of stress? How do these methods compare when using the criteria of reliability, validity, objectivity, and sensitivity.},
author = {Insko, B E},
booktitle = {Being There: Concepts, effects and measurement of user presence in synthetic environments},
chapter = {7},
editor = {Riva, G and Davide, F and IJsselsteijn, W A},
isbn = {1566-7677},
keywords = {Behavior,heart rate,presence,simulation,training,virtual reality},
pages = {109--120},
publisher = {Ios Press},
title = {{Measuring presence: Subjective, behavioral and physiological methods}},
year = {2003}
}
@techreport{VanBaren2004,
abstract = {This compendium constitutes a comprehensive overview of presence measures described in the literature so far. It contains both subjective and objective approaches to presence measurement. The theoretical basis of measures is described, along with research in which they have been applied, and other relevant literature.},
author = {van Baren, J and IJsselsteijn, W},
booktitle = {Measurement},
institution = {OmniPres project IST-2001-39237},
keywords = {behavioural indicators,indicators,measurement,measures,methods,neural indicators,presence,psychophysiological,qualitative measures,questionnaire,review,social presence,telepresence},
publisher = {OmniPres project},
title = {{Deliverable 5 Measuring Presence : A Guide to Current Measurement Approaches}},
url = {http://www.mendeley.com/research/measuring-presence-guide-current-measurement-approaches/},
volume = {0},
year = {2004}
}
@article{Klopfer2002,
abstract = { The use of computer simulations is changing the nature of scientific investigation and providing us unique insights into the way that the world works. As simulation moves from the desktop to more ubiquitous portable devices (such as PDAs), we can draw upon the unique affordances of these devices-portability, social interactivity, context sensitivity, connectivity, and individuality. The purpose of this research project is to develop and examine a new simulation platform that is designed from the ground up for handhelds to create augmented reality simulations (i.e. simulations that bridge virtual and real worlds). This paper describes environmental detectives, one such augmented reality simulation that is currently being developed at MIT. In the upcoming months, we develop and test this concept as well as produce a suite of authoring tools that students and teachers can use to design their own augmented reality simulations.},
author = {Klopfer, E. and Squire, K. and Jenkins, H.},
journal = {Proceedings. IEEE International Workshop on Wireless and Mobile Technologies in Education},
title = {{Environmental Detectives: PDAs as a window into a virtual simulated world}},
year = {2002}
}
@article{Mann2002a,
abstract = {Mixed Reality exists in many forms along a continuum from Augmented Reality (reality enhanced by graphics, such as Sutherland's work from more than 30 years ago) to more recent efforts at Augmented Virtuality (graphics enhanced by reality, graphics enhanced by video, etc.). Mixed Reality provides numerous ways to add together (mix) various proportions of real and virtual worlds. However, Mediated Reality is an even older tradition, introduced by Stratton more than 100 years ago. Stratton presented two important ideas: 1. the idea of constructing special eyeglasses to modify how he saw the world; and 2. the ecologically motivated approach to conducting his experiments within the domain of his own everyday personal life. Stratton's seminal work has inspired a wide variety of devices that can be used to augment, deliberately diminish, or otherwise alter human visual perception. The first half of this paper presents some of the problems with the existing taxonomies (e.g. mixed reality) and distinctions (e.g. optical versus video see-through), that arise when we consider reality-modifying devices. The second half of the paper presents various new designs for reality-modifying devices, especially those used to modify only a portion of the visual reality stream, suitable for use in everyday life. These devices have the appearance of ordinary bifocal eyeglasses and reading glasses. Finally, a new kind of reality mediator that uses the eyeglass frames themselves as the mediating element is presented. This design makes it impossible for those other than the wearer, even upon very close inspection, to determine whether or not the eyeglasses contain a reality mediator. Such designs make possible livelong experiments and mediated reality experiences in personal everyday life, without the social stigma associated with obvious reality--modifying devices.},
author = {Mann, Steve},
journal = {Presence: Teleoperators and Virtual Environments},
keywords = {HCI,Mediated Reality,UX},
title = {{Mediated Reality with implementations for everyday life}},
url = {http://www.mitpressjournals.org/toc/pres/11/4},
year = {2002}
}
@misc{DiLuca2010,
abstract = {Abstract A virtual reality (VR) system tracks one or more objects to generate the depiction of a virtual environment from the user's vantage point. No system achieves this instantaneously: changes in the depicted virtual environment are delayed from changes in the position of the objects being tracked. In this paper, a method is proposed to quantify this time difference, the end-to-end delay of the VR system. Two light-sensing devices and two luminance gradients are used to simultaneously encode the position of one tracked object and its virtual counterpart. One light-sensing device is attached to the tracked object and it captures light from the gradient in the physical environment. The other device captures light from the gradient in the virtual environment. A measurement is obtained by moving the tracked object repetitively (by hand) across the gradient. The end-to-end delay is the asynchrony between the signals generated by the two light-sensing devices. The results collected with oscillatory movements performed at different frequencies indicate that for some VR systems, the end-to-end delay might not be constant but could vary as a function of the oscillation frequency.},
author = {{Di Luca}, Massimiliano},
booktitle = {Presence: Teleoperators and Virtual Environments},
doi = {10.1162/pres{\_}a{\_}00023},
issn = {1054-7460},
number = {6},
pages = {569--584},
title = {{New Method to Measure End-to-End Delay of Virtual Reality}},
volume = {19},
year = {2010}
}
@misc{LaValle2013,
author = {LaValle, Steve},
booktitle = {Oculus VR official website},
title = {{Sensor Fusion: Keeping It Simple}},
url = {http://www.oculusvr.com/blog/sensor-fusion-keeping-it-simple/},
year = {2013}
}
@article{Cutler1995,
abstract = {"The same dynamics of interction that characterize face-to-face interpersonal and group communication interaction can be found in the thousands of discussion groups in cyberspace" (p. 10) "From one perspective, the application of CMC technology is a social act from the outset" (p,2) "That altered sense of awareness that creates senses of who I am and who othes are can be called a sense of presence" (p. 3) "Like a building, the network creates the structure. ...To participate in social constructed space requires a larger sense of presence than that tied to a central geographic location" (p. 4) Personal Disclosure According to Mead {\&} Cooley, reflectivity is necessary for self-concept creation. In this age of interactive media, self-cocept creation further requires an awareness of control of disclosure. The more one discloses personal information, the more others will reciprocate, and teh more individuals know about each other the more likely they are to establish trust, seek support, and thus find satisfaction. Without disclosure and interaction nothing happens. Disclosure creates a kind of currency that is spent to keep interaction moving" (p. 4) "Regarding the formation of self-concept, control of information disclosure is important for the interaction of individuals as they seek to form affiliations and trusting relationships" "Personal information helps form relationships by disclosing interntions and thus building trust" (p. 6) Commitment "Committment does not come out of previous relationships but out of the temporal mutuality of interests" (p. 7) "Commitment of participants seems to be to maintaining their opportunities to continue discussions and to maintaining social decorum" (p,. 7) "Further commitment to maintain groups can be found in the discourses tangent to discussion or issues. Participants argue, cajole, rebuke, rejoin, rally to support each other and seek to reconcile warring parties" (p. 10) Management "People change the information space they work in" (p. 8) Social Presence The concept of social presence has already a literature allied to that of CMC. Short, Williams, and Christie (1976) take the ability of a medium to deliver degrees of audio and visual richness and tie it to a perceiver's subjective awareness of another communicator. However in cyberspace social presence in interactive social spaces takes on more of a complexion of reciprocal awareness by others of an individual and the individual's awareness of others. In interactive media such as CMC an new, mutual sense of interaction is essential to the feeling that others are there. Lurkers have low social presence, flaming reveals high social presence.},
author = {Cutler, R},
journal = {Interpersonal Computing and Technology An Electronic Journal for the 21st Century},
number = {2},
pages = {12--32},
title = {{Distributed presence and community in cyberspace}},
url = {http://www.helsinki.fi/science/optek/1995/n2/cutler.txt},
volume = {3},
year = {1995}
}
@article{Heeter1992,
abstract = {What do you feel when you enter a virtual world? What creates the experience of presence? What factors contribute to making you feel like you are there1 ?},
author = {Heeter, Carrie},
doi = {10.1109/VRAIS.1995.512482},
isbn = {1054-7460},
issn = {10547460},
journal = {Presence: Teleoperators and virtual environments},
number = {2},
pages = {262 -- 271},
title = {{Being there: The subjective experience of presence}},
url = {http://dl.acm.org/citation.cfm?id=196589},
volume = {1},
year = {1992}
}
@misc{Mann1994,
author = {Mann, Steve},
title = {{'Mediated Reality'}},
year = {1994}
}
@misc{Venables2013,
annote = {Quote from Palmer Luckey

'Luckey always shared his plans online to the few stalwarts of the then-small, virtual reality scene {\&}quot;since it kind of crashed in the 90s{\&}quot; he qualifies.'},
author = {Venables, Michael},
booktitle = {Forbes},
title = {{Eve: Valkyrie -- The Future Of Immersive Virtual Reality Gaming Experience}},
url = {http://www.forbes.com/sites/michaelvenables/2013/10/20/eve-valkyrie-the-future-of-immersive-virtual-reality-gaming-experience/},
urldate = {2013-01-24},
year = {2013}
}
@inproceedings{Oyekoya2013,
author = {Oyekoya, Oyewole and Stone, Ran and Steptoe, William and Alkurdi, Laith and Klare, Stefan and Peer, Angelika and Weyrich, Tim and Cohen, Benjamin and Tecchia, Franco and Steed, Anthony},
booktitle = {VRST '13 Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology},
pages = {165--174},
title = {{Supporting interoperability and presence awareness in collaborative mixed reality environments}},
year = {2013}
}
@inproceedings{Steptoe2010,
author = {Steptoe, William and Steed, Anthony and Rovira, Aitor and Rae, John},
booktitle = {CHI '10 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1039--1048},
title = {{Lie tracking: social presence, truth and deception in avatar-mediated telecommunication}},
year = {2010}
}
@misc{Greenhalgh,
author = {Greenhalgh, Chris and Izadi, Shahram and Benford, Steve},
title = {{The EQUIP Platform: Bringing Together Physical and Virtual Worlds}}
}
@inproceedings{Sutherland1968,
abstract = {The fundamental idea behind the three-dimensional display is to present$\backslash$nthe user with a perspective image which changes as he moves. The$\backslash$nretinal image of the real objects which we see is, after all, only$\backslash$ntwo-dimensional. Thus if we can place suitable two-dimensional images$\backslash$non the observer's retinas, we can create the illusion that he is$\backslash$nseeing a three-dimensional object. Although stereo presentation is$\backslash$nimportant to the three-dimensional illusion, it is less important$\backslash$nthan the change that takes place in the image when the observer moves$\backslash$nhis head. The image presented by the three-dimensional display must$\backslash$nchange in exactly the way that the image of a real object would change$\backslash$nfor similar motions of the user's head. Psychologists have long known$\backslash$nthat moving perspective images appear strikingly three-dimensional$\backslash$neven without stereo presentation; the three-dimensional display described$\backslash$nin this paper depends heavily on this "kinetic depth effect.},
author = {Sutherland, Ivan E},
booktitle = {Proceedings of the December 9-11, 1968, fall joint computer conference, part I},
doi = {10.1145/1476589.1476686},
isbn = {158113052X},
pages = {757--764},
publisher = {ACM},
series = {AFIPS '68 (Fall, part I)},
title = {{A head-mounted three dimensional display}},
url = {http://doi.acm.org/10.1145/1476589.1476686},
year = {1968}
}
@inproceedings{Pece2013,
abstract = {We present PanoInserts: a novel teleconferencing system that uses smartphone cameras to create a surround representation of meeting places. We take a static panoramic image of a location into which we insert live videos from smartphones. We use a combination},
author = {Pece, Fabrizio and Steptoe, William and Wanner, Fabian and Julier, Simon and Weyrich, Tim and Kautz, Jan and Steed, Anthony},
booktitle = {CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/2470654.2466173},
isbn = {9781450318990},
publisher = {ACM Request Permissions},
title = {{Panoinserts: mobile spatial teleconferencing}},
url = {http://portal.acm.org/citation.cfm?id=2470654.2466173{\&}coll=DL{\&}dl=ACM{\&}CFID=256167498{\&}CFTOKEN=74790294},
year = {2013}
}
@article{Mann1998,
abstract = {Traditionally, video has been either part of the environment, such
as video surveillance cameras mounted on or inside a building or video
conferencing systems based on fixed cameras within a special room, or
the domain of large organizations such as broadcast television stations.
However, a new field of research called {\&}amp;ldquo;personal imaging{\&}amp;rdquo;
has emerged. Personal imaging systems are based on wireless video
technology, and are typically characterized by video from a first-person
perspective by way of a head-mounted camera and display together with an
image processing computer worn on the body of the user. The
possibilities afforded by personal imaging include a personal safely
device for crime reduction, a new kind of video conferencing system for
computer-supported collaboration, as well as a new tool for
photojournalism. This article describes work in personal imaging as it
has evolved over the past 20 years, and then sets forth a future vision
for wireless video in a head-mounted context. Most notably, the notion
of computer-supported collaborative wireless video is presented},
author = {Mann, S.},
doi = {10.1109/35.685381},
issn = {0163-6804},
journal = {IEEE Communications Magazine},
number = {6},
title = {{Headmounted wireless video: computer-supported collaboration for
photojournalism and everyday use}},
volume = {36},
year = {1998}
}
@article{Mann2002,
abstract = {Diminished reality is as important as augmented reality, and both are possible with a device called the Reality Mediator . Over the past two decades, we have designed, built, worn, and tested many different embodiments of this device in the context of wearable computing, Incorporated into the Reality Mediator is an "EyeTap" system, which is a device that quantifies and resynthesizes light that would otherwise pass through one or both lenses of the eye(s) of a wearer. The functional principles of EyeTap devices are discussed, in detail. The EyeTap diverts into a spatial measurement system at least a portion of light that would otherwise pass through the center of projection of at least one lens of an eye of a wearer. The Reality Mediator has at least one mode of operation in which it reconstructs these rays of light, under the control of a wearable computer system. The computer system then uses new results in algebraic projective geometry and comparametric equations to perform head tracking, as well as to track motion of rigid planar patches present in the scene. We describe how our tracking algorithm allows an EyeTap to alter the light from a particular portion of the scene to give rise to a computer-controlled, selectively mediated reality. An important difference between mediated reality and augmented reality includes the ability to not just augment but also deliberately diminish or otherwise alter the visual perception of reality. For example, diminished reality allows additional information to be inserted without causing the user to experience information overload. Our tracking algorithm also takes into account the effects of automatic gain control, by performing motion estimation in both spatial as well as tonal motion coordinates.},
author = {Mann, Steve and Fung, James},
doi = {10.1162/1054746021470603},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
number = {2},
pages = {158--175},
title = {{EyeTap Devices for Augmented, Deliberately Diminished, or Otherwise Altered Visual Perception of Rigid Planar Patches of Real-World Scenes}},
volume = {11},
year = {2002}
}
@article{Fung2002,
abstract = { We present a way of making the wearing of a lifelong electrocardiographic health monitor fun for a user. The health monitor is coupled with a reality mediator device to create physiologically mediated reality, i.e. mediated reality which alters a user's audiovisual perception of the world based upon their own electrocardiographic waveform. This creates an interesting audiovisual experience for the user, playing upon the poetic narrative of combining cardio-centric metaphors pervasive in everyday life (the heart as a symbol of love and centrality, e.g. "get to the heart of the matter") with ubiquitous occular-centric metaphors such as "see the world from my point of view". This audiovisual experience is further enhanced by combining music which alters the visual perception and also heightens the user's emotional response to their experience and, in doing so, further affects their heart(beat).},
author = {Fung, J. and Mann, S.},
doi = {10.1109/ISMAR.2002.1115110},
isbn = {0-7695-1781-1},
journal = {Proceedings. International Symposium on Mixed and Augmented Reality},
title = {{Exploring humanistic intelligence through physiologically mediated reality}},
year = {2002}
}
@article{Woods1993,
abstract = {This paper discusses the origins, characteristics and effects of image distortions in stereoscopic video systems. The geometry of stereoscopic camera and display systems is presented first. This is followed by the analysis and diagrammatic presentation of various image distortions such as depth plane curvature, depth non-linearity, depth and size magnification, shearing distortion and keystone distortion. The variation of system parameters is also analyzed with the help of plots of image geometry to show their effects on image distortions. The converged (toed-in) and parallel camera configurations are compared and the amount of vertical parallax induced by lens distortion and keystone distortion are discussed. The range of acceptable vertical parallax and the convergence/accommodation limitations on depth range are also discussed. It is shown that a number of these distortions can be eliminated by the appropriate choice of camera and display systems parameters. There are some image distortions, however, which cannot be avoided due to the nature of human vision and limitations of current stereoscopic video display techniques.},
author = {Woods, Andrew and Docherty, Tom and Koch, Rolf},
doi = {10.1117/12.157041},
issn = {0277786X},
journal = {SPIE's Symposium on Electronic Imaging: Science and Technology},
number = {February 1993},
pages = {36----48},
title = {{Image Distortions in Stereoscopic Video Systems}},
volume = {36},
year = {1993}
}
@misc{Constantin2003a,
author = {Constantin, Corina},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Constantin - 2003 - Virtual Environments and the Sense of Being There An SEM Model of Presence Extended abstract submitted for presentat.pdf:pdf},
pages = {1--18},
title = {{Virtual Environments and the Sense of Being There: An SEM Model of Presence}},
year = {2003}
}
@inproceedings{Ijsselsteijn2001,
author = {Ijsselsteijn, Wijnand},
booktitle = {Proceedings of the AIIA 2002 'Workshop sulla percezione della presenza in ambienti virtuali o remoti'},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ijsselsteijn - 2001 - Understanding Presence.pdf:pdf},
title = {{Understanding Presence}},
year = {2001}
}
@misc{Constantin2003,
author = {Constantin, Corina},
title = {{Virtual Environments and the Sense of Being There: An SEM Model of Presence}},
year = {2003}
}
@misc{IndoorAtlasInc.,
author = {{IndoorAtlas Inc.}},
title = {{Accuracy of IndoorAtlas indoor positioning system}},
url = {https://www.indooratlas.com/faq{\#}q242897},
urldate = {2014-01-13}
}
@book{Rheingold1992,
author = {Rheingold, Howard},
isbn = {978-0671778972},
pages = {416},
publisher = {Simon {\&} Schuster},
title = {{Virtual Reality: The Revolutionary Technology of Computer-Generated Artificial Worlds - and How It Promises to Transform Society}},
year = {1992}
}
@book{Rheingold2000,
address = {Cambridge, MA},
author = {Rheingold, Howard},
edition = {revised ed},
isbn = {978-0262681216},
pages = {447},
publisher = {The MIT Press},
title = {{The Virtual Community: Homesteading on the Electronic Frontier}},
year = {2000}
}
@book{Blascovich2011,
author = {Blascovich, Jim and Bailenson, Jeremy},
isbn = {978-0061809507},
pages = {304},
publisher = {William Morrow},
title = {{Infinite Reality: Avatars, Eternal Life, New Worlds, and the Dawn of the Virtual Revolution}},
year = {2011}
}
@book{Benedikt1992,
address = {Cambridge, MA},
editor = {Benedikt, Michael},
isbn = {978-0262521772},
pages = {446},
publisher = {The MIT Press},
title = {{Cyberspace: First Steps}},
year = {1992}
}
@inproceedings{Applin2013,
author = {Applin, Sally A and Fischer, Michael},
booktitle = {Proceedings of the IEEE International Symposium on Technology and Society (ISTAS)},
title = {{Watching Me, Watching You (Process Surveillance and Agency in the Workplace)}},
year = {2013}
}
@inproceedings{Applin2013a,
abstract = {We explore how PolySocial Reality (PoSR), a framework for representing how people, devices and communication technologies interrelate, can be applied to developing use cases within integrated IoT and Smart Environment paradigms, giving special consideration to the nature of location-aware messaging from sensors, and the resultant data collection.},
author = {Applin, Sally A and Fischer, Michael},
booktitle = {Proceedings of the IEEE Conference on Intelligent User Interfaces (IUI 2013) IUI Workshop on Location Awareness for Mixed and Dual Reality (LAMDa)},
title = {{Thing Theory: Connecting Humans to Location-Aware Smart Environments}},
year = {2013}
}
@article{Slater1997,
abstract = {Reviews the concepts of immersion and presence in virtual environments (VEs). Aspects of immersion; Definition of presence; Influence of immersion on presence; Presence in shared environments; How the degree of immersion can be objectively assessed as the characteristics of a technology.},
author = {Slater, Mel and Wilbur, Sylvia},
issn = {10547460},
journal = {Presence Teleoperators Virtual Environments},
keywords = {research,terms {\&} phrases,virtual computer systems,virtual reality},
number = {6},
pages = {603},
pmid = {7851},
publisher = {MIT Press},
title = {{A framework for immersive virtual environments (FIVE)}},
url = {http://libezproxy.open.ac.uk/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=a9h{\&}AN=9716{\&}site=ehost-live{\&}scope=site},
volume = {6},
year = {1997}
}
@phdthesis{Perl2012,
author = {Perl, Thomas},
school = {Vienna University of Technology},
title = {{Cross-Platform Tracking of a 6DoF Motion Controller}},
year = {2012}
}
@inproceedings{Regenbrecht2002,
author = {Regenbrecht, Holger and Schubert, Thomas},
booktitle = {Proceedings of the 5th Annual International Workshop on Presence},
title = {{Measuring presence in augmented reality environments: design and a first test of a questionnaire}},
year = {2002}
}
@inproceedings{Wesugi2003,
author = {Wesugi, Shigeru and Miwa, Yoshiyuki},
booktitle = {Presence},
title = {{"Dual" embodied interaction for creating a virtual co-existing space}},
year = {2003}
}
@inproceedings{Groten2011,
author = {Groten, Raphaela and Kilteni, Konstantina and Slater, Mel},
booktitle = {Beaming},
title = {{Discussion of Embodiment as Basis for Enhanced Virtual Reality}},
year = {2011}
}
@article{Zhao2003,
abstract = {This paper contributes to the presence literature by explicating the meanings and subtypes of copresence. Copresence is defined here as consisting of two dimensions: copresence as mode of being with others, and copresence as sense of being with others. Mode of copresence refers to the physical conditions that structure human interaction. Six such conditions are delineated. Sense of copresence, on the other hand, refers to the subjective experience of being with others that an individual acquires in interaction. The main argument of this paper is that mode of copresence affects sense of copresence, and knowledge of how the former affects the latter will benefit copresence design. ABSTRACT FROM AUTHOR},
author = {Zhao, Shanyang},
doi = {10.1162/105474603322761261},
issn = {10547460},
journal = {Presence Teleoperators Virtual Environments},
number = {5},
pages = {445--455},
publisher = {MIT Press},
title = {{Toward a Taxonomy of Copresence}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/105474603322761261},
volume = {12},
year = {2003}
}
@article{Steuer1992,
abstract = {Virtual reality (VR) is typically defined in terms of technological hardware. This paper attempts to cast a new, variable-based definition of virtual reality that can be used to classify virtual reality in relation to other media. The defintion of virtual reality is based on concepts of presence and telepresence, which refer to the sense of being in an environment, generated by natural or mediated means, respectively. Two technological dimensions that contribute to telepresence, vividness and interactivity, are discussed. A variety of media are classified according to these dimensions. Suggestions are made for the application of the new definition of virtual reality within the field of communication research.},
author = {Steuer, Jonathan},
doi = {10.1111/j.1460-2466.1992.tb00812.x},
editor = {Biocca, F and Levy, M R},
institution = {Institute for Communication Research in the Communication Department (Stanford University)},
isbn = {080581549X},
issn = {00219916},
journal = {Journal of Communication},
number = {4},
pages = {73--93},
pmid = {19369540},
publisher = {Blackwell Publishing Ltd},
series = {Communication in the age of virtual reality},
title = {{Defining Virtual Reality: Dimensions Determining Telepresence}},
url = {http://doi.wiley.com/10.1111/j.1460-2466.1992.tb00812.x},
volume = {42},
year = {1992}
}
@misc{Bruckman1992,
abstract = {This survey paper introduces the different kinds of MUDs, and social phenomena typical of each kind. It introduces issues of representations of self and how MUDs form a kind of "identity workshop." Introduces the notion of MUDs as an evocative medium--by being between reality and unreality, MUDs often encourage people to reflect on the nature of reality. Introduces gender issues that arise in MUDs, and explores the topic of MUD addiction.},
author = {Bruckman, Amy},
publisher = {unpublished paper},
title = {{Identity Workshop: Emergent Social and Psychological Phenomena in Text-Based Virtual Reality}},
year = {1992}
}
@article{Papagiannakis2009,
abstract = {We propose an integrated Mixed Reality methodology for recreating ancient daily life that features realistic simulations of animated virtual human actors (clothes, body, skin, face) who augment real environments and re-enact staged storytelling dramas. We aim to go further from traditional concepts of static cultural artifacts or rigid geometrical and 2D textual augmentations and allow for 3D, interactive, augmented historical character-based event representations in a mobile and wearable setup. This is the main contribution of the described work as well as the proposed extensions to AR Enabling technologies: a VR/AR character simulation kernel framework with real-time, clothed virtual humans that are dynamically superimposed on live camera input, animated and acting based on a predefined, historically correct scenario. We demonstrate such a real-time case study on the actual site of ancient Pompeii.},
author = {Papagiannakis, George and Magnenat-Thalmann, Nadia},
journal = {Arqueologica 2.0},
pages = {16--20},
title = {{Recreating Daily Life in Pompeii}},
volume = {1},
year = {2009}
}
@article{Magnenat-Thalmann2008,
abstract = {Abstract In this paper, we intro- duce a European research project, interactive media with personal networked devices (INTERMEDIA) in which we seek to progress be- yond the home and device-centric convergence toward truly user- centric convergence of multimedia. Our vision is to make the user the multimedia center: the user as the point at which multimedia services and the means for interacting with them converge. This paper proposes the main research goals in providing users with a personalized interface and content independent of physical networked devices, and space and time. As a case study, we describe an indoors, mobile mixed reality guide system: ChloeUniversity. With a see-through head-mounted display (HMD) connected to a small wearable computing de- vice, ChloeUniversity provides users with an efficient way to guide someone in a building. A 3D virtual character in front of the user guides him/her to the required destination.},
author = {Magnenat-Thalmann, Nadia and Peternier, Achille and Righetti, Xavier and Lim, Mingyu and Papagiannakis, George and Fragopoulos, Tasos and Lambropoulou, Kyriaki and Barsocchi, Paolo and Thalmann, Daniel},
doi = {10.1007/s00371-008-0264-6},
issn = {01782789},
journal = {The Visual Computer},
keywords = {content,dynamic networks,interactive media,management,mobile mixed reality,personalized,wearable interface},
number = {7-9},
pages = {827--836},
title = {{A virtual 3D mobile guide in the INTERMEDIA project}},
url = {http://www.springerlink.com/index/10.1007/s00371-008-0264-6},
volume = {24},
year = {2008}
}
@article{Papagiannakis2008,
abstract = {Recent advances in hardware and software for mobile computing have enabled a new breed of mobile AR systems and applications. A new breed of computing called augmented ubiquitous computing has resulted from the convergence of wearable computing, wireless networking and mobile AR interfaces. In this paper we provide a survey of different mobile and wireless technologies and how they have impact AR. Our goal is to place them into different categories so that it becomes easier to understand the state of art and to help identify new directions of research.},
author = {Papagiannakis, George and Singh, Gurminder and Magnenat-Thalmann, Nadia},
doi = {10.1002/cav.221},
institution = {MIRALab, University of Geneva},
issn = {15464261},
journal = {Computer Animation And Virtual Worlds},
keywords = {augmented mixed reality,mobile systems,wireless networking},
number = {1},
pages = {3--22},
publisher = {Wiley Online Library},
title = {{A survey of mobile and wireless technologies for augmented reality systems}},
url = {http://doi.wiley.com/10.1002/cav.221},
volume = {19},
year = {2008}
}
@article{Arnold2008,
abstract = {Modern 3D VR systems rely heavily on the interplay of heterogeneous technologies. Because of this inherently interdisciplinary character, VR domain can be viewed as a melting pot of various technologies which although complementary are non-trivial to put together. Frameworks can be used to address this challenge as they offer advantages such as reusability of components, as well as easiness of replacements, extensions, and adaptations. Hence, this paper presents developments within the EPOCH project, in particular the Characterize NEWTON, to improve and release frameworks that support the incorporation of avatars in interactive real-time 3D VR systems. The purpose is to enable avatars to be interactive and to react to model metadata; thus adding realism and engaging the users interest. This vertical middleware offers the advantage to be based on open source generic frameworks, such as OpenScenegraph and OpenSG as well as offering complementary functionalities},
author = {Arnold, D and Glauert, J and Jennings, V and Kevelham, B and Ma{\"{\i}}m, Jonathan and Maupu, D and Papagiannakis, G and Thalmann, D and Yersin, Barbara},
journal = {Environments},
pages = {6},
title = {{Tools for Populating Cultural Heritage Environments with Interactive Virtual Humans}},
url = {http://eprints.brighton.ac.uk/6408/1/rome-final-event.pdf},
volume = {3},
year = {2008}
}
@incollection{Magnenat-Thalmann2008a,
abstract = {Recent advances in hardware and software for mobile computing have enabled a new breed of mobile Augmented Reality systems and applications featuring interactive virtual characters. This has resulted from the convergence of the tremendous progress in mobile computer graphics and mobile AR interfaces. In this paper, we focus on the evolution of our algorithms and their integration towards improving the presence and interactivity of virtual characters in real and virtual environments, as we realize the transition from mobile workstations to ultra-mobile PC’s. We examine in detail three crucial parts of such systems: user-tracked interaction; real-time, automatic, adaptable animation of virtual characters and deformable pre-computed radiance transfer illumination for virtual characters. We examine our efforts to enhance the sense of presence for the user, while maintaining the quality of animation and interactivity as we scale and deploy our AR framework in a variety of platforms. We examine different AR virtual human enhanced scenarios under the different mobile devices that illustrate the interplay and applications of our methods.},
author = {Magnenat-Thalmann, Nadia and Papagiannakis, George and Chaudhuri, Parag},
booktitle = {Encyclopedia of Multimedia},
pages = {362--368},
title = {{Interactive virtual humans in mobile augmented reality}},
year = {2008}
}
@article{Foni2007,
abstract = {This paper presents a case study centered on the virtual restitution and virtual life simulation of a highly complex and endangered heritage edifice: the church of Hagia Sophia, in Istanbul, Turkey. The goal of this article is to describe the techniques used in order to achieve a real time rendering and animation of the selected space and its characters, as well as to point out the challenges and solutions that such a work implies at different stages in production. Most of these issues are focused on the reconstruction of the architecture of the site; however, in order to achieve an accurate simulation, the social aspect is not to be omitted. The importance of a heritage site resides as well in the historical characters and the social interactions that were taking place there: this information allows a better understanding of the function and the importance of the selected site in connection with the cultural aspects of the life at a certain time. In order to strengthen the feeling of immersion in a heritage edifice virtually restituted, it is important to recreate virtual life and describe the timely evolutionary aspects of the edifice as well.},
author = {Foni, Alessandro E and Papagiannakis, George and Cadi-Yazli, Nedjma and Magnenat-Thalmann, Nadia},
journal = {International Journal of Architectural Computing},
number = {2},
pages = {284--301},
title = {{Time-Dependant Illumination And Animation Of Virtual Hagia-Sophia}},
volume = {5},
year = {2007}
}
@article{Papagiannakis2007,
abstract = {We propose a new methodology for real-time mobile mixed reality systems that feature realistic simulations of animated virtual human actors (clothes, body, skin, face) who augment real environments and re-enact staged storytelling dramas. Although ini- tially targeted at Cultural Heritage Sites, the paradigm is by no means limited to such subjects. The abandonment of traditional concepts of static cultural artifacts or rigid geometrical and 2D textual augmentations with 3D, interactive, augmented histori- cal character-based event representations in a mobile and wearable setup, is the main contribution of the described work as well as the proposed extensions to AR Enabling technologies: a VR/AR character simulation kernel framework with character to object interaction, a markerless camera tracker specialized for non-invasive geometrical registration on heritage sites and a PRT mixed reality illumination model for more consistent real-virtual real-time rendering. We demonstrate a real-time case study on the actual site of ancient Pompeii. PDF},
author = {Papagiannakis, George and Magnenat-Thalmann, Nadia},
doi = {10.1260/147807707781514887},
issn = {14780771},
journal = {International Journal of Architectural Computing},
number = {2},
pages = {396--415},
title = {{Mobile Augmented Heritage: Enabling Human Life in Ancient Pompeii}},
url = {http://openurl.ingenta.com/content/xref?genre=article{\&}issn=1478-0771{\&}volume=5{\&}issue=2{\&}spage=396},
volume = {5},
year = {2007}
}
@article{Magnenat-Thalmann7,
abstract = {The present article discusses and details the methodological approaches and the reconstruction strategies that have been employed to realize the 3D real-time virtual simulations of the populated ancient sites of Aspendos and Pompeii, respectively visualized using a virtual and an augmented reality setup. More specifically, the two case studies to which we refer concern the VR restitution of the Roman theatre of Aspendos in Turkey, visualized as it was in the 3rd century, and the on-site AR simulation of a digitally restored Thermopolium situated at the archeological site of Pompeii in Italy. In order to enhance both simulated 3D environments, either case study presents the inclusion of real time animated virtual humans, which are re-enacting situations and activities that were typically performed in such sites during ancient times. Furthermore, the implemented modeling and real time illumination strategies of both the textured static 3D models of the sites and the simulated dynamic virtual humans are equally presented and compared.},
author = {Magnenat-Thalmann, Nadia and Foni, Alessandro E and Papagiannakis, George and Cadi-Yazli, Nedjma},
journal = {The International Journal of Virtual Reality2},
number = {1},
pages = {11--24},
title = {{Real Time Animation and Illumination in Ancient Roman Sites}},
url = {http://george.papagiannakis.org/?p=269},
volume = {6},
year = {2007}
}
@article{Egges2007,
abstract = {In this paper, we present a simple and robust Mixed Reality (MR) framework that allows for real-time interaction with Virtual Humans in real and virtual environments under consistent illumination. We will look at three crucial parts of this system: interaction, animation and global illumination of virtual humans for an integrated and enhanced presence. The interaction system comprises of a dialogue module, which is interfaced with a speech recognition and synthesis system. Next to speech output, the dialogue system generates face and body motions, which are in turn managed by the virtual human animation layer. Our fast animation engine can handle various types of motions, such as normal key-frame animations, or motions that are generated on-the-fly by adapting previously recorded clips. All these different motions are generated and blended on-line, resulting in a flexible and realistic animation. Our robust rendering method operates in accordance with the previous animation layer, based on an extended for virtual humans Precomputed Radiance Transfer (PRT) illumination model, resulting in a realistic display of such interactive virtual characters in mixed reality environ- ments. Finally, we present a scenario that illustrates the interplay and application of our methods, glued under a unique framework for presence and interaction in MR.},
author = {Egges, Arjan and Papagiannakis, George and Magnenat-Thalmann, Nadia},
journal = {The Visual Computer},
number = {5},
pages = {317--333},
title = {{Presence and Interaction in Mixed Reality Environments}},
url = {http://george.papagiannakis.org/?p=266},
volume = {23},
year = {2007}
}
@article{Papagiannakis2005,
abstract = {This paper presents an innovative 3D reconstruction of ancient fresco paintings through the real-time revival of their fauna and flora, featuring groups of virtual animated characters with artificial-life dramaturgical behaviours in an immersive, fully mobile augmented reality (AR) environment. The main goal is to push the limits of current AR and virtual storytelling technologies and to explore the processes of mixed narrative design of fictional spaces (e.g. fresco paintings) where visitors can experience a high degree of realistic immersion. Based on a captured/real-time video sequence of the real scene in a video-see-through HMD set-up, these scenes are enhanced by the seamless accurate real-time registration and 3D rendering of realistic complete simulations of virtual flora and fauna (virtual humans and plants) in a real-time storytelling scenario-based environment. Thus the visitor of the ancient site is presented with an immersive and innovative multi-sensory interactive trip to the past. Copyright (c) 2005 John Wiley T Sons, Ltd.},
author = {Papagiannakis, George and Schertenleib, Sbastien and O'Kennedy, Brian and Arevalo-Poizat, Marlene and Magnenat-Thalmann, Nadia and Stoddart, Andrew and Thalmann, Daniel},
doi = {10.1002/cav.53},
issn = {15464261},
journal = {Computer Animation And Virtual Worlds},
number = {1},
pages = {11--24},
publisher = {John Wiley and Sons Ltd.},
title = {{Mixing virtual and real scenes in the site of ancient Pompeii}},
url = {http://doi.wiley.com/10.1002/cav.53},
volume = {16},
year = {2005}
}
@misc{Evolutionrobotics2005,
annote = {<m:note>evolution robotics were bought by iRobot (who now sell roombas(?)) {\&}amp; there is now no mention of NorthStar ;{\_};</m:note>},
author = {Evolution robotics},
title = {{NorthStar}},
url = {https://www.google.co.uk/url?sa=t{\&}rct=j{\&}q={\&}esrc=s{\&}source=web{\&}cd=1{\&}ved=0CDEQFjAA{\&}url=https://roboticsclub.org/redmine/projects/scoutmech/repository/revisions/f2ca18541deb46ed6ab2988d08361a2b738979cd/entry/docs/Research/Localization/northstar.pdf{\&}ei=9zIvUqvDMIeS0QXLqoGQBQ{\&}usg=AFQjCNEMJeZAdj-h7ChZwpM5uTrVNfyJJg{\&}sig2=kieAgASt4kgFXVLKT2956A{\&}bvm=bv.51773540,d.d2k},
year = {2005}
}
@misc{Liu2007,
abstract = {Wireless indoor positioning systems have become very popular in recent years. These systems have been successfully used in many applications such as asset tracking and inventory management. This paper provides an overview of the existing wireless indoor positioning solutions and attempts to classify different techniques and systems. Three typical location estimation schemes of triangulation, scene analysis, and proximity are analyzed. We also discuss location fingerprinting in detail since it is used in most current system or solutions. We then examine a set of properties by which location systems are evaluated, and apply this evaluation method to survey a number of existing systems. Comprehensive performance comparisons including accuracy, precision, complexity, scalability, robustness, and cost are presented.},
author = {Liu, Hui Liu Hui and Darabi, H and Banerjee, P and Liu, Jing Liu Jing},
booktitle = {IEEE Transactions on Systems Man and Cybernetics Part C Applications and Reviews},
doi = {10.1109/TSMCC.2007.905750},
editor = {Darabi, H},
issn = {10946977},
keywords = {indoor location sensing,location fingerprinting,positioning algorithm,radio frequency (rf),wireless localization},
number = {6},
pages = {1067--1080},
publisher = {IEEE},
title = {{Survey of Wireless Indoor Positioning Techniques and Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4343996},
volume = {37},
year = {2007}
}
@article{Medina2013,
abstract = {This paper describes the TELIAMADE system, a new indoor positioning system based on time-of-flight (TOF) of ultrasonic signal to estimate the distance between a receiver node and a transmitter node. TELIAMADE system consists of a set of wireless nodes equipped with a radio module for communication and a module for the transmission and reception of ultrasound. The access to the ultrasonic channel is managed by applying a synchronization algorithm based on a time-division multiplexing (TDMA) scheme. The ultrasonic signal is transmitted using a carrier frequency of 40 kHz and the TOF measurement is estimated by applying a quadrature detector to the signal obtained at the A/D converter output. Low sampling frequencies of 17.78 kHz or even 12.31 kHz are possible using quadrature sampling in order to optimize memory requirements and to reduce the computational cost in signal processing. The distance is calculated from the TOF taking into account the speed of sound. An excellent accuracy in the estimation of the TOF is achieved using parabolic interpolation to detect of maximum of the signal envelope at the matched filter output. The signal phase information is also used for enhancing the TOF measurement accuracy. Experimental results show a root mean square error (rmse) less than 2 mm and a standard deviation less than 0.3 mm for pseudorange measurements in the range of distances between 2 and 6 m. The system location accuracy is also evaluated by applying multilateration. A sub-centimeter location accuracy is achieved with an average rmse of 9.6 mm.},
author = {Medina, Carlos and Segura, Jos{\'{e}} Carlos and {De La Torre}, {\'{A}}ngel},
doi = {10.3390/s130303501},
issn = {14248220},
journal = {Sensors Basel Switzerland},
number = {3},
pages = {3501--26},
pmid = {23486218},
title = {{Ultrasound indoor positioning system based on a low-power wireless sensor network providing sub-centimeter accuracy.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3658758{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {13},
year = {2013}
}
@misc{Mautz2011,
abstract = {Recent advances in CCD technologies, processing speed and image understanding have been driving the development of the camera-based positioning systems. An improved performance of optical systems has triggered image based positioning methods to become an attractive alternative for applications in industrial metrology as well as for robot- and pedestrian navigation. This paper provides a survey of current optical indoor positioning approaches. Different systems are briefly described and categorized based on how the images are referenced to the environment.},
author = {Mautz, Rainer and Tilch, Sebastian},
booktitle = {2011 International Conference on Indoor Positioning and Indoor Navigation},
doi = {10.1109/IPIN.2011.6071925},
institution = {ETH Z{\&}{\#}x00FC;rich, Switzerland},
isbn = {9781457718038},
keywords = {camera based positioning,indoor photogrammetry,optical indoor positioning},
pages = {1--7},
publisher = {IEEE},
title = {{Survey of optical indoor positioning systems}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6071925},
year = {2011}
}
@article{Priyantha2000,
abstract = {This paper presents the design, implementation, and evaluation of Cricket, a location-support system for in-building, mobile, location- dependent applications. It allows applications running on mobile and static nodes to learn their physical location by using listeners that hear and analyze information from beacons spread throughout the building. Cricket is the result of several design goals, including user privacy, decentralized administration, network heterogeneity, and low cost. Rather than explicitly tracking user location, Cricket helps devices learn where they are and lets them decide whom to advertise this information to; it does not rely on any centralized management or control and there is no explicit coordination be- tween beacons; it provides information to devices regardless of their type of network connectivity; and each Cricket device is made from off-the-shelf components and costs less than U.S. {\$}10.We describe the randomized algorithm used by beacons to transmit information, the use of concurrent radio and ultrasonic signals to infer distance, the listener inference algorithms to overcome multipath and inter- ference, and practical beacon configuration and positioning tech- niques that improve accuracy. Our experience with Cricket shows that several location-dependent applications such as in-building ac- tive maps and device control can be developed with little effort or manual configuration.},
author = {Priyantha, Nissanka B and Chakraborty, Anit and Balakrishnan, Hari},
doi = {10.1145/345910.345917},
institution = {ACM},
isbn = {1581131976},
journal = {Proceedings of the 6th annual international conference on Mobile computing and networking MobiCom 00},
number = {August},
pages = {32--43},
publisher = {ACM Press},
series = {MobiCom '00},
title = {{The Cricket location-support system}},
url = {http://portal.acm.org/citation.cfm?doid=345910.345917},
volume = {2000},
year = {2000}
}
@inproceedings{Papagiannakis2004,
abstract = {In this paper we present our work on the LIFEPLUS EU IST project. LIFEPLUS proposes an innovative 3D reconstruction of ancient frescos-paintings through the real-time revival of their fauna and flora, featuring groups of virtual animated characters with artificial life dramaturgical behaviors, in an immersive AR environment. The goal of this project is to push the limits of current Augmented Reality (AR) technologies, exploring the processes of narrative design of fictional spaces where users can experience a high degree of realistic interactive immersion. Based on a captured/real-time video of a real scene, the project is oriented in enhancing these scenes by allowing the possibility to render realistic 3D simulations of virtual characters in real-time. Although initially targeted at Cultural Heritage Centers and Sites, the paradigm is by no means limited to such subjects, but encompasses all types of future Location-Based Entertainments, E- visitor Attractions, e-Worker training schemes as well as on-set visualizations for the TV/movie industry. In this paper we provide an overview of the project and the technologies being employed and finally we present early results based on the ongoing research.},
author = {Papagiannakis, George and Schertenleib, Sebastien and Ponder, Michal and Ar{\'{e}}valo-Poizat, Marl{\`{e}}ne and Magnenat-Thalmann, Nadia and Thalmann, Daniel},
booktitle = {1st European Conference on Visual Media Production CVMP},
isbn = {0863413919},
number = {4},
pages = {273--276},
publisher = {IET},
title = {{Real-time virtual humans in AR sites}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.2478{\&}amp;rep=rep1{\&}amp;type=pdf},
year = {2004}
}
@inproceedings{Nakazato2008,
author = {Nakazato, Yusuke and Kanbara, Masayuki and Yokoya, Naokazu},
booktitle = {Proceedings of the ACM Symposium on Virtual Reality Software and Technology},
pages = {295--296},
title = {{Localization System for Large Indoor Environments Using Invisible markers}},
year = {2008}
}
@inproceedings{Okura2011,
author = {Okura, Fumio and Kanbara, Masayuki and Yokoya, Naokazu},
booktitle = {International Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 2011, Vancouver, BC, Canada, August 7-11, 2011 , Poster Proceedings},
title = {{Fly-through Heijo Palace Site: Historical Tourism System Using Augmented Telepresence}},
year = {2011}
}
@article{Okura2006,
abstract = {Augmented Telepresence is a technique for viewing a remote site using immersive displays.},
author = {Okura, Fumio and Kanbara, Masayuki and Yokoya, Naokazu},
isbn = {9781450309219},
journal = {Computer},
pages = {4503--4503},
title = {{Fly-through Heijo Palace Site : Augmented Telepresence Using Aerial Omnidirectional Videos}},
volume = {1},
year = {2006}
}
@inproceedings{Yamanaka2007,
abstract = {This paper describes a new method of measuring position of running user for location-based services in wide indoor environments, such as augmented reality navigation system with wearable computer. Conventional localization methods usually employ a hybrid approach in which user's position is estimated by combining positioning infrastructures and a pedometer. Since the installation cost of infrastructures increases when the area expands, the measurement method of user's relative position with high accuracy is required. Although a number of methods using a pedometer have been developed to improve the estimation accuracy, these methods generally can handle only usual walking behavior of a user. This paper proposes a new real time localization method for both walking and running users by using a wearable electromagnetic tracker and an inertial sensor. The proposed localization method estimates a moving distance in the period when both legs do not ground by estimating a velocity of waist when user's leg leaves. Experiments have been carried out using a prototype system to evaluate the accuracy of user localization with the proposed method.},
author = {Yamanaka, Kazuki and Kanbara, Masayuki and Yokoya, Naokazu},
booktitle = {17TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE ICAT 2007 PROCEEDINGS},
isbn = {9780769530567},
organization = {Aalborg Univ Esbjerg; Virtual Real Soc Japan; SoundScapes; KPMG; Teknisk Landsforbund; Thuesen Bodker {\&} Jaeger; LEGO; Sydvestjysk Udviklingsforum; IBM; Varde Erhvervs OG Turistrad; arKaos; VRLOGIC; EXPLANAR; ZEN; Art Abilitation; LEDA; ICVR},
pages = {39--45},
title = {{Localization of walking or running user with wearable 3D position sensor}},
year = {2007}
}
@incollection{Taketomi2011,
abstract = {This paper describes an application of augmented reality (AR) techniques to virtual cultural heritage reconstruction on the real sites of defunct constructs. To realize AR-based cultural heritage reconstruction, extrinsic camera parameter estimation is required for geometric registration of real and virtual worlds. To estimate extrinsic camera parameters, we use a pre-constructed feature landmark database of the target environment. Conventionally, a feature landmark database has been constructed in a large-scale environment using a structure -from-motion technique for omnidirectional image sequences. However, the accuracy of estimated camera parameters is insufficient for specific applications like AR-based cultural heritage reconstruction, which needs to overlay CG objects at the position close to the user’s viewpoint. This is due to the difficulty in compensation of the appearance change of close landmarks only from the sparse 3-D information obtained by structure-from-motion. In this paper, visual patterns of landmarks are compensated for by considering local shapes obtained by omnidirectional range finder to find corresponding landmarks existing close to the user. By using these landmarks with local shapes, accurate geometric registration is achieved for AR sightseeing in historic sites.},
author = {Taketomi, Takafumi and Sato, Tomokazu and Yokoya, Naokazu},
booktitle = {Computer Vision – ACCV 2010 Workshops},
pages = {265--275},
title = {{AR Cultural Heritage Reconstruction Based on Feature Landmark Database Constructed by Using Omnidirectional Range Sensor}},
year = {2011}
}
@article{Weng2012,
abstract = {Introductions are given to various display systems and corresponding registration methods developed and realized at Beijing Institute of Technology for augmented reality applications. An interactive projection system is used in a theatrical performance, and the registration between the virtual scene (projected image) and the real objects (dancers) is realized through a video camera working in the near infrared waveband. An ultra-light wide-angle head-mounted display system is designed for an interactive exhibition item in a scientific museum, and a multi-user six-degree-of-freedom tracking system is developed for the indoor registration, which uses infrared markers projected on the ceiling and a camera fixed on top of each head-mounted display. A fixed-position viewing system is developed for the on-site digital reconstruction of a historical site, which provides visitors with the visualization of the original magnificent buildings on the natural field of the ruins. The azimuth and pitch of the viewing system are detected by two rotary encoders. A volumetric 3D display based on multi-angle projection is applied in a navigation system for endoscopic sinus surgery. A 3D digital scanner is employed to scan the skin on the patient's head for the alignment between the patient and the 3D model from his CT or MRI images. The registration of the surgical tool is also achieved by optical means through tracking cameras.},
author = {Weng, Dongdong and Cheng, Dewen and Wang, Yongtian and Liu, Yue},
journal = {Optik - International Journal for Light and Electron Optics},
number = {9},
pages = {769--774},
title = {{Display systems and registration methods for augmented reality applications}},
url = {http://dx.doi.org/10.1016/j.ijleo.2011.05.033},
volume = {123},
year = {2012}
}
@article{Carmigniani2010,
abstract = {This paper surveys the current state-of-the-art of technology, systems and applications in Augmented Reality. It describes work performed by many different research groups, the purpose behind each new Augmented Reality system, and the difficulties and problems encountered when building some Augmented Reality applications. It surveysmobile augmented reality systems challenges and requirements for successful mobile systems. This paper summarizes the current applications of Augmented Reality and speculates on future applications and where current research will lead Augmented Realitys development. Challenges augmented reality is facing in each of these applications to go fromthe laboratories to the industry, as well as the future challenges we can forecast are also discussed in this paper. Section 1 gives an introduction to what Augmented Reality is and the motivations for developing this technology. Section 2 discusses Augmented Reality Technologies with computer vision methods, AR devices, interfaces and systems, and visualization tools. The mobile and wireless systems for Augmented Reality are discussed in Section 3. Four classes of current applications that have been explored are described in Section 4. These applications were chosen as they are the most famous type of applications encountered when researching AR apps. The future of augmented reality and the challenges they will be facing are discussed in Section 5.},
author = {Carmigniani, Julie and Furht, Borko and Anisetti, Marco and Ceravolo, Paolo and Damiani, Ernesto and Ivkovic, Misa},
doi = {10.1007/s11042-010-0660-6},
issn = {13807501},
journal = {Multimedia Tools and Applications},
keywords = {ar,augmented,augmented reality,augmented reality applications,augmented reality iphone4,augmented reality technologies,b,carmigniani,furht,j,reality mobile devices,systems},
number = {1},
pages = {341--377},
publisher = {Springer Netherlands},
title = {{Augmented reality technologies, systems and applications}},
url = {http://www.springerlink.com/index/10.1007/s11042-010-0660-6},
volume = {51},
year = {2010}
}
@article{Foni2010,
abstract = {In this article we present a general classification of the different approaches that might be employed to constitute a visual representation of a cultural heritage item, including the ones featuring the use of traditional tools as the ones exhibiting the inclusion of modern 2D and 3D digital technologies. In order to establish a coherent taxonomy, specific elements characterizing such approaches will be discussed and employed to assist the definition of a general conceptual framework that will enable the classification of the possible design choices according to their specific characteristics. Finally, a selection of modeling and simulation techniques which are specifically related to the creation process underlying the virtual representation of heritage items by means of modern visualization technologies will be explored alongside the main areas of preferences linked to the major actors active in the cultural heritage field.},
author = {Foni, Alessandro E and Papagiannakis, George and Magnenat-Thalmann, Nadia},
doi = {10.1145/1805961.1805962},
issn = {15564673},
journal = {Journal on Computing and Cultural Heritage},
number = {1},
pages = {1--21},
publisher = {ACM},
title = {{A taxonomy of visualization strategies for cultural heritage applications}},
url = {http://portal.acm.org/citation.cfm?doid=1805961.1805962},
volume = {3},
year = {2010}
}
@article{Campos-Castillo2012,
author = {Campos-Castillo, Celeste},
journal = {Sociology Compass},
number = {5},
pages = {425--433},
title = {{Copresence in Virtual Environments}},
volume = {6},
year = {2012}
}
@inproceedings{Zhao2002,
author = {Zhao, Shanyang},
booktitle = {Proceedings of the fifth annual international workshop on Presence},
title = {{Reconceptualizing Presence: Differentiating Between Mode of Presence and Sense of Presence}},
year = {2002}
}
@inproceedings{Kaltenbrunner2000,
abstract = {This paper proposes that virtual environments that aim to support mutual presence for distributed work groups should allow for multiple partial presence. The introduction of teleworking, and the massive uptake of mobile phones have addressed a need for people to be virtually present (if not physically present) from many spatial locations. Conventional virtual environment systems, however, seem fixed to a notion of presence as being tied to being in a specific place. It is this view of VR that we have modified with collaborative working in mind. Specifically, we have extended a graphical Internet-based 3D world to allow for users to have multiple, proxy, avatars which provides a sense of partial presence in many locations in the virtual world, and/or in many different virtual worlds. Presence is now not tied to place, but to awareness of events. Users are connected to their proxies by audio cues, allowing for multiple locations to be attended to at once, creating a form of presence appropriate to the workplace.},
author = {Kaltenbrunner, Martin and Hagenberg, FH and Huxor, A},
booktitle = {Proc of the 3rd International Workshop on Presence},
pages = {14--18},
publisher = {Citeseer},
title = {{Multiple Presence through Auditory Bots in Virtual Environments}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.3180{\&}amp;rep=rep1{\&}amp;type=pdf},
year = {2000}
}
@article{Sheridan1992a,
author = {Sheridan, Thomas},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {120--126},
title = {{Musings on Telepresence and Virtual Presence}},
volume = {1},
year = {1992}
}
@article{Loomis1992a,
author = {Loomis, Jack M},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {113--119},
title = {{Distal Attribution and Presence}},
volume = {1},
year = {1992}
}
@article{Held1992,
author = {Held, Richard and Durlach, Nathaniel},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {109--112},
title = {{Telepresence}},
volume = {1},
year = {1992}
}
@article{Burdea1992,
author = {Burdea, Grigore and Zhuang, Jiachen and Roskos, Edward and Silver, Deborah and Langrana, Noshir},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {18--28},
title = {{A Portable Dextrous Master with Force Feedback}},
volume = {1},
year = {1992}
}
@article{Sheridan1992,
author = {Sheridan, Thomas and Furness, Thomas},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {iii},
title = {{Welcome to the New Journal}},
volume = {1},
year = {1992}
}
@article{Bishop1992,
author = {Bishop, Patricia},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {151},
title = {{"Beep"}},
volume = {1},
year = {1992}
}
@article{Naiman1992,
author = {Naiman, Alaric},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {145--148},
title = {{Presence, and Other Gifts or What Is Reality?, Why? Who Cares Anyway?}},
volume = {1},
year = {1992}
}
@article{Zeltzer1992,
author = {Zeltzer, David},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {127--132},
title = {{Autonomy, Interaction, and Presence}},
volume = {1},
year = {1992}
}
@article{Bateman2012,
abstract = {Virtual worlds (VWs) are powerful three-dimensional technologies where users can assume identities and interact with others. While designed as open-platforms for creativity, expression, and experimentation by recreational users, VWs were once lauded for their potential applications to business. Today, much of the business community has either moved on from the hype of VWs or struggles to understand whether value can be obtained by using VWs. This paper attempts to provide an understanding of these outcomes through the analysis of assessments written by 59 business professionals, who each spent an extended period of time in a popular VW during the peak of the hype. From these assessments, four broad perspectives on the value of VWs to organizations (or lack thereof) were identified, along with challenges facing use of VWs if they are to become more widely used within business.},
author = {Bateman, Patrick and Pike, Jacqueline and Berente, Nicholas and Hansen, Sean},
journal = {Journal of Virtual Worlds Research},
keywords = {Second Life,adoption,applications,benefits,business value,challenges,virtual worlds},
number = {3},
title = {{Time for a Post-Mortem?: Business Professionals’ Perspectives on the Disillusionment of Virtual Worlds}},
url = {http://journals.tdl.org/jvwr/index.php/jvwr/article/view/6324},
volume = {5},
year = {2012}
}
@inproceedings{Mautz2009,
abstract = {This paper gives an overview of the current and near future positioning capabilities for indoor environments with focus on the research activities in that field at the Institute of Geodesy and Photogrammetry at the ETH Zurich. Object of study are those novel indoor-position systems that have the potential to achieve cm-level accuracy or better which is seen as a requirement for most geodetic applications. The focus is given on four alternative positioning systems where the GeomETH group at the ETH Zurich has made some experiences. These systems are iGPS, which is a system based on a rotating infrared laser fan, the Locata system that uses GNSS similar signals on pseudolites, the cricket ultra-sound system and a photogrammetric laser beam positioning systems (CLIPS) that is currently under development. As a result it can be noted that there are several unconventional positioning systems on their way that may compensate for the deficiencies of GNSS or total stations.},
author = {Mautz, R},
booktitle = {2009 6th Workshop on Positioning Navigation and Communication},
doi = {10.1109/WPNC.2009.4907800},
isbn = {9781424432929},
keywords = {alternative novel positioning systems,future positioning scenarios,indoor positioning},
pages = {29--36},
publisher = {Ieee},
title = {{The challenges of indoor environments and specification on some alternative positioning systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4907800},
volume = {2009},
year = {2009}
}
@article{Collin2003,
author = {Collin, Jussi and Mezentsev, Oleg and Engineering, Geomatics},
pages = {1--7},
title = {{Indoor Positioning System Using Accelerometry and High Accuracy Heading Sensors}},
year = {2003}
}
@article{Schweinzer2010,
author = {Schweinzer, Herbert and Syafrudin, Mohammad},
isbn = {9781424458646},
number = {September},
pages = {15--17},
title = {{LOSNUS: An Ultrasonic System Enabling High Accuracy and Secure TDoA Locating of Numerous Devices}},
year = {2010}
}
@misc{Schweinzer2010a,
abstract = {This paper presents an indoor positioning system called LOSNUS (LOcalization of Sensor Nodes by Ultra-Sound). It offers high accuracy of {\~{}}10 mm, a locating rate up to {\~{}}10 cycles/s and is applicable for both tracking mobile and locating static devices. LOSNUS is mainly designed to localize static devices especially in a wireless sensor network (WSN) with numerously deployed sensor/actuator devices which enables substantially improving a lot of aspects of applications, e.g. network integration of nodes, supplying node locations to application programs, supervising locations with respect to accidentally dislocating, automatic setup and detecting faking of node locations. In order to deal with the demand of locating static devices, the system is optimized for cheap implementation and on the other hand for a high resolution of locations. Concept and basic operation, realization of system components and low-cost receiver principles, improved system performance and setup of a test system will be discussed in this paper.},
author = {Schweinzer, H and Syafrudin, M},
booktitle = {Indoor Positioning and Indoor Navigation IPIN 2010 International Conference on},
doi = {10.1109/IPIN.2010.5645819},
isbn = {9781424458622},
keywords = {indoor gps,one bit correlation,sequential locating,ultrasonic locating system},
pages = {1--8},
publisher = {IEEE},
title = {{LOSNUS: An ultrasonic system enabling high accuracy and secure TDoA locating of numerous devices}},
url = {http://ieeexplore.ieee.org/xpl/freeabs{\_}all.jsp?arnumber=5645819},
year = {2010}
}
@phdthesis{Joliat2013,
author = {Joliat, Nicholas},
school = {Massachusetts Institute of Technology},
title = {{DoppelLab: Spatialized Data Sonification in a 3D Virtual Environment}},
year = {2013}
}
@article{Claypool2006,
abstract = {Latency determines not only how players experience online gameplay but also how to design the games to mitigate its effects and meet player expectations.},
author = {Claypool, Mark and Claypool, Kajal},
doi = {10.1145/1167838.1167860},
issn = {00010782},
journal = {Communications of the ACM},
number = {11},
pages = {40},
publisher = {ACM},
title = {{Latency and player actions in online games}},
url = {http://portal.acm.org/citation.cfm?doid=1167838.1167860},
volume = {49},
year = {2006}
}
@incollection{Getchell2009,
author = {Getchell, K and Miller, A and Allison, C and Sweetman, R},
booktitle = {Serious Games on the Move},
pages = {165--180},
publisher = {Springer},
title = {{Exploring the Second Life of a Byzantine Basilica}},
year = {2009}
}
@inproceedings{Oliver2013,
author = {Oliver, Iain and Miller, Alan and Allison, Colin and Dow, Lisa and Campbell, Anne and Davies, CJ and McCaffery, John},
booktitle = {Proceedings of the 27th IEEE International Conference on Advanced Information Networking and Applications},
title = {{Towards the 3D Web with Open Simulator}},
year = {2013}
}
@inproceedings{Allison2012,
abstract = {The growth in the range of disciplines that Virtual Worlds support for educational purposes is evidenced by recent applications in the fields of cultural heritage, humanitarian aid, space exploration, virtual laboratories in the physical sciences, archaeology, computer science and coastal geography. This growth is due in part to the flexibility of OpenSim, the open source virtual world platform which by adopting Second Life protocols and norms has created a de facto standard for open virtual worlds that is supported by a growing number of third party open source viewers. Yet while this diversity of use-cases is impressive and Virtual Worlds for open learning are highly popular with lecturers and learners alike immersive education remains an essentially niche activity. This paper identifies functional challenges in terms of Management, Network Infrastructure, the Immersive 3D Web and Programmability that must be addressed to enable the wider adoption of Open Virtual Worlds as a routine learning technology platform. We refer to specific use-cases based on OpenSim and abstract generic requirements which should be met to enable the growth in use of Open Virtual Worlds as a mainstream educational facility. A case study of a deployment to support a formal education curriculum and associated informal learning is used to illustrate key points.},
author = {Allison, Colin and Campbell, Anne and Davies, C J and Dow, Lisa and Kennedy, Sarah and Miller, Alan and Oliver, Iain and Perera, Indika},
booktitle = {Proceedings of the 2nd European Immersive Education Summit EiED 2012},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allison et al. - 2012 - Growing the Use of Virtual Worlds in Education an OpenSim Perspective.pdf:pdf},
keywords = {education,muve,open simulator,virtual worlds,xmrm},
title = {{Growing the Use of Virtual Worlds in Education: an OpenSim Perspective}},
year = {2012}
}
@article{Chung2011,
abstract = {We present an indoor positioning system that measures location using disturbances of the Earth's magnetic field caused by structural steel elements in a building. The presence of these large steel members warps the geomagnetic field in a way that is spatially varying but temporally stable. To localize, we measure the magnetic field using an array of e-compasses and compare the measurement with a previously obtained magnetic map. We demonstrate accuracy within 1 meter 88{\%} of the time in experiments in two buildings and across multiple floors within the buildings. We discuss several constraint techniques that can maintain accuracy as the sample space increases.},
author = {Chung, Jaewoo and Donahoe, Matt and Schmandt, Chris and Kim, Ig-jae and Razavai, Pedram and Wiseman, Micaela},
doi = {10.1145/1999995.2000010},
isbn = {9781450306430},
journal = {System},
pages = {141--154},
publisher = {ACM Press},
title = {{Indoor Location Sensing Using Geo-Magnetism}},
url = {http://portal.acm.org/citation.cfm?doid=1999995.2000010},
year = {2011}
}
@inproceedings{Haverinen2009,
abstract = {Magnetic field fluctuations in modern buildings arise from both natural and man-made sources, such as steel and reinforced concrete structures, electric power systems, electric and electronic appliances, and industrial devices. If the anomalies of the magnetic field inside the building are nearly static and they have sufficient local variability, they provide a unique magnetic fingerprint that can be utilized in global self-localization. In this article, a Monte Carlo localization (MCL) technique based on this hypothesis is proposed. The feasibility of the technique is demonstrated by presenting a series of global localization experiments conducted in four arbitrarily selected buildings, including a hospital. The experiment setup consists of a mobile robot instrumented with a 3-axis magnetometer and a computer. In addition, successful human self-localization experiments were conducted by using a wireless wearable magnetometer. The reported experiments suggest that the ambient magnetic field may remain sufficiently stable for longer periods of time, giving support for self-localization techniques utilizing the local deviations of the field.},
author = {Haverinen, J and Kemppainen, A},
booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation (2009)},
doi = {10.1109/ROBOT.2009.5152885},
isbn = {9781424427888},
issn = {10504729},
pages = {3142--3147},
publisher = {Ieee},
title = {{A global self-localization technique utilizing local anomalies of the ambient magnetic field}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5152885},
year = {2009}
}
@article{Haverinen2009a,
abstract = {There is evidence that animals utilize local anomalities of Earths magnetic field not just for orientation detection but also for true navigation, i.e. , some animals are not only able to detect the direction of Earths magnetic field (compass heading), they are able to derive positional information from local cues arising from the local anomalities of Earths magnetic field. Similarly to Earths non-constant magnetic field, the magnetic field inside buildings can be highly non-uniform. The magnetic field fluctuations inside buildings arise from both natural and man-made sources, such as steel and reinforced concrete structures, electric power systems, electric and electronic appliances, and industrial devices. Assuming the anomalities of the magnetic field inside a building are nearly static and they have sufficient local variability, the anomalies provide a unique magnetic fingerprint that can be utilized in global self-localization. Based on the evidence presented in this article it can be argued that this hypothesis is valid. In this article, a Monte Carlo Localization (MCL) technique based on the above hypothesis is proposed. The feasibility of the technique is demonstrated by presenting a series of global self-localization experiments conducted in four arbitrarily selected buildings, including a hospital. The experiment setup consists of a mobile robot instrumented with a 3-axis magnetometer and a computer. In addition to global robot self-localization experiments, successful person self-localization experiments were also conducted by using a wireless, wearable magnetometer. The reported experiments suggest that the ambient magnetic field may remain sufficiently stable for longer periods of time giving support for self-localization techniques utilizing the local deviations of the magnetic field.},
author = {Haverinen, Janne and Kemppainen, Anssi},
doi = {10.1016/j.robot.2009.07.018},
isbn = {9781424427895},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {monte carlo localization},
number = {10},
pages = {1028--1035},
publisher = {Elsevier B.V.},
title = {{Global indoor self-localization based on the ambient magnetic field}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889009001092},
volume = {57},
year = {2009}
}
@inproceedings{Fujimoto2011,
author = {Fujimoto, M and Nakamori, E and Inada, A and Oda, Y and Wada, T and Mutsuura, K and Okada, H},
booktitle = {Proceedings of the 2011 International Conference on Indoor Positioning and Indoor navigation (IPIN)},
title = {{A Broad-Typed Multi-Sensing-Range Metehod for Indoor Position Estimation of Passive RFID Tags}},
year = {2011}
}
@phdthesis{Mautz2012,
author = {Mautz, Rainer},
pages = {127},
school = {ETH Zurich},
title = {{Indoor Positioning Technologies}},
year = {2012}
}
@inproceedings{Kuck,
author = {Kuck, R and Wind, J and Riege, K and Bogen, M},
title = {{Improving the AVANGO VR/AR Framework - Lessons Learned}}
}
@inproceedings{Kulik2011,
author = {Kulik, Alexander and Kunert, Andr{\'{e}} and Beck, Stephan and Reichel, Roman and Blach, Roland and Zink, Armin and Froehlich, Bernd},
booktitle = {Proceedings of the 2011 SIGGRAPH Asia Conference},
title = {{C1x6: A Stereoscopic Six-User Display for Co-located Collaboration in Shared Virtual Environments}},
year = {2011}
}
@article{Friedmann1992,
author = {Friedmann, M and Starner, T and Pentland, A},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {139 -- 144},
title = {{Synchronization in Virtual Realities}},
volume = {1},
year = {1992}
}
@article{Bates1992,
author = {Bates, Joseph},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {133 -- 138},
title = {{Virtual Reality, Art and Entertainment}},
volume = {1},
year = {1992}
}
@article{Loomis1992,
author = {Loomis, Jack},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {113 -- 119},
title = {{Distal Attribution and Presence}},
volume = {1},
year = {1992}
}
@inproceedings{Sutherland1965,
author = {Sutherland, Ivan},
booktitle = {Proceedings of IFIP Congress},
pages = {506--508},
title = {{The Ultimate Display}},
year = {1965}
}
@article{Appino1992,
abstract = {This paper presents a system architecture for creating interactive, multisensory, three-dimensional environments called virtual worlds. The architecture specifically addresses the requirements of virtual worlds for high performance, flexibility, and coordination of concurrent events. Performance is enhanced by a distributed client/server system structure and by efficient overlap of processing time and input/output delay. All processes communicate via asynchronous messages. The functional partitioning of a virtual world requires relatively low bandwidth among the individual processes and the system can be implemented over a conventional local-area network. A key element of this architecture is a central, event-driven dialogue manager which coordinates concurrent input and output events. The dialogue manager provides a clear separation of the interaction techniques from the content of the virtual world as defined by the application. The system is flexible and easily reconfigurable. An interaction technique can be readily changed or replaced because each interaction device is modularized into a separate server and each interaction modality into a separate subdialogue. Subdialogues can be loaded and dropped dynamically, enabling input/output device remapping and the selection of interaction techniques while a virtual world is running. As an initial test of this architecture we have implemented a virtual world for interacting with data from a computational fluid dynamics simulation.},
author = {Appino, Perry A and Lewis, J Bryan and Koved, Lawrence and Ling, Daniel T and Rabenhorst, David A and Codella, Christopher F},
issn = {10547460},
journal = {Presence: Teleoperators and Virtual Environments},
number = {1},
pages = {1--17},
publisher = {MIT Press},
title = {{An architecture for virtual worlds}},
url = {http://www.research.ibm.com/people/k/koved/papers/rc16446.html},
volume = {1},
year = {1992}
}
@article{Minsky1980,
author = {Minsky, Marvin},
journal = {Omni Magazine},
title = {{Telepresence}},
year = {1980}
}
@article{Klatzky1998,
abstract = {Two studies investigated updating of self-position and heading during real, imagined, and simulated locomotion. Subjects were exposed to a two-segment path with a turn between segments; they responded by turning to face the origin as they would if they had walked the path and were at the end of the second segment. The conditions of pathway exposure included physical walking, imagined walking from a verbal description, watching another person walk, and experiencing optic flow that simulated walking, with or without a physical turn between the path segments. If subjects failed to update an internal representation of heading, but did encode the pathway trajectory, they should have overturned by the magnitude of the turn between the path segments. Such systematic overturning was found in the description and watching conditions, but not with physical walking. Simulated optic flow was not by itself sufficient to induce spatial updating that supported correct turn responses.},
author = {Klatzky, Roberta L and Loomis, Jack M and Beall, Andrew C and Chance, Sarah S and Golledge, Reginald G},
doi = {10.1111/1467-9280.00058},
issn = {09567976},
journal = {Psychological Science},
number = {4},
pages = {293--298},
publisher = {Blackwell Publishing on behalf of the Association for Psychological Science},
title = {{Spatial updating of self-position and orientation during real, imagined, and virtual locomotion}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/1467-9280.00058},
volume = {9},
year = {1998}
}
@article{Beck2013,
author = {Beck, Stephan and Kunert, Andr{\'{e}} and Kulik, Alexander and Froehlich, Bernd},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {4},
title = {{Immersive Group-to-Group Telepresence}},
volume = {19},
year = {2013}
}
@article{Witmer1998,
abstract = {The effectiveness of virtual environments (VEs) has often been linked to the sense of presence reported by users of those VEs. (Presence is defined as the subjective experience of being in one place or environment, even when one is physically situated in another.) We believe that presence is a normal awareness phenomenon that requires directed attention and is based in the interaction between sensory stimulation, environmental factors that encourage involvement and enable immersion, and internal tendencies to become involved. Factors believed to underlie presence were described in the premier issue of Presence: Teleoperators and Virtual Environments. We used these factors and others as the basis for a presence questionnaire (PQ) to measure presence in VEs. In addition we developed an immersive tendencies questionnaire (ITQ) to measure differences in the tendencies of individuals to experience presence. These questionnaires are being used to evaluate relationships among reported presence and other research variables. Combined results from four experiments lead to the following conclusions: the PQ and ITQ are internally consistent measures with high reliability; there is a weak but consistent positive relation between presence and task performance in VEs; individual tendencies as measured by the ITQ predict presence as measured by the PQ; and individuals who report more simulator sickness symptoms in VE report less presence than those who report fewer symptoms.},
author = {Witmer, Bob G and Singer, Michael J},
doi = {10.1162/105474698565686},
institution = {U.S. Army Research Institute for the Behavioral and Social Sciences},
isbn = {1011621054},
issn = {10547460},
journal = {Presence: Teleoperators and Virtual Environments},
number = {3},
pages = {225--240},
publisher = {MIT Press},
title = {{Measuring Presence in Virtual Environments: A Presence Questionnaire}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/105474698565686},
volume = {7},
year = {1998}
}
@article{Slater1999,
abstract = {Explains why for not using the Witmer and Singer questionnaire for eliciting presence in virtual environments and a person's immersive tendencies. Differences in the definition of presence; Three aspects of presence; Factors that influence presence; Opinion on the questionnaire's design and methodology.},
author = {Slater, M},
journal = {Presence: Teleoperators and Virtual Environments},
keywords = {virtual environments},
number = {5},
pages = {560--565},
publisher = {M I T PRESS},
title = {{Measuring presence: A response to the Witmer and Singer presence questionnaire}},
url = {http://discovery.ucl.ac.uk/136732/},
volume = {8},
year = {1999}
}
@inproceedings{Maimone2013,
author = {Maimone, Andrew and Yang, Xubo and Dierk, Nate and State, Andrei and Dou, Minsong and Fuchs, Henry},
booktitle = {IEEE Virtual Reality 2013},
title = {{General-Purpose Telepresence with Head-Worn Optical See-Through Displays and Projector-Based Lighting}},
year = {2013}
}
@article{Cirio2013,
author = {Cirio, Gabriel and Olivier, Anne-H{\'{e}}l{\`{e}}ne and Marchal, Maud and Pettr{\'{e}}, Julien},
doi = {10.1109/TVCG.2013.34},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {4},
title = {{Kinematic Evaluation of Virtual Walking Trajectories}},
volume = {19},
year = {2013}
}
@article{Hodgson2012,
author = {Hodgson, Eric and Bachmann, Eric},
doi = {10.1109/TVCG.2013.28},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {4},
title = {{Comparing Four Approaches to Generalized Redirected Walking: Simulation and Live User Data}},
volume = {19},
year = {2012}
}
@book{Fielding2008,
editor = {Fielding, Nigel and Lee, Raymond and Blank, Grant},
isbn = {978-1412922937},
pages = {592},
publisher = {SAGE Publications Ltd},
title = {{The SAGE Handbook of Online Research Methods}},
year = {2008}
}
@misc{Lombard1997,
abstract = {A number of emerging technologies including virtual reality, simulation rides, video conferencing, home theater, and high definition television are designed to provide media users with an illusion that a mediated experience is not mediated, a perception defined here as presence. Traditional media such as the telephone, radio, television, film, and many others offer a lesser degree of presence as well. This article examines the key concept of presence. It begins by noting practical and theoretical reasons for studying this concept. Six conceptualizations of presence found in a diverse set of literatures are identified and a detailed explication of the concept that incorporates these conceptualizations is presented. Existing research and speculation about the factors that encourage or discourage a sense of presence in media users as well as the physiological and psychological effects of presence are then outlined. Finally, suggestions concerning future systematic research about presence are presented.},
author = {Lombard, M and Ditton, T},
booktitle = {Journal of Computer-Mediated Communication},
doi = {10.1093/cid/cir583},
issn = {10836101},
number = {2},
pages = {20},
pmid = {22045961},
publisher = {Wiley Online Library},
title = {{At The Heart of It All The Concept of Presence.pdf}},
url = {http://jcmc.indiana.edu/vol3/issue2/lombard.html},
volume = {3},
year = {1997}
}
@misc{Lifton2009a,
author = {Lifton, Joshua},
publisher = {Meta Institute for Computational Astrophysics (MICA)},
title = {{Trends, Dual Reality, and Identity in Virtual Worlds}},
url = {http://dspace.mit.edu/openaccess-disseminate/1721.1/61991},
year = {2009}
}
@misc{OpenVirtualWorldsgroupSchoolofComputerScience,
author = {{Open Virtual Worlds group, School of Computer Science}, University of St Ancrews},
title = {{Registration page for Open Virtual Worlds group OpenSim grid}},
url = {http://virtualworlds.cs.st-andrews.ac.uk/cathedral/login.php},
urldate = {2013-04-01}
}
@misc{Davies,
author = {Davies, C J},
title = {{Arduino sketch for Pangolin}},
url = {https://bitbucket.org/cj{\_}davies/arduino{\_}hmc6434{\_}ublox{\_}max{\_}6{\_}tinygps},
urldate = {2013-04-01}
}
@misc{Daviesa,
author = {Davies, C J},
title = {{Pangolin source code}},
url = {https://bitbucket.org/cj{\_}davies/viewer-release-serial-io},
urldate = {2013-04-01}
}
@misc{Daviesb,
author = {Davies, C J},
title = {{Database as tar archive suitable for input into pg{\_}restore}},
url = {http://straylight.cs.st-andrews.ac.uk/cj{\_}davies{\_}psql{\_}db{\_}tar{\_}for{\_}pg{\_}restore},
urldate = {2013-04-01}
}
@misc{Daviesc,
author = {Davies, C J},
title = {{Database as plain-text SQL script file}},
url = {http://straylight.cs.st-andrews.ac.uk/cj{\_}davies{\_}psql{\_}db{\_}sql{\_}plaintext},
urldate = {2013-04-01}
}
@inproceedings{Kennedy2012,
abstract = {Abstract. St Andrews Cathedral is located on the East Coast of Scotland, construc- tion started in 1160 and spanned Romanesque and Gothic architectural styles. It was consecrated in 1318, four years after the battle of Bannockburn in the pres- ence of King Robert the Bruce. For several hundred years, the Cathedral was one of the most important religious buildings in Europe and the centre of religious life in Scotland. During the Scottish Reformation, John Knox lead reformers in divesting the Cathedral of much of its finery. Thereafter it fell into disuse and decline. Today the impressive remains only hint at the former glory of this important building. Cultural Heritage encompasses physical aspects such as architecture and arti- facts along with less tangible culture such as music, songs and stories. Open virtual worlds offer an extensible collaborative environment for developing historic scenes against the background of which material and ephemeral aspects of cultural her- itage associated with a site may be explored through engagement with historic nar- ratives. They offer the potential to reconstruct within a 3D computer environment both the physical structures of the past and important aspects of the light, music and life that once filled those structures. Virtual reconstructions enable scenarios to be created where individual pieces of art can be located and appreciated within the audio, visual and spacial contexts for which they were originally created. Bringing together architecture, sculpture, illumination, stained-glass, music, procession and lighting into a scene which can be explored from multiple spatial perspectives en- ables holistic experience and appreciation. Historic reconstructions may be created upon virtual stages allowing new and engaging Cultural Heritage perspectives to be accessible to diverse audiences. Through the example of St Andrews Cathedral reconstruction this paper presents an example of Open Virtual Worlds as a technology for supporting the creation and use of virtual reconstructions as a platform that promotes understanding of and engagement with Cultural Heritage. The use contexts discussed range from research based exploration of 3D spaces, to primary schools students using the reconstructions as a backdrop for tag. The digital literacies of the audience and goals of the use case impact on the appropriateness of the user interface. A range of interfaces are explored including games controllers, touch screens, tablets that provide location aware views into the model and hands free gesture control systems.},
author = {Kennedy, Sarah and Dow, Lisa and Oliver, Iain Angus and Sweetman, Rebecca Jane and Miller, Alan Henry David and Campbell, Anne and Davies, Christopher John and McCaffery, John Philip and Allison, Colin and Green, Daryl and Luxford, Julian Marcus and Fawcett, Richard},
booktitle = {Proceedings of the 2nd European Immersive Education Summit EiED 2012},
editor = {Gardner, Michael and Garnier, Fran{\c{c}}ois and Kloos, Carlos Delgado},
isbn = {8469564277},
keywords = {cultural heritage,narrative,qa76 computer software,virtual reconstruction,virtual worlds},
pages = {146--160},
publisher = {Universidad Carlos III de Madrid, Departamento de Ingenier{\'{\i}}a Telem{\'{a}}tica , Madrid, Spain},
title = {{Living history with Open Virtual Worlds: Reconstructing St Andrews Cathedral as a stage for historic narrative}},
url = {http://hdl.handle.net/10023/3332},
year = {2012}
}
@misc{Hart,
author = {Hart, Mikal},
title = {{TinyGPS}},
url = {http://arduiniana.org/libraries/tinygps/},
urldate = {2013-04-01}
}
@misc{Google2012a,
author = {Google},
title = {{My Tracks - Android Apps on Google Play}},
year = {2012}
}
@misc{Harta,
author = {Hart, Mikal},
title = {{TinyGPS}},
url = {http://arduiniana.org/libraries/tinygps/},
urldate = {2013-03-31}
}
@misc{Google2012,
author = {Google},
title = {{My Tracks - Android Apps on Google Play}},
url = {https://play.google.com/store/apps/details?id=com.google.android.maps.mytracks{\&}hl=en},
urldate = {2012-03-28},
year = {2012}
}
@misc{U-bloxAGa,
author = {u-blox AG},
title = {{u-center GPS evaluation software}},
url = {http://www.u-blox.com/en/evaluation-tools-a-software/u-center/u-center.html},
urldate = {2012-03-28}
}
@misc{QualcommIncorporated2013,
author = {{Qualcomm Incorporated}},
title = {{Snapdragon Processors | QUalcomm}},
url = {http://www.qualcomm.eu/uk/products/snapdragon},
urldate = {2013-03-28},
year = {2013}
}
@misc{HTCCorporation2013,
author = {{HTC Corporation}},
title = {{HTC One S Overview - HTC Smartphones}},
url = {http://www.htc.com/www/smartphones/htc-one-s/},
urldate = {2013-03-28},
year = {2013}
}
@misc{U-bloxAG2012,
author = {u-blox AG},
title = {{MAX-6 Product Summary}},
url = {http://www.u-blox.com/images/downloads/Product{\_}Docs/MAX-6{\_}ProductSummary{\_}(GPS.G6-HW-10089).pdf},
year = {2012}
}
@book{Gellert1989,
address = {New York},
author = {Gellert, W and Gottwald, M and Hellwich, H and K{\"{a}}stner, H and K{\"{u}}stner, H},
edition = {2},
publisher = {Van Nostrand Reinhold},
title = {{The VNR Concise Encyclopedia of Mathematics}},
year = {1989}
}
@book{Bartle2004,
abstract = {Designing Virtual Worlds is the most comprehensive treatment of virtual worlddesign to-date from one of the true pioneers and most sought-after design consultants. It's a tour de force of VW design, stunning in intellectual scope, spanning the literary,economic, sociological, psychological, physical, technological, and ethicalunderpinnings of design, while providing the reader with a deep, well-grounded understanding of VW design principles. It covers everything from MUDs to MOOs to MMORPGs, from text-based to graphical VWs.Designing Virtual Worlds brings a rich, well-developed approach to the designconcepts behind virtual worlds. It is grounded in the earliest approaches to such designs, but the examples discussed in the book run the gamut from the earliest MUDs to the present-day MMORPG games mentioned above. It teaches the reader the actual, underlying design principles that many designers do not understand when they borrow or build from previous games. There is no other design book on the market in the area of online games and virtual worlds that provides the rich detail, historical context, and conceptual depth ofDesigning Virtual Worlds.},
author = {Bartle, Richard},
chapter = {34},
doi = {10.1093/carcin/bgs054},
editor = {Reiser, Robert A and Dempsey, John V},
institution = {Texas State Techincal College},
isbn = {0131018167},
issn = {14602180},
number = {3},
pages = {741},
pmid = {22383472},
publisher = {New Riders Games},
series = {New Riders Games Series},
title = {{Designing Virtual Worlds}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20{\&}amp;path=ASIN/0131018167},
volume = {p},
year = {2004}
}
@book{Gelernter1993,
author = {Gelernter, David},
isbn = {978-0195079067},
pages = {256},
title = {{Mirror Worlds: or the Day Software Puts the Universe in a Shoebox...How It Will Happen and What It Will Mean}},
year = {1993}
}
@misc{Applin2012a,
author = {Applin, Sally and Fischer, Michael and Walker, Kevin},
title = {{Visualising PolySocial Reality}},
url = {http://jitso.org/2012/12/03/visualising-polysocial-reality-revised/},
urldate = {2013-02-21},
year = {2012}
}
@misc{Accenture2012,
author = {Accenture},
title = {{Mobile Web Watch Internet Usage Survey 2012}},
url = {http://www.accenture.com/SiteCollectionDocuments/PDF/Accenture-Mobile-Web-Watch-Internet-Usage-Survey-2012.pdf},
urldate = {2013-04-01}
}
@misc{Applin2011b,
author = {Applin, Sally and Council},
title = {{Council Interview with Sally Applin}},
url = {http://www.theinternetofthings.eu/content/council-interview-sally-applin},
urldate = {2013-02-13},
year = {2011}
}
@article{Applin2012,
abstract = {The technology industry has evolved over the years with a development lens increasingly focused on end users and usage cases. Indeed, for the past decade or more, personas (the designer-created profiles of end users) have become stand-ins for various usage cases and user models. With regard to location aware software and mobile applications, the usage of Dual Reality and Mixed Reality as metaphors have functioned in a similar vein. Just as personas are not people, Mixed and Dual Reality do not fully represent or address the complex usage cases developing as more people do more things, with more software at more times and in more spaces than ever before. This new complex application ecosystem presents greater opportunities and challenges for application design. We discuss ways that developers can use PolySocial Reality (PoSR) to represent a more complete complex structural model},
author = {Applin, Sally A},
journal = {Policy},
number = {February},
title = {{PolySocial Reality : Prospects for Extending User Capabilities Beyond Mixed , Dual and Blended Reality}},
url = {http://www.dfki.de/LAMDa/2012/accepted/PolySocial{\_}Reality.pdf},
year = {2012}
}
@article{Applin2011a,
abstract = {We consider some possible broad changes that may impact society as a whole as a result of widespread integration of full-spectrum deployed pervasive computing technologies. Our approach considers design challenges for successfully developing and integrating pervasive technologies into culture and society. This is particularly challenging, since pervasive technologies as services are most successful when transparent, invisible, overlooked, unacknowledged and seemingly forgotten by the very groups that embrace their usage and development. We suggest a heuristic for understanding pervasive technology from an anthropological/social perspective, along with a reminder that humans create, shape and use the technologies that affect them. In particular, we look at the impact on social relations in a poly-social world where people must develop means to blend their own realities with those of of others. In conclusion, we remind those developing these technologies, that although we will eventually become wedded and intertwined as cyborgs within this new environment, it may have a positive outcome, creating new social group models for human interaction.},
author = {Applin, Sally A and Fischer, M D},
journal = {2011 Seventh International Conference on Intelligent Environments},
keywords = {gn anthropology,qa76.9.h85 human computer interaction},
pages = {285--293},
publisher = {IEEE},
title = {{Pervasive Computing in Time and Space: The Culture and Context of 'Place' Integration}},
url = {http://dx.doi.org/doi:10.1109/IE.2011.65},
year = {2011}
}
@article{Applin2011,
abstract = {Contribute to the workshop with our understanding of humans, culture and group behavior and to learn from others what type of group behavior is expected as new technologies and their subsequent experiences are created for human use. When we discuss human group behavior, we refer to the definition of a social group: a collection of humans who repeatedly interact within a system. Humans can, and do switch context between environments and blend traces of one into the other in a socially unconscious manner often seemingly simultaneously. We propose that the cultures and behaviors of humans are increasingly actively permeating Internet and network- based applications, as well as those that are geolocal. With the future Internet of things, Dual Reality and Mixed Reality, the opportunity for humans to extend their own blended reality, as well as to create new ones is unfolding. That said, because humans interact within groups, the multiplexing of their mutual blended realities rapidly creates a PoSR. Sorting out the relationships between realities as well as between synchronous and asynchronous time and geolocal space can create a condition where realities are simultaneous and the idea of 'x' can be perceived as equaling 'not x.' We explore this new type of interoperability between virtual and physical, ideational and material, representations and objects and culture.},
author = {Applin, Sally A},
journal = {Policy},
number = {February},
pages = {11--14},
title = {{A Cultural Perspective on Mixed , Dual and Blended Reality}},
url = {http://www.anthropunk.com/xwiki/wiki/anthropunk/download/Main/WebHome/ACulturalPerspectiveApplinFischer.pdf},
year = {2011}
}
@misc{Gu2009,
abstract = {Recently, indoor positioning systems (IPSs) have been designed to provide location information of persons and devices. The position information enables location-based protocols for user applications. Personal networks (PNs) are designed to meet the users' needs and interconnect users' devices equipped with different communications technologies in various places to form one network. Location-aware services need to be developed in PNs to offer flexible and adaptive personal services and improve the quality of lives. This paper gives a comprehensive survey of numerous IPSs, which include both commercial products and research-oriented solutions. Evaluation criteria are proposed for assessing these systems, namely security and privacy, cost, performance, robustness, complexity, user preferences, commercial availability, and limitations.We compare the existing IPSs and outline the trade-offs among these systems from the viewpoint of a user in a PN.},
author = {Gu, Yanying Gu Yanying and Lo, A and Niemegeers, I},
booktitle = {IEEE Communications Surveys Tutorials},
doi = {10.1109/SURV.2009.090103},
issn = {1553877X},
keywords = {indoor positioning systems,location techniques,personal networks},
number = {1},
pages = {13--32},
publisher = {IEEE},
title = {{A survey of indoor positioning systems for wireless personal networks}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4796924},
volume = {11},
year = {2009}
}
@unpublished{IndoorAtlasLtd.2012,
author = {{IndoorAtlas Ltd.}},
pages = {5},
title = {{Ambient magnetic field-based indoor location technology}},
url = {http://web.indooratlas.com/web/WhitePaper.pdf},
year = {2012}
}
@misc{IndoorAtlasLtd.,
author = {{IndoorAtlas Ltd.}},
title = {{Technology}},
url = {http://www.indooratlas.com/Technology},
urldate = {2013-02-11}
}
@misc{Sonitor,
author = {Sonitor},
title = {{Enabling Technology}},
url = {http://www.sonitor.com/technology/enabling-technology},
urldate = {2013-02-11}
}
@misc{Sarantel,
author = {Sarantel},
title = {{SL1200}},
url = {http://www.sarantel.com/products/sl1200},
urldate = {2013-02-11}
}
@misc{U-bloxAG,
author = {u-blox AG},
title = {{MAX-6 series}},
url = {http://www.u-blox.com/en/gps-modules/pvt-modules/max-6.html},
urldate = {2013-02-11}
}
@misc{AzureWave,
author = {AzureWave},
title = {{GPS-M16}},
url = {http://www.azurewave.com/product{\_}GPS-M19{\_}1.asp},
urldate = {2013-02-11}
}
@book{Castronova2006,
author = {Castronova, Edward},
isbn = {0226096270},
pages = {344},
publisher = {University of Chicago Press},
title = {{Synthetic Worlds: The Business and Culture of Online Games}},
year = {2006}
}
@misc{Parris2007,
author = {Parris, Colin},
booktitle = {MIT Technology Review},
title = {{Building an Immersive Web}},
url = {http://www.technologyreview.com/notebook/408168/building-an-immersive-web/},
urldate = {2013-01-31},
year = {2007}
}
@book{Munkres2000,
author = {Munkres, James},
edition = {2},
pages = {537},
title = {{Topology}},
year = {2000}
}
@misc{PostGIS,
author = {PostGIS},
booktitle = {PostGIS 2.0.2 Manual},
title = {{ST{\_}HausdorffDistance}},
url = {http://www.postgis.org/docs/ST{\_}HausdorffDistance.html},
urldate = {2013-01-29}
}
@unpublished{InstituteofElectricalandElectronicsEngineers2012,
author = {{Institute of Electrical and Electronics Engineers}},
title = {{IEEE P1828/D1 Draft Trial-Use Standard for Systems with Virtual Components}},
url = {http://www.metaversestandards.org/1828{\_}draft.doc},
year = {2012}
}
@misc{IEEE,
author = {IEEE},
title = {{IEEE VW Standard Working Group}},
url = {http://www.metaversestandards.org/index.php?title=Main{\_}Page},
urldate = {2012-06-05}
}
@phdthesis{Clark-Casey2010,
author = {Clark-Casey, Justin},
school = {Oxford},
title = {{Scaling OpenSimulator: An Examination of Possible Architectures for an Internet-Scale Virtual Environment Network}},
url = {http://justincc.org/downloads/docs/justincc-dissertation.pdf},
year = {2010}
}
@misc{EpicGames,
author = {{Epic Games}},
title = {{Game Engine Technology by Unreal}},
url = {http://www.unrealengine.com/},
urldate = {2012-05-31}
}
@phdthesis{Dublon2011a,
author = {Dublon, Gershon},
school = {Massachusetts Institute of Technology},
title = {{Beyond the Lens: Communicating Context through Sensing, Video and Visualization}},
year = {2011}
}
@misc{Dublon2011,
abstract = {We present DoppelLab, an immersive sensor data browser built on a 3-d game engine. DoppelLab unifies independent sensor networks and data sources within the spatial framework of a building. Animated visualizations and sonifications serve as representations of real-time data within the virtual space.},
author = {Dublon, Gershon and Pardue, Laurel S and Mayton, Brian and Swartz, Noah and Joliat, Nicholas and Hurst, Patrick and Paradiso, Joseph A},
booktitle = {2011 IEEE SENSORS Proceedings},
doi = {10.1109/ICSENS.2011.6126903},
institution = {Responsive Environments Group, MIT Media Lab, Cambridge, MA 02139, USA},
isbn = {9781424492886},
issn = {19300395},
pages = {1612--1615},
publisher = {IEEE},
title = {{DoppelLab: Tools for exploring and harnessing multimodal sensor network data}},
year = {2011}
}
@misc{Mason2007,
abstract = {In the second part of this report, Newsnight correspondent Paul Mason continues his search for the soul of cyberspace.},
author = {Mason, Paul},
booktitle = {BBC News Technology},
title = {{Searching for the soul of cyberspace}},
url = {http://news.bbc.co.uk/1/hi/technology/6251585.stm},
urldate = {2012-05-21},
year = {2007}
}
@misc{Hughes2009,
author = {Hughes, Ian},
title = {{Wimbledon – A fanployee perspective}},
url = {http://www.feedingedge.co.uk/blog/2009/06/15/wimbledon-a-fanployee-perspective/},
urldate = {2012-05-21},
year = {2009}
}
@misc{Hughes2006c,
author = {Hughes, Ian},
title = {{Wimbledon in Second Life}},
url = {http://eightbar.co.uk/2006/06/27/wimbledon-in-second-life/},
urldate = {2012-05-21},
year = {2006}
}
@misc{Life2006,
abstract = {IBM is embracing the virtual world of avatars--and other big companies are close behind},
author = {Life, Palmisano Gets A Second},
booktitle = {Bloomberg Businessweek},
title = {{Palmisano Gets A Second Life}},
url = {http://www.businessweek.com/magazine/content/06{\_}47/b4010068.htm?chan=tc{\&}chan=technology{\_}technology+index+page{\_}today's+top+stories},
urldate = {2012-05-21},
year = {2006}
}
@misc{Hughes2006,
author = {Hughes, Ian},
title = {{Lessons from second life}},
url = {http://eightbar.co.uk/2006/04/22/lessons-from-second-life/},
year = {2006}
}
@misc{Hughes2006a,
author = {Hughes, Ian},
title = {{Second Life – Outside in}},
url = {http://eightbar.co.uk/2006/04/09/second-life-outside-in/},
urldate = {2012-05-21},
year = {2006}
}
@misc{Hughes2006b,
author = {Hughes, Ian},
title = {{Well it got my attention – Second Life}},
url = {http://eightbar.co.uk/2006/04/04/well-it-got-my-attention-second-life/},
urldate = {2012-05-21},
year = {2006}
}
@article{King2008,
author = {King, Rita J},
doi = {10.2167/new304.0},
institution = {IBM},
journal = {New Writing},
number = {1},
pages = {80--86},
title = {{From the Fire Pit}},
volume = {3},
year = {2008}
}
@article{Mittal2011,
author = {Mittal, Manas and Paradiso, Joseph A},
doi = {10.1109/JSEN.2010.2081976},
issn = {1530437X},
journal = {Ieee Sensors Journal},
number = {3},
pages = {818--828},
title = {{Ubicorder: A Mobile Device for Situated Interactions With Sensor Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5590279},
volume = {11},
year = {2011}
}
@misc{ResponsiveEnvironmentsGroup,
author = {{Responsive Environments Group}},
title = {{Responsive Environments Group - Research Themes}},
url = {http://resenv.media.mit.edu/motto.html},
urldate = {2012-05-18}
}
@phdthesis{LaPenta2007,
author = {LaPenta, Jason},
school = {Massachusetts Institute of Technology},
title = {{Real-time 3-d Localization using Radar and Passive Surface Acoustic Wave Transponders}},
url = {http://www.media.mit.edu/resenv/pubs/theses/j.lapenta.ms.thesis.pdf},
year = {2007}
}
@article{Laibowitz2005,
author = {Laibowitz, Mathew and Paradiso, Joseph A},
doi = {10.1007/11428572{\_}16},
editor = {Gellersen, Hans and Want, Roy and Schmidt, Albrecht},
isbn = {9783540260080},
journal = {Pervasive Computing},
pages = {255 -- 278},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Parasitic Mobility for Pervasive Sensor Networks}},
url = {http://www.springerlink.com/index/xet6u0rf34h1k94g.pdf},
volume = {3468},
year = {2005}
}
@article{Bamberg2008,
abstract = {We describe a wireless wearable system that was developed to provide quantitative gait analysis outside the confines of the traditional motion laboratory. The sensor suite includes three orthogonal accelerometers, three orthogonal gyroscopes, four force sensors, two bidirectional bend sensors, two dynamic pressure sensors, as well as electric field height sensors. The "GaitShoe" was built to be worn in any shoe, without interfering with gait and was designed to collect data unobtrusively, in any environment, and over long periods. The calibrated sensor outputs were analyzed and validated with results obtained simultaneously from the Massachusetts General Hospital, Biomotion Laboratory. The GaitShoe proved highly capable of detecting heel-strike and toe-off, as well as estimating foot orientation and position, inter alia.},
author = {Bamberg, Stacy J Morris and Benbasat, Ari Y and Scarborough, Donna Moxley and Krebs, David E and Paradiso, Joseph A},
institution = {Massachusetts Institute of Technology (MIT) , Cambridge, MA 02139, USA. sjm@alum.mit.edu},
journal = {IEEE transactions on information technology in biomedicine a publication of the IEEE Engineering in Medicine and Biology Society},
keywords = {ambulatory,ambulatory instrumentation,equipment design,equipment failure analysis,gait,gait physiology,humans,manometry,manometry instrumentation,monitoring,shoes,systems integration,telemetry,telemetry instrumentation},
number = {4},
pages = {413--423},
pmid = {18632321},
publisher = {IEEE},
title = {{Gait analysis using a shoe-integrated wireless sensor system.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18632321},
volume = {12},
year = {2008}
}
@inproceedings{Richardson2004,
address = {New York, New York, USA},
author = {Richardson, Bruce and Leydon, Krispin and Fernstrom, Mikael and Paradiso, Joseph A.},
booktitle = {Extended abstracts of the 2004 conference on Human factors and computing systems - CHI '04},
doi = {10.1145/985921.986107},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Richardson et al. - 2004 - Z-Tiles.pdf:pdf},
isbn = {1581137036},
keywords = {blob detection,foot sensing,networked floorspace,pressure-sensitive,responsive environments,self-organising},
month = {apr},
pages = {1529},
publisher = {ACM Press},
title = {{Z-Tiles}},
url = {http://dl.acm.org/citation.cfm?id=985921.986107},
year = {2004}
}
@article{Ma2002,
abstract = {We have designed an active tagging system that responds to a coded optical beam from several meters away. The tags contain a minimalist microprocessor that ambiently operates in shutdown mode and, upon detecting particular frequency components in the AM-modulated interrogation beam, awakens to decode the incident digital message and produce an appropriate response. The lack of linear amplifiers means that these tags draw under 0.5 $\mu$A when sleeping, hence can operate up to 10 years on a lithium coin cell. Such devices are practical demonstrations of the potential of ubiquitous computing where common, nearly passive objects have a sense of identity and the ability to respond to external stimuli. In our example, the interrogator is a flashlight, with which one scans an area; when the light beam hits a tag programmed with a code that matches that sent by the interrogator, an on-tag LED flashes, indicating that the desired object is found.},
author = {Ma, Hongshen and Paradiso, J},
doi = {10.1007/3-540-45809-3{\_}12},
editor = {Borriello, G and Holmquist, L E},
journal = {UbiComp 2002 Ubiquitous Computing},
pages = {1--8},
publisher = {Springer},
title = {{The FindIT Flashlight : Responsive Tagging Based on Optically Triggered Microprocessor Wakeup}},
url = {http://www.springerlink.com/index/JX2DL0YK396DPHEJ.pdf},
year = {2002}
}
@article{Paradiso2000,
abstract = {This paper describes four different systems that we have developed for capturing various manners of gesture near interactive surfaces. The first is a low-cost scanning laser rangefinder adapted to accurately track the position of bare hands in a plane just above a large projection display. The second is an acoustic system that detects the position of taps on a large, continuous surface (such as a table, wall, or window) by measuring the differential time-of-arrival of the acoustic shock impulse at several discrete locations. The third is a sensate carpet that uses a grid of piezoelectric wire to measure the dynamic location and pressure of footfalls. The fourth is a swept radio frequency (RF) tag reader that measures the height, approximate location, and other properties (orientation or a control variable like pressure) of objects containing passive, magnetically coupled resonant tags, and updates the continuous parameters of all tagged objects at 30 Hz. In addition to discussing the technologies and surveying different approaches, sample applications are given for each system.},
author = {Paradiso, J A and Hsiao, K and Strickon, J and Lifton, J and Adler, A},
doi = {10.1147/sj.393.0892},
issn = {00188670},
journal = {IBM Systems Journal},
number = {3},
pages = {892--914},
title = {{Sensor systems for interactive surfaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5387038},
volume = {39},
year = {2000}
}
@article{A2007,
author = {A, Joseph and Feldmeier, Mark and Paradiso, Joseph A},
journal = {Spring},
number = {1},
pages = {50--67},
title = {{Wireless Motion Sensors An Interactive Music Environment for Large Groups with Giveaway Wireless Motion Sensors}},
volume = {31},
year = {2007}
}
@inproceedings{Paradiso1997a,
abstract = {An interactive environment has been developed that uses a pair of Doppler radars to measure upper-body kinematics (velocity, direction of motion, amount of motion) and a grid of piezoelectric wires hidden under a 6 x 10 foot carpet to monitor dynamic foot position and pressure. This system has been used in an audio installation, where users launch and modify complex musical sounds and sequences as they wander about the carpet. This paper describes the floor and radar systems, quantifies their performance, and outlines the musical application.},
author = {Paradiso, J and Abler, C and Hsiao, K and Reynolds, M},
booktitle = {Proceedings of the ACM Conference on Human Factors in Computing Systems},
isbn = {0897919262},
pages = {277--278},
publisher = {ACM Press},
title = {{The Magic Carpet: Physical Sensing for Immersive Environments}},
url = {http://portal.acm.org/citation.cfm?id=1120391},
year = {1997}
}
@article{Lifton2001,
author = {Lifton, Joshua and Lee, Jay},
doi = {10.1145/634067.634183},
isbn = {1581133405},
journal = {CHI 01 extended abstracts on Human factors in computing systems CHI 01},
pages = {193--194},
publisher = {ACM Press},
title = {{Media Matrix : Self-organizing Distributed Physical Database}},
url = {http://portal.acm.org/citation.cfm?doid=634067.634183},
year = {2001}
}
@phdthesis{Teegarden2001,
author = {Teegarden, Z},
school = {Massachusetts Institute of Technology},
title = {{Embedded Low-Power Wireless Sensor System: Design of a Software Radio Base Station}},
url = {http://www.media.mit.edu/resenv/pubs/theses/ZOE{\_}MEng{\_}Thesis.pdf},
year = {2001}
}
@phdthesis{Knaian2000,
author = {Knaian, Ara},
school = {Massachusetts Institute of Technology},
title = {{A Wireless Sensor Network for Smart Roadbeds and Intelligent Transportation Systems}},
url = {http://www.media.mit.edu/resenv/pubs/theses/AraKnaian-Thesis.pdf},
year = {2000}
}
@inproceedings{Paradiso1997,
abstract = {A sensor system is described for instrumenting a pair of dancing shoes in order to capture many expressive degrees of freedom and use them to drive music synthesizers and computer graphics in a real-time performance. Dynamic pressure is measured at three points in the shoe sole, as are the bend of the sole, pitch and yaw shoe angles, and translational shoe positions. Data will be transmit across a 19.2 kbaud wireless link, enabling updates at 10 msec intervals.},
author = {Paradiso, Joseph A and Hu, Eric},
booktitle = {First International Symposium on Wearable Computers ISWC 97},
doi = {10.1109/ISWC.1997.629936},
isbn = {0818681926},
pages = {165--166},
publisher = {IEEE Computer Society},
title = {{Expressive Footwear for Computer-Augmented Dance Performance}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=629936},
year = {1997}
}
@inproceedings{Burke1996,
author = {Burke, S E and Paradiso, J A},
booktitle = {Proc Second Technical Conference on Telecommunications Research and Development in Massachusetts electronic},
keywords = {zzz},
pages = {13},
title = {{High-Resolution Piezopolymer Acoustic Bearing Estimator}},
year = {1996}
}
@phdthesis{Rowe1999,
author = {Rowe, Phillip},
school = {Massachusetts Institute of Technology},
title = {{Characterization of a Wideband Monopulse Piezoelectric Direction Finder}},
url = {http://www.media.mit.edu/resenv/pubs/theses/PJRowe-Thesis.pdf},
year = {1999}
}
@article{Paradiso1996,
author = {Paradiso, J A},
doi = {10.1147/sj.353.0473},
issn = {00188670},
journal = {IBM Systems Journal},
number = {3},
pages = {473--487},
title = {{The interactive balloon: Sensing, actuation and behavior in a common object}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5387220},
volume = {35},
year = {1996}
}
@article{York2004,
abstract = {The current paper takes an introspective look at the human-computer interaction (HCI) issues for mobile computing in a variable work context. We catalogue the current research in four major categories. The major findings of our study are following. (1) A majority of HCI issues, about 58{\%}, fall under the category of computer systems and interface architecture implications. (2) 23{\%} of the articles focus on development and implementation issues. (3) 13{\%} of the articles focus on use and context of computer issues. (4) 6{\%} of the articles focus on human characteristics issues. Further, the literature indicates that the field services is a main application of mobile computing (46{\%}) followed by sales force (21{\%}), health care (17{\%}), fieldwork (8{\%}), insurance claims (4{\%}) and journalism (4{\%}).},
author = {York, Judy and Pendharkar, Parag C},
chapter = {771},
doi = {10.1016/j.ijhcs.2003.07.004},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
number = {5-6},
pages = {771--797},
title = {{Human computer interaction issues for mobile computing in a variable work context}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581904000035},
volume = {60},
year = {2004}
}
@article{Cisco2011,
abstract = {This forecast is part of the Cisco Visual Networking Index, an ongoing initiative to track and forecast the impact of visual networking applications. The purpose of this paper is to lay out the details of Ciscos global IP traffic forecast and the methodology behind it. For a more analytical look at the implications of the data presented below, please refer to the companion article to this paper entitled Hyperconnectivity and the Approaching Zettabyte Era.},
author = {Cisco},
institution = {Cisco},
journal = {Middle East},
number = {1},
pages = {2010--2015},
publisher = {Cisco},
title = {{Cisco Visual Networking Index : Forecast and Methodology , 2010 – 2015}},
url = {http://www.cisco.com/en/US/solutions/collateral/ns341/ns525/ns537/ns705/ns827/white{\_}paper{\_}c11-481360{\_}ns827{\_}Networking{\_}Solutions{\_}White{\_}Paper.html},
volume = {June},
year = {2011}
}
@misc{Druck2006,
abstract = {Aaron Druck has been fascinated with virtual realty, like most of us, so he conducted a study to forecast its future use. Aaron explores the obstacles to VR in this article. He also presents results of a survey to estimate when it will be commercially available, the applications people favor, and how much they will pay.},
author = {Druck, Aaron},
pages = {6},
publisher = {TechCast LLC},
title = {{When Will Virtual Reality Become a Reality?}},
url = {http://www.techcastglobal.com/documents/10193/34869/++Aaron/aade1a72-900b-4261-9214-061fba89053d},
year = {2006}
}
@article{TenEyck2011,
abstract = {Simulation provides a range of educational tools that have increasingly been incorporated into emergency medicine (EM) curricula. Standardized patients and some partial task trainers, such as intubation heads, have been used for decades. More recently, a growing number of computer-screen simulations, high-fidelity mannequins, and virtual-reality simulators have expanded the number of procedures and conditions, which can be effectively simulated.The Accreditation Council for Graduate Medical Education transitioned to a competency-based assessment of residency programs in 2001 and included simulation as a method for incorporating the 6 core competencies into graduate medical education curricula. Over the past decade, numerous peer-reviewed publications have promoted simulation as an effective educational tool for each of the core competencies.The advanced technology used to operate many current simulators can erroneously become the focus of efforts to create a simulation-based curriculum. Simulation can most effectively be incorporated into EM curricula through the use of time-proven concepts, which start with defining the targeted learners, assessing their general and specific educational needs, defining learning objectives, and selecting the best educational strategy for achieving each objective. In many, but not all, instances, simulation can be the best tool for achieving EM learning objectives.},
author = {{Ten Eyck}, Raymond P},
institution = {Department of Emergency Medicine, Boonshoft School of Medicine, Wright State University, Dayton, OH, USA. raymond.teneyck@wright.edu},
journal = {Pediatric Emergency Care},
keywords = {computer assisted instruction,computer simulation,curriculum,education,emergency medicine,emergency medicine education,manikins,medical,medical methods,pediatrics,pediatrics education},
number = {4},
pages = {342--344},
pmid = {21467890},
title = {{Simulation in emergency medicine training.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21467889},
volume = {27},
year = {2011}
}
@inproceedings{Qiu2009,
abstract = {Virtual reality and computer simulation are two popular techniques in the field of today's computer applications. They are widely used in building virtual battlefield environment, reconstructing the real environment of the researched region, and foreseeing the combat situation. In this paper, a real-time virtual military simulation system is presented. We explore the general architecture of this simulation system and some related key techniques. Practical usage shows that this system not only supports extendable software architecture but also can provide high efficient scene rendering methods which can be used in real-time visualization of battlefield.},
author = {Qiu, Hang and Chen, Leiting},
booktitle = {2009 First International Conference on Information Science and Engineering},
doi = {10.1109/ICISE.2009.870},
isbn = {9781424449095},
number = {2007},
pages = {1391--1394},
publisher = {Ieee},
title = {{Real-Time Virtual Military Simulation System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5455511},
year = {2009}
}
@inproceedings{Sturgeon2006,
annote = {<m:note>Written a while ago by Tommy Sturgeon, was going to tie in the sensors around the Jack Cole 'smart building' into a 3D simulation. Looked at primarily game engines (probably before the nonesense about virtual worlds began at St Andrews), trying the Quake engine (which was recently open sourced at the time of writing) before then modelling in 3DS Max {\&}amp; then rendering using Java for portability/ease of deployment over the Internet. Planned to use TinyOS nodes. Don't think this project got developed much further though (otherwise I wou;d probably have heard of it...).<m:linebreak/>        <m:linebreak/>      </m:note>},
author = {Sturgeon, T and Miller, A and Getchell, K and Allison, C},
booktitle = {International Postgraduate Symposium on the Convergence of Telecommunications Networking and Broadcasting},
keywords = {school},
title = {{Real Time Mixed Reality in Virtual Environments}},
volume = {Liverpool},
year = {2006}
}
@inproceedings{Pletinckx2002,
author = {Pletinckx, D and Silberman, N and Callebaut, D},
booktitle = {Proc VAST 2001 Virtual Reality Arachaeology and Cultural Heritage},
pages = {197--204},
publisher = {ACM Siggraph},
title = {{The Saint Laurentius Church in Ename and Its Role in the Francia Media Heritage Initiative}},
year = {2002}
}
@article{Song2003,
annote = {<m:note>Mainly focuses on the virtual caligraphy system that they developed, rather than on avatar-style virtual environment interactions.</m:note>},
author = {Song, Meehae and Elias, Thomas and M{\"{u}}ller-wittig, Wolfgang and Chan, Tony K Y},
doi = {10.1145/604471.604515},
isbn = {1581135785},
journal = {GRAPHITE 03 Proceedings of the 1st international conference on Computer graphics and interactive techniques in Australasia and South East Asia},
pages = {223----ff},
publisher = {ACM},
title = {{Interacting with the virtually recreated Peranakans}},
year = {2003}
}
@article{Sevan2008,
annote = {Very good {\&}amp; thorough background/introduction to 'real virtual worlds', assuming no previous knowledge into the subject. Focuses strongly on Second Life.},
author = {Sivan, Yesha},
issn = {19418477},
journal = {Journal of Virtual Worlds Research},
keywords = {0,3d,attribution no derivative works 3,commerce,community,creation,journal virtual,second life,under creative commons,united states license,virtual worlds,work copyrighted,worlds research},
number = {1},
pages = {1--32},
title = {{3D3C Real Virtual Worlds Defined : The Immense Potential of Merging 3D , Community , Creation , and Commerce 3D3C Real Virtual Worlds Defined : The Immense Potential of Merging 3D , Community , Creation , and Commerce}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:3D3C+Real+Virtual+Worlds+Defined{\#}0},
volume = {1},
year = {2008}
}
@misc{Addlesee2001,
abstract = {Sentient computing systems, which can change their behaviour based on a model of the environment they construct using sensor data, may hold the key to managing tomorrow's device-rich mobile networks. At AT{\&}amp;amp;T Laboratories Cambridge, we have built a system that uses sensors to update a model of the real world. We designed the model's terms (object positions, descriptions and state, and so forth) to be immediately familiar to users. Thus, the model describes the world much as users themselves would. We can use this model to write programs that react to changes in the environment according to the user's preferences. We call this sentient computing because the applications appear to share the user's perception of the environment. Treating the current state of the environment as common ground between computers and users provides new ways of interacting with information systems. A sentient computing system doesn't need to be intelligent or capable of forming new concepts about the world, it only needs to act as though its perceptions duplicate the user's. In earlier work, we described a prototype of this system and stated our intention to deploy it on a large scale. We have now installed an enhanced version throughout an office building. Over the past year, approximately 50 staff members have used the system daily with a set of trial applications},
annote = {<m:note>AT{\&}amp;T Labs Cambridge, used ultrasonic-emitting 'bats' that people carried, timing the propogation to detectors in the floors/ceilings to get accurate indoor location tracking of people.</m:note>},
author = {Addlesee, M and Curwen, R and Hodges, S and Newman, J and Steggles, P and Ward, A and Hopper, A},
booktitle = {Computer},
doi = {10.1109/2.940013},
issn = {00189162},
number = {8},
pages = {50--56},
publisher = {IEEE Computer Society Press},
title = {{Implementing a sentient computing system}},
url = {http://portal.acm.org/citation.cfm?id=621776},
volume = {34},
year = {2001}
}
@article{Reilly2010,
abstract = {We introduce TwinSpace, a flexible software infrastructure for combining interactive workspaces and collaborative virtual worlds. Its design is grounded in the need to support deep connectivity and flexible mappings between virtual and real spaces to effectively support collaboration. This is achieved through a robust connectivity layer linking heterogeneous collections of physical and virtual devices and services, and a centralized service to manage and control mappings between physical and virtual. In this paper we motivate and present the architecture of TwinSpace, discuss our experiences and lessons learned in building a generic framework for collaborative cross-reality, and illustrate the architecture using two implemented examples that highlight its flexibility and range, and its support for rapid prototyping.},
annote = {<m:note><m:note>Covers a project for collaborative cross reality (CoXR), allowing groups of people in one place {\&}amp; others in virtual worlds to collabotarte on the same work.<m:linebreak/>        <m:linebreak/>Interesting notion of virtual worlds providing {\&}quot;effectively perfect 'virtual sensing', meaning that the system has accurate, fine-grained, real-time information about participants' locations and orientations in the virtual space{\&}quot;.<m:linebreak/>        <m:linebreak/>Seemingly well-implemented 'mapping' capability, managing how physical and virtual spaces are connected {\^{}} synchronized. The system can define spatial and structural correspondence between the physical and virtual spaces, etc.<m:linebreak/>        <m:linebreak/>Good related work section of the state of Cross Reality as of October 2010.<m:linebreak/>        <m:linebreak/>Uses the term 'co-presence'.<m:linebreak/>        <m:linebreak/>Distinguishes between 'mixed presence' {\&}amp; 'cross reality'; {\&}quot;mixed presence groupware includes all systems intended to support simultaneous collocated and remote collaboration, whilst cross-reality systems integrate real and virtual worlds in some useful way{\&}quot;.<m:linebreak/>        <m:linebreak/>Mentions the Sentient Computing project as anm early cross reality effort, then mentions Lifton as 'recent work'.</m:note></m:note>},
author = {Reilly, Derek F and Rouzati, Hafez and Wu, Andy and Hwang, Jee Yeon and Brudvik, Jeremy and Edwards, W Keith},
doi = {10.1145/1866029.1866050},
isbn = {9781450302715},
journal = {October},
pages = {119--128},
publisher = {ACM Press},
series = {UIST '10},
title = {{TwinSpace : an Infrastructure for Cross-Reality Team Spaces}},
url = {http://portal.acm.org/citation.cfm?id=1866050},
year = {2010}
}
@misc{Bar-Zeev2007,
annote = {Discussion of possibility of a Google Earth/Second Life mashup, from a fairly technical perspective, obvious allusions/links to Wade Roush's article in Technology Review (Wade even leaves a comment on this webpage).

Explanation in the differences between 'mirror worlds' (such as Google Earth) {\&}amp; 'virtual worlds' (such as Second Life).

Calculations of how many SL servers would be needed to map the entire surface of the Earth with its normal architecture (2.4 billion machines) {\&}amp; just Manhattan (1400 machines).

Covers other issues, such as differing scales in Google Earth (from very far out to street level) compared to Second Life (from a few hundred feet to eye level).

Yet another paper to have referenced Snow Crash {\&}amp; its 'metaverse' concept.

Wade's comment enforces that his Technology Review article wasn't meant to be a premise for a literal Google Earth/Second Life mashup, but that they were the leading mirror world/virtual world technologies at the time {\&}amp; that overlap was sure to happen.},
author = {Bar-Zeev, Avi},
title = {{RealityPrime » Second Earth}},
url = {http://www.realityprime.com/articles/second-earth},
urldate = {2012-04-17},
year = {2007}
}
@misc{Oliver2010,
author = {Oliver, Iain A and Miller, Alan H D and Allison, Colin},
booktitle = {Proceedings of the first annual ACM SIGMM conference on Multimedia systems},
doi = {10.1145/1730836.1730873},
isbn = {9781605589145},
pages = {305},
publisher = {ACM Press},
series = {MMSys '10},
title = {{Virtual worlds, real traffic: interaction and adaptation}},
url = {http://doi.acm.org/10.1145/1730836.1730873},
year = {2010}
}
@article{Bainbridge2007,
abstract = {Online virtual worlds, electronic environments where people can work and interact in a somewhat realistic manner, have great potential as sites for research in the social, behavioral, and economic sciences, as well as in human-centered computer science. This article uses Second Life and World of Warcraft as two very different examples of current virtual worlds that foreshadow future developments, introducing a number of research methodologies that scientists are now exploring, including formal experimentation, observational ethnography, and quantitative analysis of economic markets or social networks.},
author = {Bainbridge, William Sims},
doi = {10.1126/science.1146930},
isbn = {0036807510959203},
issn = {10959203},
journal = {Science},
number = {5837},
pages = {472--6},
pmid = {17656715},
publisher = {American Association for the Advancement of Science},
title = {{The scientific research potential of virtual worlds.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17656715},
volume = {317},
year = {2007}
}
@article{Warburton2009,
abstract = {Second Life (SL) is currently the most mature and popular multi-user virtual world platform being used in education. Through an in-depth examination of SL, this article explores its potential and the barriers that multi-user virtual environments present to educators wanting to use immersive 3-D spaces in their teaching. The context is set by tracing the history of virtual worlds back to earlymulti-user online computer gaming environments and describing the current trends in the development of 3-D immersive spaces. A typology for virtual worlds is developed and the key features that have made unstructured 3-D spaces so attractive to educators are described. The popularity in use of SL is examined through three critical components of the virtual environment experience: technical, immersive and social. From here, the paper discusses the affordances that SL offers for educational activities and the types of teaching approaches that are being explored by institutions. The work concludes with a critical analysis of the barriers to successful implementation of SL as an educational tool and maps a number of developments that are underway to address these issues across virtual worlds more broadly.},
author = {Warburton, Steven},
doi = {10.1111/j.1467-8535.2009.00952.x},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Warburton - 2009 - Second Life in higher education Assessing the potential for and the barriers to deploying virtual worlds in learning and teaching.pdf:pdf},
issn = {00071013},
journal = {British Journal of Educational Technology},
number = {3},
pages = {414--426},
publisher = {Wiley-Blackwell Publishing, Inc, 350 Main Street, Commerce Place, Malden, MA, 02148-5018, USA,},
title = {{Second Life in higher education: Assessing the potential for and the barriers to deploying virtual worlds in learning and teaching}},
url = {http://blackwell-synergy.com/doi/abs/10.1111/j.1467-8535.2009.00952.x},
volume = {40},
year = {2009}
}
@article{Hendaoui2008,
abstract = {Today's social virtual worlds (SVW) are beginning to realize Stephenson's vision of the metaverse: a future massive network of interconnected digital worlds. Tens of millions of people already use these kinds of environments to communicate, collaborate, and do business. Big companies are also moving into these digital realms. Thus, in a context in which the Web is becoming increasingly social, we believe that SVWs are beginning to shape the knowledge-based and glo balized societies and economies of tomorrow. Obviously, an urgent need exists to further understand SVWs and their implications for theory and practice. This article constitutes a first attempt to bring researchers into some of the business, social, technical, legal, and ethical issues related to SVWs. We anticipate that researchers will need to build new theories and concepts for SVWs, to explore the frontiers between reality and virtuality.},
author = {Hendaoui, Adel and Limayem, Moez and Thompson, Craig W},
doi = {10.1109/MIC.2008.1},
issn = {10897801},
journal = {IEEE Internet Computing},
number = {1},
pages = {88--92},
title = {{3D Social Virtual Worlds: Research Issues and Challenges}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4428344},
volume = {12},
year = {2008}
}
@misc{Micro-StarInt'lCo.,
author = {{Micro-Star Int'l Co.}, Ltd.},
title = {{MSI Global – Notebook - WindPad 110W}},
url = {http://www.msi.com/product/nb/WindPad-110W.html},
urldate = {2012-04-08}
}
@misc{Camera,
author = {Camera, Dean},
title = {{Four Walled Cubicle - LUFA (Formerly MyUSB)}},
url = {http://www.fourwalledcubicle.com/LUFA.php},
urldate = {2012-04-05}
}
@misc{Hunt,
author = {Hunt, Darran},
title = {{Arduino UNO Joystick HID firmware}},
url = {http://hunt.net.nz/users/darran/weblog/a3599/},
urldate = {2012-04-06}
}
@misc{BlenderFoundation,
author = {{Blender Foundation}},
title = {{blender.org - Game engine}},
url = {http://www.blender.org/education-help/tutorials/game-engine/},
urldate = {2012-04-04}
}
@misc{UnigineCorp,
author = {{Unigine Corp}},
title = {{Unigine: real-time 3D engine (game, simulation, visualization and VR)}},
url = {http://unigine.com/},
urldate = {2012-04-04}
}
@misc{UnityTechnologies,
author = {{Unity Technologies}},
title = {{Unity - Game Engine}},
url = {http://unity3d.com/},
urldate = {2012-04-04}
}
@misc{OpenSimulatorProject,
author = {{OpenSimulator Project}},
title = {{OpenSim}},
url = {http://opensimulator.org/wiki/Main{\_}Page},
urldate = {2012-03-29}
}
@misc{LindenResearchInc.,
author = {{Linden Research Inc.}},
title = {{Virtual Worlds, Avatars, free 3D chat, online meetings - Second Life Official Site}},
url = {http://secondlife.com/},
urldate = {2012-03-29}
}
@misc{Gelissen2008,
author = {Gelissen, Jean},
publisher = {International Organization for Standardization},
title = {{Summary of MPEG-V}},
url = {http://mpeg.chiariglione.org/working{\_}documents.php},
year = {2008}
}
@article{Getchell2010,
abstract = {The construction and consolidation of knowledge through the practical application of concepts and processes can be difficult to support for subjects where practice is an integral component of competence and expertise in that domain. For example, participation in an archaeological excavation is not readily available to students, although a detailed understanding of what processes this involves is deemed to be core to the subject. The Laconia Acropolis Virtual Archaeology (LAVA) project has created a cooperative exploratory learning environment that addresses the need for students to engage with the complex practice of excavation. By leveraging the progressive nature of games methodologies and the immersive engagement provided by 3D multiuser virtual environments, LAVA facilitates the adoption of exploratory learning for excavation scenarios which have previously been inaccessible due to barriers of travel, time, and cost. A virtual environment based on real world data has been developed where groups of users are faced with a series of dynamic challenges with which they engage until such time that a certain level of competence is shown. Once a series of domain-specific objectives has been met, users are able to progress forward to the next level of the simulation. The excavation simulator enhances the student learning experience by providing opportunities for students to engage with the process in a customizable, virtual environment. Not only does this provide students with an opportunity to put the theories they are familiar with into practice, but it also allows students to gain experience in applying their skills in a bid to manage an excavation process, thereby making it possible for a greater emphasis to be placed on the practical application of knowledge that the excavation process necessitates. The potential of this approach has been confirmed by a positive user evaluation. LAVA contributes toward the progress of technology-enhanced learning by illustrating the- - instantiation of a framework which demonstrates how to integrate games methods with learning management systems and virtual worlds in order to support higher order learning behaviors such as applying, analyzing, evaluating, and creating.},
author = {Getchell, K and Miller, A and Nicoll, R and Sweetman, R and Allison, C},
doi = {10.1109/TLT.2010.25},
issn = {1939-1382},
journal = {IEEE Transactions on Learning Technologies},
month = {oct},
number = {4},
pages = {281--293},
title = {{Games Methodologies and Immersive Environments for Virtual Fieldwork}},
url = {http://ieeexplore.ieee.org/xpl/freeabs{\_}all.jsp?arnumber=5557838},
volume = {3},
year = {2010}
}
@misc{Dunkels,
author = {Dunkels, Adam},
title = {{The Contiki OS}},
url = {http://www.contiki-os.org/p/about-contiki.html},
urldate = {2012-02-23}
}
@misc{TinyOSAlliance,
author = {{TinyOS Alliance}},
title = {{TinyOS Home Page}},
url = {http://www.tinyos.net/},
urldate = {2012-02-22}
}
@misc{PhidgetsInc.,
author = {{Phidgets Inc.}},
title = {{Phidgets Inc. - Unique and Easy to Use USB Interfaces}},
url = {http://www.phidgets.com/},
urldate = {2012-02-22}
}
@misc{Foundation,
author = {Foundation, Raspberry Pi},
title = {{Raspberry Pi | An ARM GNU/Linux box for {\$}25. Take a byte!}},
url = {http://www.raspberrypi.org/},
urldate = {2012-02-22}
}
@misc{Arduino,
author = {Arduino},
title = {{Arduino - HomePage}},
url = {http://www.arduino.cc/},
urldate = {2012-02-22}
}
@book{Faludi2010,
address = {Sebastopol},
author = {Faludi, Robert},
edition = {1},
editor = {Jepson, Brian},
isbn = {978-0-596-80773-3},
publisher = {O'Reilly Media Inc.},
title = {{Building Wireless Sensor Networks}},
url = {http://www.faludi.com/bwsn/},
year = {2010}
}
@misc{Technology,
author = {Technology, United States Institute for Theatre},
title = {{DMX512}},
url = {http://www.usitt.org/Resources/Standards2/DMX512/}
}
@inproceedings{Wojciechowski2004,
address = {New York, New York, USA},
author = {Wojciechowski, Rafal and Walczak, Krzysztof and White, Martin and Cellary, Wojciech},
booktitle = {Proceedings of the ninth international conference on 3D Web technology - Web3D '04},
doi = {10.1145/985040.985060},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wojciechowski et al. - 2004 - Building Virtual and Augmented Reality museum exhibitions.pdf:pdf},
isbn = {1581138458},
keywords = {VRML,augmented reality,cultural heritage,virtual reality},
month = {apr},
pages = {135},
publisher = {ACM Press},
title = {{Building Virtual and Augmented Reality museum exhibitions}},
url = {http://dl.acm.org/citation.cfm?id=985040.985060},
year = {2004}
}
@incollection{Milgram1999,
address = {New York},
author = {Milgram, Paul and Jr., Herman Colquhoun},
booktitle = {Mixed Reality - Merging Real and Virtual Worlds},
editor = {Ohta, Y and Tamura, H},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Milgram, Jr. - 1999 - A Taxonomy of Real and Virtual World Display Integration.pdf:pdf},
publisher = {Springer},
title = {{A Taxonomy of Real and Virtual World Display Integration}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.6230},
year = {1999}
}
@article{Salmasi2009,
annote = {Not really related to cross reality/standards, but has an interesting history of what led to gambling/banking being banned in Seond Life - issues with different laws/jurisdictions depending upon the country of the user/server, what happens if they make the account in one country {\&}amp; then move to another, what if they use a proxy, etc., etc., etc.

Standards for the exchange of media/control information between virtual worlds {\&}amp; between virtual worlds {\&}amp; the real world may have to (may already have) take account of these sort of things - the standards can't allow users to do something that is illegal in one country without sufficient measures to prevent it in this country, whatever.},
author = {Salmasi, Anna and Gillam, Lee},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Machine Ethics for Gambling in the Metaverse: An "EthiCasino"}},
url = {https://journals.tdl.org/jvwr/article/view/653/513},
volume = {2},
year = {2009}
}
@article{Otte2009,
annote = {<m:note>Didn't really seem to talk about 'Standardization in Virtual Worlds' that much... just sort of mentioned it in the last paragraph of the conclusion so as to qualify for this issue of JVWR...</m:note>},
author = {Otte, Marco and Hoorn, Johan},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Standardization in Virtual Worlds: Prevention of False Hope and Undue Fear}},
url = {https://journals.tdl.org/jvwr/article/view/650/509},
volume = {2},
year = {2009}
}
@article{Osborne2009,
annote = {<m:note>More economics really.</m:note>},
author = {Osborne, Evan and Schiller, Shu},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Order and Creativity in Virtual Worlds}},
url = {https://journals.tdl.org/jvwr/article/view/649/515},
volume = {2},
year = {2009}
}
@article{Op'tLand2009,
annote = {<m:note>Talks at the end about how standardization within the MMO market appears to be {\&}quot;occurring not through an explicit process with a governing body, but via emulation and iteration{\&}quot; - eg new MMOs copy/mimic a lot of WoW's features/approach/etc. As WoW is the first exposure many gamers have to MMOs, its style of interaction {\&}amp; whatnot becomes the lingua franca of the field {\&}amp; thus future MMOs to be developed will be predicated on its models, until (if?) another MMO comes along {\&}amp; does what WoW did.</m:note>},
author = {Op'tLand, Ray},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Another Endless November: AOL, WoW, and the Corporatization of a Niche Market}},
url = {https://journals.tdl.org/jvwr/article/view/660/536},
volume = {2},
year = {2009}
}
@article{Lehtiniemi2009,
annote = {<m:note><m:note>Focuses on virtual envrionments in which the operator designs the goods {\&}amp; the production paths - eg most MMORPGs (WoW, etc.) eg not 'virtual worlds' akin to Second Life {\&}amp; friends.<m:linebreak/>        <m:linebreak/>Author says in the conclusion that there is no reason why the same approaches couldn't be used for virtual environments with different economy styles, but this seems a dubious claim {\&}amp; it is just an ending comment - there is no actual research into this presented.</m:note></m:note>},
author = {Lehtiniemi, Tuukka},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Measuring Aggregate Production in a Virtual Economy Using Log Data}},
url = {https://journals.tdl.org/jvwr/article/view/631/512},
volume = {2},
year = {2009}
}
@article{Jovanova2009,
annote = {<m:note>Mentions the exact opposite of what I want to do with GPS {\&}amp; avatar movement - moving a robot in the real world according to information from the virtual world.</m:note>},
author = {Jovanova, Blagica and Preda, Marius and Preteux, Fran{\c{c}}oise},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{The Role of Interoperability in Virtual Worlds, Analysis of the Specific Cases of Avatars}},
url = {https://journals.tdl.org/jvwr/article/view/672/508},
volume = {2},
year = {2009}
}
@article{Sivan2008,
annote = {<m:note>Interesting bit about Vuzix iWear VR920 3D goggles which, through a special driver for Second Life, allowed you to view a virtual world simply by turning your head (but of course didn't work for any other virtual world {\&}amp; in fact only a specific version of Second Life) - but shows that controlling the gaze of the avatar/camera from a real-time external data source is possible through modification of the VW server (eg a region module in OpenSim).</m:note>},
author = {Sivan, Yesha},
journal = {Journal of Virtual Worlds Research},
number = {2},
title = {{Real Virtual Worlds SOS (State of Standards) Q3-2008}},
url = {http://journals.tdl.org/jvwr/article/view/359},
volume = {1},
year = {2008}
}
@article{Garcia2009,
annote = {<m:note>Can't tell if serious...</m:note>},
author = {Garcia, Linda and LeMasters, Garrison},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Synthetic Excellence: Standards, Play, and Unintended Outcomes}},
url = {https://journals.tdl.org/jvwr/article/view/665/534},
volume = {2},
year = {2009}
}
@article{Farr2009,
author = {Farr, Will and Hut, Piet and Ames, Jeff and Johnson, Adam},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{An experiment in Using Virtual Worlds for Scientific Visualization of Self-Gravitating Systems}},
url = {https://journals.tdl.org/jvwr/article/view/659/518},
volume = {2},
year = {2009}
}
@article{Falk2009,
author = {Falk, Markus and Besemann, Daniel and Bosson, James},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Payback of Mining Activities Within Entropia Universe}},
url = {https://journals.tdl.org/jvwr/article/view/647/514},
volume = {2},
year = {2009}
}
@article{Cruz-Lara2009,
author = {Cruz-Lara, Samuel and Bellalem, Nadia and Bellalem, Lotfi and Osswald, Tarik},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Immersive 3D Environments and Multilinguality: Some Non-Intrusive and Dynamic e-learning-oriented Scenarios based on Textual Information}},
url = {https://journals.tdl.org/jvwr/article/view/727/526},
volume = {2},
year = {2009}
}
@article{Watte2009,
author = {Watte, Jon},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Virtual World Interoperability: Let Use Cases Drive Design}},
url = {https://journals.tdl.org/jvwr/article/view/727/526},
volume = {2},
year = {2009}
}
@article{VanBroeck2009,
author = {van Broeck, S and van den Broeck, M and Lou, Zhe},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Content Level Gateway for Online Virtual Worlds}},
url = {https://journals.tdl.org/jvwr/article/view/651/532},
volume = {2},
year = {2009}
}
@article{Saiman2009,
author = {Saiman, Arminas},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Barriers to Efficient Virtual Business Transactions}},
url = {https://journals.tdl.org/jvwr/article/view/661/520},
volume = {2},
year = {2009}
}
@article{Lindman2009,
author = {Lindman, Ludvaig},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Lindman Design: Virtual World Experiences}},
url = {https://journals.tdl.org/jvwr/article/view/728/537},
volume = {2},
year = {2009}
}
@article{Kimber2011,
annote = {Not cross reality - no virtual to real media/control flow.},
author = {Kimber, Don and Vaughan, Jim and Rieffel, Eleanor},
isbn = {9781450304269},
journal = {Proceedings of the 2nd Augmented Human International Conference},
keywords = {augmented,mixed reality,sensor networks,virtual worlds},
number = {1},
pages = {36},
publisher = {ACM},
title = {{Augmented Perception through Mirror Worlds}},
url = {http://portal.acm.org/citation.cfm?id=1959862},
year = {2011}
}
@article{VanderLand2011,
abstract = {In this paper, a theoretical model of effective team collaboration in 3D virtual environments is presented. The aim of this model is to enhance our understanding of the capabilities exerting influence on effective 3D virtual team collaboration. The model identifies a number of specific capabilities of 3D virtual worlds that can contribute to this team effectiveness. Compared to "traditional" computer-mediated collaboration technologies, 3D virtual environments support team collaboration primarily through (a) the shared virtual environment, and (b) avatar-based interaction. Through the shared virtual environment, users experience higher levels of presence (a feeling of actually "being there"), realism and interactivity. These capabilities increase the users' level of information processing. Avatar-based interaction induces greater feelings of social presence (being with others) and control over self-presentation (how one wants to be perceived by others), thus increasing the level of communication support in the 3D environment. Through greater levels of information and communication support, a higher level of shared understanding is reached, which in turn positively influences team performance. Our paper concludes by presenting several propositions which allow further empirical testing, implications for research and practice, and suggestions for future research. The insights obtained from this paper can help developers of these virtual worlds to design standards for the capabilities that influence effective team collaboration in 3D virtual environments.},
author = {van der Land, Sarah and Schouten, Alexandeer and van den Hooff, Bart and Feldberg, Frans},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Modeling the Metaverse: A Theoretical Model of Effective Team Collaboration in 3D Virtual Environments}},
url = {https://journals.tdl.org/jvwr/article/view/6126},
volume = {4},
year = {2011}
}
@article{Verdot2011,
abstract = {More and more people dive into Virtual Worlds, experiencing the reality of parallel universes in almost every sector. Moreover, these virtual environments actually generate "real money" directly but also indirectly by selling virtual goods. Yet the current landscape consists in a huge number of siloed Virtual Worlds. We believe that addressing this lack of interoperability could greatly improve the user experience, ease the deployment of new worlds and open up market opportunities. Bell Labs' Applications domain is contributing with Virtual Hybrid Communications, a mature Web technology based on communication hyperlinks that enables the bridging of real and virtual worlds. This technology allows people to remain connected to legacy telecom infrastructures wherever they are (in real or virtual) and to safely expose their communication means without disclosing any personal detail (name, phone number, etc). Thanks to open and standard API, it will also allow virtual service providers and Telecom operators to provide efficient communication solutions and innovative services.},
author = {Verdot, Vincent and Saidi, Adel},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Virtual Hybrid Communications – A Telecom Infrastructure for the Metaverse}},
url = {https://journals.tdl.org/jvwr/article/view/6128},
volume = {4},
year = {2011}
}
@article{Berthelot2011,
abstract = {We propose a generic architecture that allows mixing several 3D formats in a single viewer whatever the rendering engine used by the virtual world. Our goal is to solve the issue raised by the multiplicity of 3D formats and rendering engines through an interoperability solution inspired by the web model. Our architecture relies on the Scene Graph Adapter, a component which aims at interfacing communication between virtual world inputs (e.g. 3D files) and outputs (e.g. the interactive visualization window). For this purpose, the Scene Graph Adapter is made up of two APIs that leverages similarities between 3D formats and 3D rendering engines, the Format Adapter API and the Renderer Adapter API.},
author = {Berthelot, Rozenn and Duval, Thierry and Royan, J{\'{e}}r{\^{o}}me and Arnaldi, Bruno},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Improving Reusability of Assets for Virtual Worlds while Preserving 3D Formats Features}},
url = {https://journals.tdl.org/jvwr/article/view/6123},
volume = {4},
year = {2011}
}
@article{Bretaudiere2011,
abstract = {We present our current research activities associating automatic natural language processing to serious games and virtual worlds. Several interesting scenarios have been developed: language learning, natural language generation, multilingual information, emotion detection, real-time translations, and non-intrusive access to linguistic information such as definitions or synonyms. Part of our work has contributed to the specification of the Multi Lingual Information Framework [ISO FDIS 24616], (MLIF,2011). Standardization will grant stability, interoperability and sustainability of an important part of our research activities, in particular, in the framework of representing and managing multilingual textual information.},
author = {Bretaudi{\`{e}}re, Treveur and Cruz-Lara, Samuel and Barahona, Lina},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Associating Automatic Natural Language Processing to Serious Games and Virtual Worlds}},
url = {https://journals.tdl.org/jvwr/article/view/6124},
volume = {4},
year = {2011}
}
@article{Krueger2011,
abstract = {Accessibility is an important area of interoperability between real and virtual worlds that must be considered during standards-setting. The number of persons with disabilities is large and increasing, as is their use of virtual worlds. All elements of virtual worlds must be accessible. Four types of real world disability impact functioning in virtual worlds: keyboard/mouse; print; hearing/speech; and cognitive. Some virtual worlds include accessibility features, such as resizable UI elements and fonts. Alternative keyboards and mice usually work adequately in virtual worlds. However, common text-to-speech, speech-to-text, and screen reader software doesn't interface well with virtual worlds. Existing accessibility guidelines and legislation (Universal Design, Internet accessibility standards and guidelines, and online game accessibility guidelines) might be applicable to virtual worlds. Practical limitations to implementation of these solutions include their complexity and cost. As government agencies, universities, and employers increase their use of virtual worlds, specific standards for virtual world accessibility, including interfacing with common assistive technology, need to be created and enforced.},
author = {Krueger, Alice and Stineman, Margaret},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Assistive Technology Interoperability between Virtual and Real Worlds}},
url = {https://journals.tdl.org/jvwr/article/view/6125},
volume = {4},
year = {2011}
}
@article{Otte2011,
abstract = {The Internet and virtual worlds are increasingly become a part of our daily lives. Currently these two are not capable of exchanging information, largely because of the lack of a global accepted standard for information exchange. Interaction between the real world and virtual worlds is mostly limited to classic mouse and keyboard devices, and exchange of information between different virtual worlds is virtually non-existent. We present a Use Case in the Metaverse1 project to increase motivation for continued physical exercising for the elderly by connecting real-world devices to virtual worlds, and allow information exchange through the teleportation of virtual objects from Second Life to our custom virtual biking world created in the Logos3D engine. We show that the principle of exchanging information between real and virtual worlds is simple, but the solution is non-trivial and requires not only a globally accepted standard to facilitate information exchange. From the results of a focus-group study, we show that a virtual environment does have the capability to increase motivation for exercising and that users do respond to a virtual exercise coach.},
author = {Otte, Marco and Roosendaal, Loren and Hoorn, Johan},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Teleportation of Objects between Virtual Worlds: Use Case: Exer-gaming}},
url = {https://journals.tdl.org/jvwr/article/view/6127},
volume = {4},
year = {2011}
}
@article{Cabello2011,
abstract = {Nowadays, tourism has become a very important industry in the international economy. Information and communication technologies are in constant development; they progress worldwide and across sectors. Their applications in tourism and tourist resources is rapidly increasing, reaching new, innovative and sometimes amazing results in terms of effectiveness, productivity, quality, and customer satisfaction. Exploring the interaction between technologies and tourism is difficult and challenging. Specifically, using virtual world technologies as a new means of information for potential tourists is a big challenge where the actual methods, goals and needs still need to be exactly identified. This paper aims at analyzing why and how virtual worlds can become an important platform for tourism-oriented areas to promote a destination in general, and their local heritage and tourist added-value services in particular. The document will also introduce the design of the first prototypes and the validation results of the four specific technologies tested at the Virtual Travel Use Case (Soundscape generation, Multilinguality, Video streaming and Path and Camera Planning). Finally, the contribution to the MPEG-V standard will also be detailed in the paper.},
author = {Cabello, Jose Manuel and Franco, Jose Maria and Collado, Antonio and Janer, Jordi and Cruz-Lara, Samuel and Oyarzun, David and Armisen, Albert and Geraerts, Roland},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Standards in Virtual Worlds Virtual Travel Use Case Metaverse1 Project}},
url = {https://journals.tdl.org/jvwr/article/view/6129},
volume = {4},
year = {2011}
}
@article{Gelissen2011a,
abstract = {This paper takes an historical perspective on the Metaverse1 project. A group of about 30 EU-based organizations totalling about 100 people worked together from 2008 to 2011 to develop a global standard that will connect virtual worlds and real worlds. The project, which was under the Eureka/ITEA2 framework, was one of the key contributors to the MPEG-V 'Media context and control' standard published by ISO/IEC in January 2011. The review includes the need for virtual worlds stadnards, the formation of the research team and plan, internal research results, main outcome (MPEG-V standard). We will conclude with some reflective notes. The ITEA2 Metaverse1 project has developed a standardized global framework enabling interoperability between virtual worlds such as Second Life, IMVU, OpenSim, Active Worlds, Google Earth and with the real world in terms of sensors and actuators, vision and rendering systems, and applications in areas like social and welfare systems, banking, insurance, tourism and real estate. Results of the project drove the MPEG-V 'Media context and control' standard published by ISO/IEC in January 2011.},
author = {Gelissen, Jean and Sivan, Yesha},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{The Metaverse1 Case: Historical Review of Making One Virtual Worlds Standard (MPEG-V)}},
url = {https://journals.tdl.org/jvwr/article/view/6066},
volume = {4},
year = {2011}
}
@article{Gelissen2011,
abstract = {In this issue, we report on the first phase of MPEG-V, a work that started in 2007. MPEG-V was conceived as a unified effort to develop standards within virtual worlds, and between virtual worlds and real worlds. This work culminated in the publication of the ISO/IEC MPEG-V 'Media context and control' standards in January 2011. The papers in this issue of the Journal of Virtual World Research expose both the many current standards for virtual worlds, as well as the many missing standards. As such, the issue hints at many more places where standards are needed. To fulfill the potential of virtual worlds much more standardization (MPEG-V, and other standards) is needed.},
author = {Gelissen, Jean and Preda, Marius and Cruz-Lara, Samuel and Sivan, Yesha},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Issue Editors' Corner: The Current and Future Angles of Standards}},
url = {https://journals.tdl.org/jvwr/article/view/6139},
volume = {4},
year = {2011}
}
@article{Sivan2011,
abstract = {With this issue JVWR celebrates its fourth year. During these years, we have matured to be the prime source of research in our emerging domain. Earlier this month (Dec. 2011), we celebrated, for the first time, by hosting a JVWR workshop at the International Conference on Information Systems (ICIS 2011 Shanghai, China. This issue takes an historical perspective. In many ways, this issue is a direct decedent of Volume 2, Number 3 - Technology, Economy and Standards in Virtual Worlds. The latter has drawn a vision, this one reports on the outcomes. On this note of moving from vision to reality, I wanted to wish us all happy new 2012.},
author = {Sivan, Yesha},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Managing Editor’s Corner: Celebrating Four Years and Planning for the Next}},
url = {https://journals.tdl.org/jvwr/article/view/6140},
volume = {4},
year = {2011}
}
@article{Krevelen2010,
abstract = {We are on the verge of ubiquitously adopting Augmented Reality (AR) technologies to enhance our percep- tion and help us see, hear, and feel our environments in new and enriched ways. AR will support us in fields such as education, maintenance, design and reconnaissance, to name but a few. This paper describes the field of AR, including a brief definition and development history, the enabling technologies and their characteristics. It surveys the state of the art by reviewing some recent applications of AR technology as well as some known limitations regarding human factors in the use of AR systems that developers will need to overcome},
annote = {<m:note>Comprehensive overview of AR field, survey of technologies, applications<m:linebreak/>, limitations {\&}amp; a survey on frameworks as well as content authorting<m:linebreak/>tools.</m:note>},
author = {Krevelen, D W F Van and Poelman, R},
journal = {The International Journal of Virtual Reality},
number = {2},
pages = {1--20},
title = {{A Survey of Augmented Reality Technologies, Applications and Limitations}},
url = {http://www.mendeley.com/research/survey-augmented-reality-technologies-applications-limitations/},
volume = {9},
year = {2010}
}
@inproceedings{McKinnon2004,
address = {New York, New York, USA},
annote = {<m:note>Presents 2 experiments studying sense of presence in virtual reality {\&}amp; real world, see 'extent of prescence metaphor'.</m:note>},
author = {McKinnon, Lynn D. and North, Max M.},
booktitle = {Proceedings of the 42nd annual Southeast regional conference on - ACM-SE 42},
doi = {10.1145/986537.986597},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McKinnon, North - 2004 - A comparative study of presence in virtual reality vs. presence in the real world.pdf:pdf},
isbn = {1581138709},
keywords = {sense of presence,virtual environments,virtual reality},
month = {apr},
pages = {253},
publisher = {ACM Press},
title = {{A comparative study of presence in virtual reality vs. presence in the real world}},
url = {http://dl.acm.org/citation.cfm?id=986537.986597},
year = {2004}
}
@article{Tamura2001,
abstract = {Mixed reality (MR) is a kind of virtual reality (VR), but a broader concept than augmented reality (AR), which augments the real world with synthetic electronic data. On the opposite side, augmented virtuality (AV) enhances or augments virtual environment with data from real world. MR covers a continuum from AR to AV.},
annote = {<m:note>IEEE Computer Graphics and Applications magazine article.<m:linebreak/><m:linebreak/>        <m:linebreak/>Agrees with Paul Milgram's definition of mixed reaity as encompassing<m:linebreak/>augmented reality {\&}amp; augmented virtuality. Describes some of the research<m:linebreak/>conducted at the Mixed Reality Systems Laboratory funded by Canon {\&}amp; the<m:linebreak/>Japanese government from 1997 - 2001. Results were presented in conjunc-<m:linebreak/>-tion with IEEE Virtual Reality 2001 {\&}amp; the Second International Symposi-<m:linebreak/>-um on Mixed Reality (ISMR). Led to many research projects in image<m:linebreak/>rendering in VR space, visualization of large spaces, see-through HMD.</m:note>},
author = {Tamura, H and Yamamoto, H and Katayama, A},
doi = {10.1109/38.963462},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
number = {6},
pages = {64--70},
title = {{Mixed reality: future dreams seen at the border between real and virtual worlds}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=963462},
volume = {21},
year = {2001}
}
@inproceedings{Metzger,
abstract = {Distributed interactive simulation provides an environment for realistic participation in virtual worlds. Humans interact with the virtual world through interface devices such as switches and knobs, keyboards and mice, touch screens and data gloves. The time has come for the seamless integration of these physical, real-world human interface devices with the systems that generate and display the virtual environments. The merging of these two areas will result in virtual world experiences more realistic than any available today},
annote = {<m:note><m:note>Describes a system that is capable of overlaying images of the real wor-<m:linebreak/>-ld on top of a virtual world scene {\&}amp; overlaying virtual world imagery<m:linebreak/>onto a real world scene, with applications for both presented.<m:linebreak/>        <m:linebreak/>{\&}quot;The merging of these two areas will result in virtual world experiences<m:linebreak/>more realistic than any available today.{\&}quot;<m:linebreak/>        <m:linebreak/>{\&}quot;It will be quite some time before the line separating the real world {\&}amp;<m:linebreak/>the virtual world disappears completely. However, systems have been cre-<m:linebreak/>-ated which demonstrate thatit is possible to make the distinction betw-<m:linebreak/>-een what is real and wha tis virtual a bit more difficult to determine{\&}quot;</m:note></m:note>},
author = {Metzger, P.J.},
booktitle = {Proceedings of IEEE Virtual Reality Annual International Symposium},
doi = {10.1109/VRAIS.1993.380805},
isbn = {0-7803-1363-1},
pages = {7--13},
publisher = {IEEE},
title = {{Adding reality to the virtual}},
url = {http://ieeexplore.ieee.org/xpl/freeabs{\_}all.jsp?arnumber=380805}
}
@inproceedings{Timmerer2009,
annote = {<m:note>Provides an overview of MPEG-V {\&}amp; its intended standardization areas. Id-<m:linebreak/>-entifies the requirement for a standardized framework to allow existin-<m:linebreak/>-g {\&}amp; emerging metaverses to be bridged.</m:note>},
author = {Timmerer, Christian and Gelissen, Jean and Waltl, Markus and Hellwagner, Hermann},
booktitle = {Proceedings of the 2009 NEM Summit},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Timmerer et al. - 2009 - Interfacing with Virtual Worlds.pdf:pdf},
keywords = {interoperability,mpeg v,virtual world},
pages = {28--30},
title = {{Interfacing with Virtual Worlds}},
url = {http://www-itec.uni-klu.ac.at/{~}timse/research/publications/NEM{\_}MPEG-V{\_}v.4.0.pdf},
year = {2009}
}
@inproceedings{Koleva2000,
address = {New York, New York, USA},
annote = {Describes different displays (interfaces) between real {\&}amp; virtual worlds,
including fabric curtains, rain curtains, sliding doors {\&}amp; flip-up scree-
-ns.},
author = {Koleva, Boriana and Schn{\"{a}}delbach, Holger and Benford, Steve and Greenhalgh, Chris},
booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '00},
doi = {10.1145/332040.332437},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koleva et al. - 2000 - Traversable interfaces between real and virtual worlds.pdf:pdf},
isbn = {1581132166},
keywords = {augmented reality,mixed reality,tele-embodiment,tele-presence,virtual environments},
month = {apr},
pages = {233--240},
publisher = {ACM Press},
title = {{Traversable interfaces between real and virtual worlds}},
url = {http://dl.acm.org/citation.cfm?id=332040.332437},
year = {2000}
}
@article{Aberer2006,
annote = {Good background/history/overview of GSN from EPFL, covering the arch-
-itecture {\&}amp; an interesting example deployment. Also gives analysis of
performance/scalability.},
author = {Aberer, Karl and Hauswirth, Manfred and Salehi, Ali},
keywords = {NCCR-MICS,NCCR-MICS/CL4,sensor internetworking,sensor middleware,sensor networks},
title = {{The Global Sensor Networks middleware for efficient and flexible deployment and interconnection of sensor networks}},
year = {2006}
}
@misc{MicrosoftResearch2008,
annote = {<m:note>An introduction to working with SenseWeb, including background on how it<m:linebreak/>works {\&}amp; the system's architecture.</m:note>},
author = {{Microsoft Research}},
title = {{SenseWeb Tutorial}},
url = {http://research.microsoft.com/en-us/products/senseweb/SenseWebTutorial.pdf},
year = {2008}
}
@inproceedings{Park2010,
address = {New York, New York, USA},
annote = {<m:note><m:note>'XLogic Collaborative RFID/USN-Enabled Adaptive Middleware' aims to all-<m:linebreak/>-ow collaboration between many RFID/USN applications by providing them<m:linebreak/>with a flexible interface through a web-based service scheme, XML-based<m:linebreak/>infrastructure {\&}amp; the XLogic sript language. Paper includes simulation<m:linebreak/>results including performance analysis.<m:linebreak/>        <m:linebreak/>'seamlessly orchestrating framework'<m:linebreak/>        <m:linebreak/>XCREAM framework sits between various RFID/USN middlewares {\&}amp; application<m:linebreak/>services.</m:note></m:note>},
author = {Park, Kyungeun and Yun, Jekuk and Byun, Changhyun and Kim, Yanggon and Chang, Juno},
booktitle = {Proceedings of the 12th International Conference on Information Integration and Web-based Applications {\&} Services - iiWAS '10},
doi = {10.1145/1967486.1967597},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Park et al. - 2010 - XCREAM.pdf:pdf},
isbn = {9781450304214},
keywords = {RFID (radio frequency identifcation),USN (universal sensor network),XCREAM (XLogic collaborative RFID/USN-Enabled adap,collaboration,middleware framework},
month = {nov},
pages = {692},
publisher = {ACM Press},
title = {{XCREAM}},
url = {http://dl.acm.org/citation.cfm?id=1967486.1967597},
year = {2010}
}
@misc{OMG2007,
annote = {<m:note>More definition of 'smart transducer', use in combination with elmenreich.</m:note>},
author = {OMG},
title = {{Smart Transducer Interface Specification}},
url = {http://www.omg.org/docs/formal/03-01-01.pdf},
year = {2007}
}
@inproceedings{Gilsinn,
abstract = {NIST started working with industry and the Institute of Electrical and Electronics Engineers (IEEE) in the mid 90's to develop a standardized interface to network smart sensors. With the spread of wireless technology, more industries are looking to incorporate wireless communications into their products and manufacturing processes. This paper discusses the IEEE 1451 standard interface for smart sensors, emerging wireless communication technologies, and possible solutions for creating a wireless interface for the IEEE 1451 standard},
annote = {<m:note><m:note>Discusses the IEEE 1451 standard for smart sensors, emerging wireless<m:linebreak/>communication technologies {\&}amp; possible solutions for creating a wireless<m:linebreak/>interface for the IEEE 1451 standard.<m:linebreak/>        <m:linebreak/>*** Did such a wireless interface already come into being since this '91<m:linebreak/>paper {\&}amp; before the 2008 paper above? I suspect that the integration with<m:linebreak/>bluetooth/zigbee/whatever is this '91 paper realised? Check.***</m:note></m:note>},
author = {Gilsinn, J.D. and Lee, K.},
booktitle = {SIcon/01. Sensors for Industry Conference. Proceedings of the First ISA/IEEE. Sensors for Industry Conference (Cat. No.01EX459)},
doi = {10.1109/SFICON.2001.968497},
isbn = {0-7803-6659-X},
pages = {45--50},
publisher = {IEEE},
title = {{Wireless interfaces for IEEE 1451 sensor networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=968497}
}
@article{Song2008,
abstract = {This article introduces the IEEE 1451 standard for networked smart transducers. It discusses the concepts of smart transducers, IEEE 1451 smart transducers, the architecture of the IEEE 1451 family of standards, application of IEEE 1451, and example implementations of the IEEE 1451 standards. In conclusion, the IEEE 1451 suite of standards provides a set of standard interfaces for networked smart transducers, helping to achieve sensor plug and play and interoperability for industry and government.},
annote = {<m:note><m:note>IEEE Instrumentation {\&}amp; Measurement Magazine article, very good explanat-<m:linebreak/>-ion of IEEE 1451, TIM {\&}amp; NCAP, definitions of transducer {\&}amp; smart transd-<m:linebreak/>-ucer, TEDS, integration with bluetooth/zigbee, etc. Very nice article!<m:linebreak/>        <m:linebreak/>Definition of 'transducer' {\&}amp; 'smart transducer' (latter is a reference<m:linebreak/>to elmenreich.</m:note></m:note>},
author = {Song, Eugene and Lee, Kang},
doi = {10.1109/MIM.2008.4483728},
issn = {1094-6969},
journal = {IEEE Instrumentation {\&} Measurement Magazine},
month = {apr},
number = {2},
pages = {11--17},
title = {{Understanding IEEE 1451-Networked smart transducer interface standard - What is a smart transducer?}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4483728},
volume = {11},
year = {2008}
}
@misc{OpenGeospatialConsortium,
annote = {<m:note>Videos/more information on demonostrations of SWE at OWS-4, covers the dirty bomb scenario.</m:note>},
author = {{Open Geospatial Consortium}, Inc.},
title = {{OWS-4 Demonstration}},
url = {http://www.opengeospatial.org/pub/www/ows4/index.html}
}
@article{Botts2008,
abstract = {The Open Geospatial Consortium (OGC) standards activities that focus on sensors and sensor networks comprise an OGC focus area known as Sensor Web Enablement (SWE). Readers interested in greater technical and architecture details can download the OGC SWE Architecture Discussion Paper titled “The OGC Sensor Web Enablement Architecture” (OGC document 06-021r1).},
address = {Berlin, Heidelberg},
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>OGC Sensor Web Enablement: Overview and High Level Architecture</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Botts, Mike; Percivall, George; Reed, Carl; Davidson, John )<m:linebreak/>        </m:bold>        <m:linebreak/>        <m:linebreak/>        <m:linebreak/>        <m:bold>From Duplicate 2 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>GeoSensor Networks</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Botts, Mike; Percivall, George; Reed, Carl; Davidson, John; Nittel, Silvia; Labrinidis, Alexandros; Stefanidis, Anthony )<m:linebreak/>        </m:bold>        <m:linebreak/>High level overview, gives details about interesting real world deployment (dirty bomb scenario).<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Botts, Mike and Percivall, George and Reed, Carl and Davidson, John and Nittel, Silvia and Labrinidis, Alexandros and Stefanidis, Anthony},
doi = {10.1007/978-3-540-79996-2},
editor = {Nittel, S and Labrinidis, A and Stefanidis, A},
institution = {Open Geospatial Consortium Inc.},
isbn = {978-3-540-79995-5},
issn = {0302-9743},
journal = {Lecture Notes in Computer Science},
keywords = {Computer Science},
number = {175},
pages = {175--190},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{GeoSensor Networks}},
url = {http://www.springerlink.com/index/ux1224j76264g8j4.pdf http://www.springerlink.com/content/ux1224j76264g8j4/},
volume = {4540},
year = {2008}
}
@article{Juarez2009,
annote = {<m:note>I would consider a robot to be a specific type or grouping of multiple actuators, so I wouldn't agree<m:linebreak/>that we need standards specifically for allowing communication between robots and virtual worlds, but<m:linebreak/>that a framework (such as ISO/IEC 23005) that allows media {\&}amp; control information to flow between real<m:linebreak/>{\&}amp; virtual worlds should allow for the control {\&}amp; interaction of virtual worlds with robots. So this is<m:linebreak/>an application of cross reality, essentially.</m:note>},
author = {Juarez, Alex and Bartneck, Christoph and Feijs, Lou},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{On the creation of standards for interaction between real robots and virtual worlds}},
url = {http://journals.tdl.org/jvwr/article/view/655},
volume = {2},
year = {2009}
}
@article{Janer2009,
annote = {<m:note>Talks about the importance of sound {\&}amp; not just graphics for virtual worlds {\&}amp; how sounds are difficult<m:linebreak/>when users are creating their own objects, unless a framework is adopted for finding sounds from a<m:linebreak/>free to access repository using metadata, machine learning, etc. Not particularly useful in general<m:linebreak/>for cross reality, but emphasises the importance of standards for further virtual world adoption.</m:note>},
author = {Janer, Jordi and Finney, Nathaniel and Roma, Gerard and Kersten, Stefan and Serra, Xavier},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Supporting Soundscape Design in Virtual Environments with Content-based Audio Retrieval}},
url = {http://journals.tdl.org/jvwr/article/view/635/523},
volume = {2},
year = {2009}
}
@article{Jakobs2009,
annote = {<m:note>Only mentions virtual worlds very briefly in the introduction {\&}amp; the summary, the main bulk of the paper<m:linebreak/>talks about the organisation of national {\&}amp; international standards organisations {\&}amp; why it is difficult<m:linebreak/>to come to agreement etc., but in a very discipline-independent way {\&}amp; only brings virtual worlds back<m:linebreak/>into the discussion in the summary at the very end of the paper. So not overly useful.</m:note>},
author = {Jakobs, Kai},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Real Standards for Virtual Worlds – Why and How?}},
url = {http://journals.tdl.org/jvwr/article/view/717},
volume = {2},
year = {2009}
}
@article{Bloomfield2009,
annote = {<m:note>Long piece on the possible creation of a future virtual world usable for simulating complex<m:linebreak/>real world business/financial interactions. Has a lot of background about virtual worlds {\&}amp;<m:linebreak/>an account of first experience with Second Life as well.</m:note>},
author = {Bloomfield, Robert},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{World of Bizcraft}},
url = {http://journals.tdl.org/jvwr/article/view/743/535},
volume = {2},
year = {2009}
}
@inproceedings{Roussou2002,
annote = {<m:note>Very good introduction to the use of virtual reality in the realm of heritage, lots of useful definitions.

{\&}quot;The use of immersive VR technology accounts almost a decade of research{\&}quot; (as of publication in 2000)

{\&}quot;a tool for the study and presentation of the past{\&}quot;

{\&}quot;the visualization of abstract concepts and ideas, spaces that are unreachable or no longer exist, or objects
that must be examined from diverse and unique points of view{\&}quot;

{\&}quot;heritage refers to the study of human activity not only through the recovery of remains, as is the case
with archaeology, but also through tradition, art {\&}amp; cultural evidences, narratives, etc.{\&}quot;

{\&}quot;To virtualize heritage means to atcualize it digitally, to simulate it using computer graphics technology...{\&}quot;

Lots more, etc.</m:note>},
author = {Roussou, Maria},
booktitle = {VAST 2000 Euroconference},
pages = {93--100},
publisher = {BAR International Series 1075, Oxford, Archaeopress},
title = {{Virtual Heritage : From the Research Lab to the Broad Public}},
url = {http://www.makebelieve.gr/mr/research/papers/VAST/VAST{\_}00/mroussou{\_}VAST00{\_}press.pdf},
year = {2002}
}
@article{Levoy1999,
annote = {<m:note>Very interesting project by Stanford using laser rangefinders/scanners to digitize Michelangelo's David {\&}amp; other
statues as well as other artefacts {\&}amp; parts of the museum buildings themselves.</m:note>},
author = {Levoy, Marc},
isbn = {0-7695-0062-5},
month = {oct},
pages = {2--11},
title = {{The digital michelangelo project}},
url = {http://dl.acm.org/citation.cfm?id=1889712.1889714},
year = {1999}
}
@inproceedings{Dikaiakou2003,
abstract = {This paper presents our initial results in producing a 3D model of the Chrysaliniotisa Quarter in Nicosia using the GIS data of the region, and an analysis of the structure of the areas buildings. We tried to create a partly-automatic system, which was aimed at producing a realistic model of the geometry and architectural style of the district, rather than an exact reconstruction of every detail. The residential buildings of the particular area follow some well defined architectural styles, which allows us to follow an automatic building generation, based on the 2D digital data and a library of predefined 3D building blocks. Starting from the GIS file, the data is sorted, examined and processed to detect the houses features and style as accurately as possible. The 3D model is then constructed by stitching together the appropriate blocks from the component library. Besides the automatic-generation method, we have used ImageModeler from RealViz to create accurate 3D representations of landmarks and exceptional buildings as well as for the building blocks.},
annote = {<m:note>Accurate 3D model/recreation of a substantial urban area, using partly automated construction/rendering
of similar building styles/types.</m:note>},
author = {Dikaiakou, M and Efthymiou, A and Chrysanthou, Yiorgos},
booktitle = {VAST},
doi = {http://dx.doi.org/10.2312/VAST/VAST03/061-070},
keywords = {Typology,automatic reconstruction,component based modelling,urban environment},
pages = {61--70},
title = {{Modelling the Walled City of Nicosia}},
url = {http://dx.doi.org/10.2312/VAST/VAST03/061-070},
year = {2003}
}
@inproceedings{Sundstedt2004,
address = {New York, New York, USA},
annote = {<m:note>Talks about the importance of accuracy to archaeology {\&}amp; the practical methodology that should be adopted to
create a truly high fidelity reconstruction of an archaeological site, paying particular interest to the
accuracy of the lighting (measuring emission spectra of different oils burning {\&}amp; everything!). Spurred by the
fact that {\&}quot;there are very few high fidelity reconstructions that attempt to authentically represent how a
site may have been perceived in the past. Crucial to this accurate perception is the need to correctly
model the ancient lighting.{\&}quot;

Most self-defined virtual worlds (eg Second Life, OpenSim, etc.) don't have complex enough rendering/lighitng
engines for this (except Avatar Reality, based on some version of CryEngine).

Used Maya in combination with Radiance, a suite of tools for lighting simulation. Allows archaeologists to
determine how light would have fallen on different parts of structures in their original (non-ruined) conditions
{\&}amp; in their original locations (the Kalabsha was moved) to make new discoveries about the role of light in
these structures.</m:note>},
author = {Sundstedt, Veronica and Chalmers, Alan and Martinez, Philippe},
booktitle = {Proceedings of the 3rd international conference on Computer graphics, virtual reality, visualisation and interaction in Africa - AFRIGRAPH '04},
doi = {10.1145/1029949.1029970},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sundstedt, Chalmers, Martinez - 2004 - High fidelity reconstruction of the ancient Egyptian temple of Kalabsha.pdf:pdf},
isbn = {1581138636},
keywords = {ancient Egypt,high fidelity graphics,virtual archaeology},
month = {nov},
pages = {107},
publisher = {ACM Press},
title = {{High fidelity reconstruction of the ancient Egyptian temple of Kalabsha}},
url = {http://dl.acm.org/citation.cfm?id=1029949.1029970},
year = {2004}
}
@article{Remondino2009,
annote = {<m:note>Virtual digitization of the Great Inscription of Gortyna, Crete, using several different
digitizing techniques/equipments at different resolutions (more detailed the closer to the
area of interest, etc.).</m:note>},
author = {Remondino, Fabio and Girardi, Stefano and Rizzi, Alessandro and Gonzo, Lorenzo},
doi = {10.1145/1551676.1551678},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Remondino et al. - 2009 - 3D modeling of complex and detailed cultural heritage using multi-resolution data.pdf:pdf},
issn = {15564673},
journal = {Journal on Computing and Cultural Heritage},
keywords = {3D modeling,laser scanning,photogrammetry},
month = {jul},
number = {1},
pages = {1--20},
title = {{3D modeling of complex and detailed cultural heritage using multi-resolution data}},
url = {http://dl.acm.org/citation.cfm?id=1551676.1551678},
volume = {2},
year = {2009}
}
@inproceedings{Kim2009,
address = {New York, New York, USA},
author = {Kim, Kangsoo and Seo, Byung-Kuk and Han, Jae-Hyek and Park, Jong-Il},
booktitle = {Proceedings of the 8th International Conference on Virtual Reality Continuum and its Applications in Industry - VRCAI '09},
doi = {10.1145/1670252.1670325},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim et al. - 2009 - Augmented reality tour system for immersive experience of cultural heritage.pdf:pdf},
isbn = {9781605589121},
keywords = {augmented reality,cultural heritage tour system,virtual tours},
month = {dec},
pages = {323},
publisher = {ACM Press},
title = {{Augmented reality tour system for immersive experience of cultural heritage}},
url = {http://dl.acm.org/citation.cfm?id=1670252.1670325},
year = {2009}
}
@inproceedings{Seo2010,
address = {New York, New York, USA},
author = {Seo, Byung-Kuk and Kim, Kangsoo and Park, Jungsik and Park, Jong-Il},
booktitle = {Proceedings of the 9th ACM SIGGRAPH Conference on Virtual-Reality Continuum and its Applications in Industry - VRCAI '10},
doi = {10.1145/1900179.1900215},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seo et al. - 2010 - A tracking framework for augmented reality tours on cultural heritage sites.pdf:pdf},
isbn = {9781450304597},
keywords = {augmented reality,camera tracking,multimedia tour guides},
month = {dec},
pages = {169},
publisher = {ACM Press},
title = {{A tracking framework for augmented reality tours on cultural heritage sites}},
url = {http://dl.acm.org/citation.cfm?id=1900179.1900215},
year = {2010}
}
@inproceedings{Ruffaldi2008,
address = {New York, New York, USA},
annote = {Presentation of a virtual environment as something available for both desktop {\&}amp; immersive
visualisations. Construction of such 'information landscapes' requires preliminary design
effort by some developer.

In the related work section, mentions large scale (city scale) virtual reproductions {\&}amp;
several examples of 3D virtual cultural heritage using various technologies (some even
allowing haptic interfaces) finally mentioning the existence of many virtual cultural
heritage things in Second Life ('applications of real-time 3D graphics... ...which need
dedicated clients').

Explains that virtual reality does not anchor to physical reality - 3D environments can
be entirely synthetic, can model a real world location or a museum that doesn't exist in
the real world at all.},
author = {Ruffaldi, Emanuele and Evangelista, Chiara and Neri, Veronica and Carrozzino, Marcello and Bergamasco, Massimo},
booktitle = {Proceedings of the 3rd international conference on Digital Interactive Media in Entertainment and Arts - DIMEA '08},
doi = {10.1145/1413634.1413659},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruffaldi et al. - 2008 - Design of information landscapes for cultural heritage content.pdf:pdf},
isbn = {9781605582481},
keywords = {cultural heritage,virtual reality,visualization},
month = {sep},
pages = {113},
publisher = {ACM Press},
title = {{Design of information landscapes for cultural heritage content}},
url = {http://dl.acm.org/citation.cfm?id=1413634.1413659},
year = {2008}
}
@inproceedings{Christou2006,
address = {New York, New York, USA},
annote = {Uses a CAVE with a 2-armed haptic interface. Applicability of haptic interfaces for cross
reality?

Useful quote for the shortcomings of self-proclaimed virtual worlds - {\&}quot;Such environments suffer
either from a lack of realism or a low degree of interactivity, due to technological and
methodological constraints.{\&}quot;.},
author = {Christou, Chris and Angus, Cameron and Loscos, Celine and Dettori, Andrea and Roussou, Maria},
booktitle = {Proceedings of the ACM symposium on Virtual reality software and technology - VRST '06},
doi = {10.1145/1180495.1180523},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Christou et al. - 2006 - A versatile large-scale multimodal VR system for cultural heritage visualization.pdf:pdf},
isbn = {1595933212},
keywords = {haptics,multimodal Interfaces,virtual heritage},
month = {nov},
pages = {133},
publisher = {ACM Press},
title = {{A versatile large-scale multimodal VR system for cultural heritage visualization}},
url = {http://dl.acm.org/citation.cfm?id=1180495.1180523},
year = {2006}
}
@article{Ikeuchi2003,
annote = {Research on digital preservation of cultural assets (in this case statues of Buddha) {\&}amp;
digital restoration of their original appearance. Gets very maths-ey.

Usable quote - {\&}quot;Currently, a large number of cultural heritage objects around the world
are deteriorating or being destroyed because of natural weathering, disasters and civil wars.{\&}quot;},
author = {Ikeuchi, Katsushi and Nakazawa, Atsushi and Hasegawa, Kazuhide and Ohishi, Takeshi},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ikeuchi et al. - 2003 - The Great Buddha Project Modeling Cultural Heritage for VR Systems through Observation.pdf:pdf},
isbn = {0-7695-2006-5},
journal = {Proceedings of the Second IEEE and ACM International Symposium on Mixed and Augmented Reality},
month = {oct},
pages = {7},
title = {{The Great Buddha Project: Modeling Cultural Heritage for VR Systems through Observation}},
url = {http://dl.acm.org/citation.cfm?id=946248.946860},
year = {2003}
}
@misc{Marketwire2008,
annote = {<m:note>News site coverage of the announcement of IBM's 3-D Data Center technology, mostly just repeats what's<m:linebreak/>in the official press release.</m:note>},
author = {Marketwire},
title = {{IBM 3-D Data Centers Show Virtual Worlds Fit for Business}},
url = {http://www.marketwire.com/press-release/ibm-3-d-data-centers-show-virtual-worlds-fit-for-business-nyse-ibm-823627.htm},
year = {2008}
}
@misc{IBM2008,
annote = {Press release for IBM's 3-D Data Center technology and Holographic Enterprise Network middleware.
Used by Implenia (the guys who headed the Eolus One project) to further the ability of their building
management virtual world interface to control HVAC/etc. to effect reductions in energy consumption, etc.},
author = {IBM},
title = {{Made in IBM Labs: IBM 3-D Data Centers Show Virtual Worlds Fit for Business}},
url = {http://www-03.ibm.com/press/us/en/pressrelease/23565.wss},
year = {2008}
}
@article{Fillinger2009,
abstract = {Looks at the data and metrology tools developed by The National Institute of Standards and Technology for the research community, including common middleware for distributed sensor data acquisition and processing.},
annote = {<m:note>Rather technical discussion of NIST's middleware for distributed sensor<m:linebreak/>data aquisition {\&}amp; processing. Heavily focused on data-flow, not of<m:linebreak/>particular interest to cross reality but does have a nice 1 paragraph<m:linebreak/>summary/description of Global Sensor Networks (GSN).</m:note>},
author = {Fillinger, Antoine and Hamchi, Imad and Degre, St{\'{e}}phane and Diduch, Lukas L. and Rose, Travis and Fiscus, Jonathan and Stanford, Vincent},
doi = {10.1109/MPRV.2009.50},
issn = {1536-1268},
journal = {IEEE Pervasive Computing},
month = {jul},
number = {3},
pages = {74--83},
title = {{Middleware and Metrology for the Pervasive Future}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165564},
volume = {8},
year = {2009}
}
@article{Yankelovich2009,
abstract = {Considers present and future practical applications of cross-reality. From tools to build new 3D virtual worlds to the products of those tools, cross-reality is becoming a staple of our everyday reality. Practical applications of cross-reality include the ability to virtually visit a factory to manage and maintain resources from the comfort of your laptop or desktop PC as well as sentient visors that augment reality with additional information so that users can make more informed choices. Tools and projects considered are:Project Wonderland for multiuser mixed reality;ClearWorlds: mixed- reality presence through virtual clearboards; VICI (Visualization of Immersive and Contextual Information) for ubiquitous augmented reality based on a tangible user interface; Mirror World Chocolate Factory; and sentient visors for browsing the world.},
annote = {<m:note>Briefly discusses 5 current {\&}amp; future applications of cross reality,<m:linebreak/>however by my definitions none of these 5 are cross reality but just<m:linebreak/>augmented reality or augmented virtuality. The chocolate factory example<m:linebreak/>is however interesting - taking real time sensor data from the real<m:linebreak/>factory {\&}amp; using it to update a virtual simulation of the factory.</m:note>},
author = {Yankelovich, Nicole and Slott, Jordan and Hill, Alex and Bonner, Matt and Schiefer, Jacob and MacIntyre, Blair and Mugellini, Elena and Khaled, Omar Abou and Barras, Fr{\'{e}}d{\'{e}}ric and Bapst, Jacques and Back, Maribeth and Aviles-Lopez, Edgardo and Garcia-Macias, J. Antonio},
doi = {10.1109/MPRV.2009.41},
issn = {1536-1268},
journal = {IEEE Pervasive Computing},
month = {jul},
number = {3},
pages = {55--57},
title = {{Building and Employing Cross-Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165561},
volume = {8},
year = {2009}
}
@article{Horn2009,
abstract = {Outlines the Meru Project at Stanford University is designing and implementing an architecture for the virtual worlds of the future. The hope is that we can avoid some of the complexities the Web has encountered by learning how to build applications and services before they are subject to the short-term necessities of commercial development. While Meru cannot compete with the content creation of commercial virtual worlds, it can, like the original World Wide Web at CERN, investigate basic questions about system design. By doing so, the door can be opened to a future where physical sensors in the real world seed their virtual reflections, users can visually browse a sea of information, and virtual avatars convey physical social cues to bring distance interaction to the level of actual presence.},
annote = {<m:note><m:note>Talks about the scalability problems of todays virtual worlds (both<m:linebreak/>self proclaimed 'virtual worlds' like Second Life {\&}amp; online games like<m:linebreak/>WoW {\&}amp; Eve Online). Proposes the Meru Project (Stanford) as a virtual<m:linebreak/>world architecture that can scale to global scales by modelling the<m:linebreak/>virtual world after the real world - eg using distance to determine the<m:linebreak/>detail/bandwidth with which to render an object.<m:linebreak/>        <m:linebreak/>Envisages cross reality by a special 'space zero' within which physical<m:linebreak/>objects can register themselves {\&}amp; thus advertise their presence {\&}amp;<m:linebreak/>location to users of the virtual world. Nice example of a real person<m:linebreak/>walking down a street in the real world {\&}amp; an avatar's position in space<m:linebreak/>zero being updated by GPS, with shop owners who have registered their<m:linebreak/>shops with space zero able to advertise specials to the avatar.<m:linebreak/>        <m:linebreak/>Also makes the point that, just like with the real web, it won't always<m:linebreak/>be actual users observing the virtual world, it may well be scripts/bots<m:linebreak/>that, for example, comb/search through specials.</m:note></m:note>},
author = {Horn, Daniel and Cheslack-Postava, Ewen and Azim, Tahir and Freedman, Michael J. and Levis, Philip},
doi = {10.1109/MPRV.2009.54},
issn = {1536-1268},
journal = {IEEE Pervasive Computing},
month = {jul},
number = {3},
pages = {50--54},
title = {{Scaling Virtual Worlds with a Physical Metaphor}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165560},
volume = {8},
year = {2009}
}
@article{Dindar2009,
abstract = {Complex event processing (CEP) is an essential functionality for cross-reality environments. Through CEP, we can turn raw sensor data generated in the real world into more meaningful information that has some significance for the virtual world. In this article, the authors present DejaVu, a general-purpose event processing system built at ETH Zurich. SmartRFLib, a cross-reality application, builds on DejaVu and enables real-time event detection over RFID data streams feeding a virtual library on second life.},
annote = {<m:note><m:note>Discusses the importance of higher level inference techniques to make<m:linebreak/>sense of phenomena detected by sensor networks, presenting it as an<m:linebreak/>essential functionality of cross reality environments. Lifton touched<m:linebreak/>on such a thing in his PhD, talking about how looking at vibration data<m:linebreak/>could tell you whether a lamp was plugged in before being turned on etc.<m:linebreak/>        <m:linebreak/>Presents DejaVu, an event processing system, that works along with an<m:linebreak/>example cross reality application that feeds real world RFID data into<m:linebreak/>a virtual library in Second Life.</m:note></m:note>},
author = {Dindar, Nihal and Balkesen, {\c{C}}agri and Kromwijk, Katina and Tatbul, Nesime},
doi = {10.1109/MPRV.2009.43},
issn = {1536-1268},
journal = {IEEE Pervasive Computing},
month = {jul},
number = {3},
pages = {34--41},
title = {{Event Processing Support for Cross-Reality Environments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165558},
volume = {8},
year = {2009}
}
@article{Want2009,
abstract = {EIC Roy Want introduces the special issue on cross-reality environments and discusses alternate realities including virtual reality, augmented reality, embodied virtuality, cross-reality, and mixed reality.},
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Through Tinted Eyeglasses</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Want, Roy )<m:linebreak/>        </m:bold>        <m:linebreak/>Introduction to the issue about cross reality, tries to define the<m:linebreak/>different types of alternate realities (VR, AR, ER, MR) but I believe<m:linebreak/>his definition of cross reality to be wrong (he describes what I<m:linebreak/>consider augmented virtuality).<m:linebreak/>        <m:linebreak/>Features a 2x2 matrix that shows the relation between the different<m:linebreak/>alternate realities. Where he has cross reality (top left) I would place<m:linebreak/>augmented virtuality.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Want, Roy},
doi = {10.1109/MPRV.2009.58},
issn = {1536-1268},
journal = {IEEE Pervasive Computing},
month = {jul},
number = {3},
pages = {2--4},
title = {{Through Tinted Eyeglasses}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165551},
volume = {8},
year = {2009}
}
@misc{Pardue,
author = {Pardue, Laurel and Dublon, Gershon and Jethwani, Anisha and Prouty, Jeffrey and Turner, Prouty and Joliat, Nicholas and Swartz, Noah and Paradiso, Joseph},
title = {{DoppelLab}},
url = {http://www.media.mit.edu/resenv/doppellab/}
}
@inproceedings{Lifton2007,
annote = {<m:note>Paper about the Tricorder handheld sensor network browser. Again, published before Lifton's PhD so more/up-to-date information about Tricorder is in the PhD.</m:note>},
author = {Lifton, Joshua and Mittal, Manas and Lapinski, Michael and Paradiso, Joseph},
booktitle = {Proceedings of the ACM CHI 2007 Conference - Mobile Spatial Interaction Workshop},
title = {{Tricorder: A mobile sensor network browser}},
year = {2007}
}
@inproceedings{Lifton2007b,
address = {New York, New York, USA},
annote = {Paper about the Plug sensor/actuator platform developed by the Media Lab for Lifton's research. Published before Lifton's PhD so doesn't contain as much information as the PhD does about Plug {\&}amp; its uses.},
author = {Lifton, Joshua and Feldmeier, Mark and Ono, Yasuhiro and Lewis, Cameron and Paradiso, Joseph A.},
booktitle = {Proceedings of the 6th international conference on Information processing in sensor networks - IPSN '07},
doi = {10.1145/1236360.1236377},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lifton et al. - 2007 - A Platform for Ubiquitous Sensor Deployment in Occupational and Domestic Environments.pdf:pdf},
isbn = {978159593638X},
month = {apr},
pages = {119},
publisher = {ACM Press},
title = {{A platform for ubiquitous sensor deployment in occupational and domestic environments}},
url = {http://dl.acm.org/citation.cfm?id=1236360.1236377},
year = {2007}
}
@article{Milgram1994,
abstract = {This paper focuses on Mixed Reality (MR) visual displays, a particular subset of Virtual Reality (VR) related technologies that involve the merging of real and virtual worlds somewhere along the "virtuality continuum" which connects completely real environments to completely virtual ones. Probably the best known of these is Augmented Reality (AR), which refers to all cases in which the display of an otherwise real environment is augmented by means of virtual (computer graphic) objects. The converse case on the virtuality continuum is therefore Augmented Virtuality (AV). Six classes of hybrid MR display environments are identified. However, an attempt to distinguish these classes on the basis of whether they are primarily video or computer graphics based, whether the real world is viewed directly or via some electronic display medium, whether the viewer is intended to feel part of the world or on the outside looking in, and whether or not the scale of the display is intended to map orthoscopically onto the real world leads to quite different groupings among the six identified classes, thereby demonstrating the need for an efficient taxonomy, or classification framework, according to which essential differences can be identified. The 'obvious' distinction between the terms "real" and "virtual" is shown to have a number of different aspects, depending on whether one is dealing with real or virtual objects, real or virtual images, and direct or non-direct viewing of these. An (approximately) three dimensional taxonomy is proposed, comprising the following dimensions: Extent of World Knowledge ("how much do we know about the world being displayed?"), Reproduction Fidelity ("how 'realistically' are we able to display it?"), and Extent of Presence Metaphor ("what is the extent of the illusion that the observer is present within that world?").},
annote = {Professor at University of Toronoto, responsible for coming up with the
virtuality continuum in all of its different versions. Provides some
fairly high-level theoretical discussion of what distinguishes the
different alternate realities that computer science has come to explore,
including how to determine whether an environment is augmented reality
or augmented virtuality (eg at what point does a scene stop being
augmented reality {\&}amp; become augmented virtuality, etc.).



============


Brief introduction to mixed reality {\&}amp; to the virtuality continuum
between completely real environments {\&}amp; completely virtual environments.

Identifies 3 aspects that distinguish between real {\&}amp; virtual;
{\&}gt; extent of world knowledge
{\&}quot;how much do we know about the world being displayed?{\&}quot;
world unmodelled (computer knows nothing about the contents of the
environment) to world completely modelled (traditional virtual real-
-ity where the computer has complete knowledge about each object in
the environment)
{\&}gt; reproduction fidelity
{\&}quot;how realistically are we able to display it?{\&}quot;
pertains to both real {\&}amp; virtual objects
{\&}gt; extent of prescence metaphor
{\&}quot;what is the extent of the illusion that the observer is present
within that world?{\&}quot;
mixed reality displays include highly immersive environments with a
strong presence metaphor, but also exocentric type AR displays

Identifies 6 different types of display technology that constitute mixed
reality interfaces.

Contains diagrams of virtuality continuum, extent of world knowledge,
reproduction fidelity {\&}amp; extent of presence metaphor (all linear).

Definition of virtual reality.},
author = {Milgram, Paul and Kishino, Fumio},
journal = {IEICE Trans. Information Systems},
keywords = {augmented reality (AR),mixed reality (MR),virtual reality (VR)},
number = {12},
pages = {1321--1329},
title = {{A Taxonomy of Mixed Reality Visual Displays}},
url = {http://etclab.mie.utoronto.ca/people/paul{\_}dir/IEICE94/ieice.html},
volume = {E77-D},
year = {1994}
}
@misc{OpenWonderlandFoundation,
author = {{Open Wonderland Foundation}},
title = {{Open source 3D virtual collaboration toolkit | Open Wonderland}},
url = {http://openwonderland.org/},
urldate = {2012-03-29}
}
@misc{Timmerer2008,
author = {Timmerer, Christian},
title = {{Representation of Sensory Effects: Call for Proposals}},
url = {http://multimediacommunication.blogspot.com/2008/05/representation-of-sensory-effects-call.html},
year = {2008}
}
@misc{Roush2007,
abstract = {The World Wide Web will soon be absorbed into the World Wide Sim: an environment combining elements of Second Life and Google Earth.},
annote = {Discussion about the 'second earth' concept that would arise from a combination/mashup between 'mirror worlds' (such as Google Earth) {\&}amp; 'virtual worlds' (such as Second Life).

Cited by Joshua Lifton in his PhD.

Technology Review is published by MIT, Wade Roush was staff at Technology Review for a number of years.

Another mention of Snow Crash's 'metaverse' {\&}amp; allusions to it. Also mentions Gibson's notion of 'consensual hallucinations' in Neuromancer.

{\&}quot;Second Life is a true virtual world, unconstrained by any resemblance to the real planet.{\&}quot; {\&}quot;These worlds are not games, however.{\&}quot;

The term 'mirror worlds' was coined by Yale CS David Gelernter (Artificial Intelligence is Lost in the Woods, another Technology Review article).

Introduces the concept of 'mobile augmented reality'; accessing the data from extensive 3D simulations via 2D displays on location aware phones or whatnot.

Points out that Second Life {\&}amp; Google Earth will probably endure as they are (with the usual upgrades) well into the metaverse era, rather than becoming the second earth concept embodied.

Lolworth quote - {\&}quot;...according to technology research firm Gartner, current trends suggest that 80 percent of active Internet users and FOrtune 500 companies will participate in Second Life or some competing virtual world by the end of 2011.{\&}quot;

{\&}quot;As it turns out, simulations need not be convincing to be enveloping.{\&}quot;

Mentions another vision of virtual earth; David Gelernter's 'Mirror Worlds: Or the day software puts the universe in a shoebox... how it will happen and what it will mean'.},
author = {Roush, Wade},
booktitle = {Technology Review},
title = {{Second Earth}},
url = {http://www.technologyreview.com/Infotech/18911/},
year = {2007}
}
@article{Lifton2009,
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Metaphor and Manifestation Cross-Reality with Ubiquitous Sensor/Actuator Networks</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Lifton, Joshua; Laibowitz, Mathew; Harry, Drew; Gong, Nan-Wei; Mittal, Manas; Paradiso, Joseph A. )<m:linebreak/>        </m:bold>        <m:linebreak/>Article from volume 8 issue 3 of IEEE Pervasive Computing magazine (the<m:linebreak/>one all about cross reality environments) that again essentially just<m:linebreak/>covers Lifton's PhD {\&}amp; the associated work/projects at the Media Lab.<m:linebreak/>        <m:linebreak/>Identifies commercial implementations of cross reality (IBM's data cent-<m:linebreak/>er operation visualization {\&}amp; VRContext's ProcessLife technology).<m:linebreak/>        <m:linebreak/>'wormholes' quote!<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Lifton, Joshua and Laibowitz, Mathew and Harry, Drew and Gong, Nan-wei and Mittal, Manas and Paradiso, Joseph A.},
doi = {10.1109/MPRV.2009.49},
issn = {1536-1268},
journal = {IEEE Pervasive Computing: Mobile and Ubiquitous Systems},
keywords = {IEEE,augmented reality,mixed reality,mobile computing,pervasive computing,privacy,sensor networks,ubiquitous media,virtual worlds},
month = {jul},
number = {3},
pages = {24--33},
title = {{Metaphor and Manifestation - Cross-Reality with Ubiquitous Sensor/Actuator Networks}},
url = {http://dl.acm.org/citation.cfm?id=1591886.1592128},
volume = {8},
year = {2009}
}
@inproceedings{roussou:photorealism,
annote = {<m:note>From Duplicate 1 ( Photorealism and Non-Photorealism in Virtual Heritage Representation - Maria Roussou, George Drettakis )

Definition of virtual heritage - {\&}quot;Virtual heritage, broadly defined, involves the synthesis, conservation,
reproduction, representation, digital reprocessing, and display of cultural evidence with the use of
advanced imaging technology.{\&}quot;

{\&}quot;...virtual heritage has long been concentrated on generating digital reconstructions of historical or
archaeological artefacts and sites with enough fidelity to be truly accurate representations of their real
world counterparts.{\&}quot;

Contrasts between photorealistic {\&}amp; non-photorealistic computer graphics and that for some users the realism
isn't the most important factor, but rather how believeable {\&}amp; convincing it is, regardless if the imagery
emulates the physical properties of the real world or not. More 'artistic' means of expression can that do
not necessarily hold true to a photographic view of a site can nonetheless be important to a user's understanding.

{\&}quot;In virtual heritage representation, architectural walkthroughs and picture-perfect simulations of objects
have defined a practice where photorealism is considered as perhaps the most important measure of a
successful representation.{\&}quot;

But...

{\&}quot;...the emphasis on achieving a high degree of realism runs the risk of limiting VR reconstruction to the
creation of historically accurate yet static worlds that leave little flexibility for interpretive and/or
educational use.{\&}quot;

So advanced realistic modelling techniques are good for accuracy {\&}amp; authenticity, but non-photorealistic methods
can provide appropriate tools for more flexible uses in virtual heritage applications. This paper tries to
combine both photorealism {\&}amp; interactivity into the same virtual reality framework under the CREATE project.

{\&}quot;...heritage is 'as much about the living and evolving place, people, and environment as it is about any
single static monument'{\&}quot;

{\&}quot;In the case of an archaeology scholar who intends to restore the ancient monument, the goal is to offer
the possibility to try varied reconstruction hypotheses and choose the most plausible.{\&}quot;</m:note>},
author = {Roussou, Maria and Drettakis, George and {Maria Roussou}, George Drettakis},
booktitle = {Proceedings of the International Symposium on Virtual Reality, Archeology and Cultural Heritage (VAST)},
title = {{Photorealism and Non-Photorealism in Virtual Heritage Representation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.9.8705},
year = {2003}
}
@misc{InternationalOrganizationforStandardization,
author = {{International Organization for Standardization (ISO)}},
howpublished = {$\backslash$url{\{}http://www.iso.org/iso/standards{\_}development/processes{\_}and{\_}procedures/stages{\_}description/stages{\_}table.htm{\#}s90{\}}},
title = {{International harmonized stage codes}},
url = {http://www.iso.org/iso/standards{\_}development/processes{\_}and{\_}procedures/stages{\_}description/stages{\_}table.htm{\#}s90}
}
@inproceedings{caballero:behand,
address = {New York, NY, USA},
author = {Caballero, Mar{\'{\i}}a and Chang, Ting-Ray and Men{\'{e}}ndez, Mar{\'{\i}}a and Occhialini, Valentina},
booktitle = {Proceedings of the 12th international conference on Human computer interaction with mobile devices and services},
doi = {http://doi.acm.org/10.1145/1851600.1851704},
isbn = {978-1-60558-835-3},
keywords = {3D,augmented virtuality,gestural interfaces,interaction strategies,manipulation,mixed reality,mobile devices},
pages = {451--454},
publisher = {ACM},
series = {MobileHCI '10},
title = {{Behand: augmented virtuality gestural interaction for mobile phones}},
url = {http://doi.acm.org/10.1145/1851600.1851704},
year = {2010}
}
@article{Bose2009,
abstract = {Sensor networks have come a long way since their humble beginnings in DARPA-funded academic research projects in the 1990s and have morphed into a significant research area in their own right. Over the last decade or so, networked sensing devices have become embedded all around us. In this article we look at how sensor network research and applications have evolved and how emerging trends could determine where they're headed.},
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Sensor Networks Motes, Smart Spaces, and Beyond</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Bose, Raja )<m:linebreak/>        </m:bold>        <m:linebreak/>A nice history of (wireless) sensor networks {\&}amp; what current research<m:linebreak/>into the paradigm is focused on. Has a section about 'first generation<m:linebreak/>sensor platforms' which includes Berkeley Motes (which includes the<m:linebreak/>Telos platform which the Tmotes I used for my SH Project are) {\&}amp; the<m:linebreak/>TinyOS operating system (including an identification that it is not<m:linebreak/>designed for easy {\&}amp; rapid application development nor for supporting<m:linebreak/>sophisticated applications. Also has a section on Phidgets, which I also<m:linebreak/>used in my SH Project.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Bose, Faja and Bose, Raja},
doi = {10.1109/MPRV.2009.55},
issn = {1536-1268},
journal = {Pervasive Computing, IEEE},
keywords = {ad-hoc network,remote base station,scientific appl},
month = {jul},
number = {3},
pages = {84--90},
title = {{Sensor Networks Motes, Smart Spaces, and Beyond}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165565},
volume = {8},
year = {2009}
}
@misc{InternationalOrganizationforStandardization2011,
author = {{International Organization for Standardization} and (ISO)},
title = {{ISO/IEC 23005-1:2011 - Information technology -- Media context and control -- Part 1: Architecture}},
url = {http://www.iso.org/iso/iso{\_}catalogue/catalogue{\_}tc/catalogue{\_}detail.htm?csnumber=54985},
year = {2011}
}
@inproceedings{vlahakis:archeoguide,
address = {New York, NY, USA},
annote = {<m:note>From Duplicate 2 ( Archeoguide - Vlahakis, Vassilios; Ioannidis, Nikos; Karigiannis, John; Tsotros, Manolis; Gounaris, Michael; Almeida, Luis; Stricker, Didier; Gleue, Tim; Christou, Ioannis T.; Carlucci, Renzo )

A system that provides on-site help {\&}amp; augmented reality reconstructions of ancient ruins. Claims to have
applications ranging from archaeological research to education to multimedia publishing and cultural
tourism.

Had a laptop, tablet computer {\&}amp; PDA version of the system, used GPS in some to ascertain location, compass
to ascertain direction {\&}amp; to augment reality accordingly.</m:note>},
author = {Vlahakis, Vassilios and Ioannidis, Nikos and Karigiannis, John and Tsotros, Manolis and Gounaris, Michael and Almeida, Luis and Stricker, Didier and Gleue, Tim and Christou, Ioannis T. and Carlucci, Renzo},
booktitle = {Proceedings of the 2001 conference on Virtual reality, archeology, and cultural heritage},
doi = {http://doi.acm.org/10.1145/584993.585015},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vlahakis et al. - 2001 - Archeoguide.pdf:pdf},
isbn = {1-58113-447-9},
keywords = {augmented reality,avatars,image rendering,mobile computing,position tracking},
month = {nov},
pages = {131--140},
publisher = {ACM},
series = {VAST '01},
title = {{Archeoguide: first results of an augmented reality, mobile computing system in cultural heritage sites}},
url = {http://doi.acm.org/10.1145/584993.585015 http://dl.acm.org/citation.cfm?id=584993.585015},
year = {2001}
}
@article{Ebling2009,
abstract = {New products related to the special issue on cross-reality environments are discussed including the Second Life island of learning created by Memorial University in Newfoundland, Canada, an iPhone application called iLiving, the new video game Tony Hawk: Ride, the nPower Personal Energy Generator, and the Bomo Baby Carriage.},
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Virtual Learning, Decorating, and Skateboarding</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Ebling, Maria; Corner, Mark )<m:linebreak/>        </m:bold>        <m:linebreak/>Describes some virtual reality {\&}amp; augmented reality products. Not really<m:linebreak/>that related to cross reality.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Ebling, Maria and Corner, Mark},
doi = {10.1109/MPRV.2009.61},
issn = {1536-1268},
journal = {Pervasive Computing, IEEE},
month = {jul},
number = {3},
pages = {6--7},
title = {{Virtual Learning, Decorating, and Skateboarding}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165553},
volume = {8},
year = {2009}
}
@inproceedings{harrison:bridging,
address = {New York, NY, USA},
author = {Harrison, Beverly and Fishkin, Kenneth and Gujar, Anuj and Portnov, Dmitriy and Want, Roy},
booktitle = {CHI '99 extended abstracts on Human factors in computing systems},
doi = {http://doi.acm.org/10.1145/632716.632738},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harrison et al. - 1999 - Bridging physical and virtual worlds with tagged documents, objects and locations.pdf:pdf},
isbn = {1-58113-158-5},
keywords = {RFID tag,augmented reality,phicon,physical UI,tangible interface,ubiquitous computing},
pages = {29--30},
publisher = {ACM},
series = {CHI EA '99},
title = {{Bridging physical and virtual worlds with tagged documents, objects and locations}},
url = {http://doi.acm.org/10.1145/632716.632738},
year = {1999}
}
@inproceedings{park:xcream,
address = {New York, NY, USA},
author = {Park, Kyungeun and Yun, Jekuk and Byun, Changhyun and Kim, Yanggon and Chang, Juno},
booktitle = {Proceedings of the 12th International Conference on Information Integration and Web-based Applications {\&}{\#}38; Services},
doi = {http://doi.acm.org/10.1145/1967486.1967597},
isbn = {978-1-4503-0421-4},
keywords = {RFID (radio frequency identifcation),USN (universal sensor network),XCREAM (XLogic collaborative RFID/USN-Enabled ada,collaboration,middleware framework},
pages = {692--695},
publisher = {ACM},
series = {iiWAS '10},
title = {{XCREAM: collaborative middleware framework for RFID/USN-enabled applications}},
url = {http://doi.acm.org/10.1145/1967486.1967597},
year = {2010}
}
@inproceedings{arvind:speckled,
annote = {From Duplicate 1 ( Speckled Computing: Disruptive Technology for Networked Information Appliances - Wong, K J; Arvind, D K )

Presents an emmerging technology in which data will be sensed in minute
(ultimately around 1mm{\^{}}3) semiconductor grains called Specks. The emmer-
-gence of such a technology would allow truly ubiquitous sensing which
would be great for cross reality systems.},
author = {Arvind, D K and Wong, K J},
booktitle = {Consumer Electronics, 2004 IEEE International Symposium on},
doi = {10.1109/ISCE.2004.1375940},
pages = {219--223},
title = {{Speckled computing: disruptive technology for networked information appliances}},
year = {2004}
}
@inproceedings{elmenreich:smarttransducer,
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Smart Transducers - Principles, Communications, and Configuration</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Wilfried Elmenreich, Stefan Pitzek )<m:linebreak/>        </m:bold>        <m:linebreak/>Definition of 'smart transducer'.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Elmenreich, Wilfried and Pitzek, Stefan and {Wilfried Elmenreich}, Stefan Pitzek},
booktitle = {In Proceedings of the 7th IEEE International Conference on Intelligent Engineering Systems},
pages = {510--515},
title = {{Smart Transducers - Principles, Communications, and Configuration}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.8516},
year = {2003}
}
@inproceedings{benko:collaborative,
abstract = {We present VITA (visual interaction tool for archaeology), an experimental collaborative mixed reality system for offsite visualization of an archaeological dig. Our system allows multiple users to visualize the dig site in a mixed reality environment in which tracked, see-through, head-worn displays are combined with a multi-user, multi-touch, projected table surface, a large screen display, and tracked hand-held displays. We focus on augmenting existing archaeological analysis methods with new ways to organize, visualize, and combine the standard 2D information available from an excavation (drawings, pictures, and notes) with textured, laser range-scanned 3D models of objects and the site itself. Users can combine speech, touch, and 3D hand gestures to interact multimodally with the environment. Preliminary user tests were conducted with archaeology researchers and students, and their feedback is presented here.},
address = {Washington, DC, USA},
annote = {<m:note>From Duplicate 2 ( Collaborative Mixed Reality Visualization of an Archaeological Excavation - Benko, H.; Ishak, E.W.; Feiner, S. )

Presents VITA (Visual Interaction Tool for Archaeology), a collaborative mixed reality system for
archaeological excavations.</m:note>},
author = {Benko, Hrvoje and Ishak, Edward W and Feiner, Steven},
booktitle = {Proceedings of the 3rd IEEE/ACM International Symposium on Mixed and Augmented Reality},
doi = {http://dx.doi.org/10.1109/ISMAR.2004.23},
isbn = {0-7695-2191-6},
pages = {132--140},
publisher = {IEEE Computer Society},
series = {ISMAR '04},
title = {{Collaborative Mixed Reality Visualization of an Archaeological Excavation}},
url = {http://dx.doi.org/10.1109/ISMAR.2004.23 http://ieeexplore.ieee.org/xpl/freeabs{\_}all.jsp?arnumber=1383050},
year = {2004}
}
@article{Coleman2009,
abstract = {This article discusses several networked media projects that use sensor technology to transmit data from real-world environments to virtual environments. The Eolus One project uses an experimental virtual control room to run building systems and provide a better communication network among its users. A 3D application design group called green phosphor creates code for translating n-dimensional information into 3D interactive formats for real-time effects. The Parsec voice controller system uses sonic inputs to control 3D graphical objects on the second life virtual platform. This article focuses on the design principles applied by the three projects at this experimental stage of x-reality design.},
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Using Sensor Inputs to Affect Virtual and Real Environments</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Coleman, Beth )<m:linebreak/>        </m:bold>        <m:linebreak/>Beth Coleman (MIT Comparative Media Studies {\&}amp; Program in Writing {\&}amp;<m:linebreak/>Humanistic Studies)<m:linebreak/>        <m:linebreak/>Definition of cross reality {\&}amp; use of the term x-reality.<m:linebreak/>        <m:linebreak/>Discusses 3 examples;Eolus One (real-estate), Green Phosphor (3D Interface Design,<m:linebreak/>world oil map example) {\&}amp; Parsec (control of a virtual environment using<m:linebreak/>voice).<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Coleman, Beth},
doi = {10.1109/MPRV.2009.60},
issn = {1536-1268},
journal = {Pervasive Computing, IEEE},
keywords = {3D application design,3D graphical object,3D inter},
month = {jul},
number = {3},
pages = {16--23},
title = {{Using Sensor Inputs to Affect Virtual and Real Environments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165556},
volume = {8},
year = {2009}
}
@inproceedings{lee:standard,
abstract = {The IEEE 1451 smart transducer interface standards provide the common interface and enabling technology for the connectivity of transducers to microprocessors, control and field networks, and data acquisition and instrumentation systems. The standardized TEDS specified by IEEE 1451.2 allows the self-description of sensors and the interfaces provide a standardized mechanism to facilitate the “Plug and play ” of sensors to networks. The network-independent smart transducer object model defined by IEEE 1451.1 allows sensor manufacturers to support multiple networks and protocols. Thus, transducer-to-network interoperability is on the horizon. The inclusion of P1451.3 and P1451.4 to the family of 1451 standards will meet the needs of the analog transducer users for high-speed applications. In the long run, transducer vendors and users, system integrators, and network providers can all benefit from the IEEE 1451 interface standards},
annote = {<m:note><m:note>        <m:bold>From Duplicate 2 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>IEEE 1451: A standard in support of smart transducer networking</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Kang, Lee )<m:linebreak/>        </m:bold>        <m:linebreak/>Published in 2000 when 1451.1 (common object model {\&}amp; interface specs for<m:linebreak/>components of a networkd smart transducer) {\&}amp; 1451.2 (transducers-to-NCAP<m:linebreak/>interface {\&}amp; TEDS for point-to-point configuration) were newly adopted<m:linebreak/>standards {\&}amp; 1451.3 (transducer-to-NCAP interface {\&}amp; TEDS using multi-drop<m:linebreak/>communication) {\&}amp; 1451.4 (mixed-mode interface for analog transducers<m:linebreak/>with analog {\&}amp; digital operating modes) were proposed standards. To put<m:linebreak/>this in context, in 2008 there was 1451.0 to 1451.7.<m:linebreak/>        <m:linebreak/>{\&}quot;... the IEEE 1451 project's aim is to reduce industry's effort to<m:linebreak/>develop and migrate to networked smart transducers{\&}quot;<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Kang, Lee and Lee, Kang},
booktitle = {Instrumentation and Measurement Technology Conference, 2000. IMTC 2000. Proceedings of the 17th IEEE},
doi = {10.1109/IMTC.2000.848791},
isbn = {0-7803-5890-2},
keywords = {IEEE 1451 interface standards,IEEE 1451.2,P1451.3},
pages = {525--528},
publisher = {IEEE},
title = {{IEEE 1451: A standard in support of smart transducer networking}},
url = {http://ieeexplore.ieee.org/xpl/freeabs{\_}all.jsp?arnumber=848791},
volume = {2},
year = {2000}
}
@article{Kansal2007,
abstract = {Peer-produced systems can achieve what might be infeasible for stand-alone systems developed by a single entity. The SenseWeb's goal is to enable these kinds of capabilities. Using SenseWeb, applications can initiate and access sensor data streams from shared sensors across the entire Internet. The SenseWeb infrastructure helps ensure optimal sensor selection for each application and efficient sharing of sensor streams among multiple applications.},
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>SenseWeb: An Infrastructure for Shared Sensing</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Kansal, Aman; Nath, Suman; Liu, Jie; Zhao, Feng )<m:linebreak/>        </m:bold>        <m:linebreak/>IEEE Multimedia mag article, provides a background/introduction to MS<m:linebreak/>SenseWeb, which enables peer production of sensing applications over<m:linebreak/>existing data networks.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Kansal, Aman and Nath, Suman and Liu, Jie and Zhao, Feng},
doi = {10.1109/MMUL.2007.82},
issn = {1070-986X},
journal = {Multimedia, IEEE},
keywords = {Internet,SenseWeb infrastructure,optimal sensor se},
month = {oct},
number = {4},
pages = {8--13},
title = {{SenseWeb: An Infrastructure for Shared Sensing}},
url = {http://ieeexplore.ieee.org/xpl/freeabs{\_}all.jsp?arnumber=4354151},
volume = {14},
year = {2007}
}
@inproceedings{walczak:applications,
address = {New York, NY, USA},
annote = {<m:note>From Duplicate 1 ( 


Cultural heritage applications of virtual reality


- Walczak, Krzysztof; White, Martin )



Summary/introduction to the Web3D 2003 Workshop W3, giving brief summaries of the presentations that took place, which included ARECHOGUIDE.</m:note>},
author = {Walczak, Krzysztof and White, Martin},
booktitle = {Proceedings of the eighth international conference on 3D Web technology},
doi = {http://doi.acm.org/10.1145/636593.636623},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walczak, White - 2003 - Cultural heritage applications of virtual reality.pdf:pdf},
isbn = {1-58113-644-7},
month = {mar},
pages = {182--183},
publisher = {ACM},
series = {Web3D '03},
title = {{Cultural heritage applications of virtual reality}},
url = {http://dl.acm.org/citation.cfm?id=636593.636623 http://doi.acm.org/10.1145/636593.636623},
year = {2003}
}
@misc{Fayolle2011,
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>The Concept of the Remote Laboratory</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Fayolle, Jacques )<m:linebreak/>        </m:bold>        <m:linebreak/>A citation to the concept of using Project Wonderland's application sharing feature to control lab<m:linebreak/>equipment remotely {\&}amp; then visualise the results (eg in 3D in the virtual world) by interacting with<m:linebreak/>external data sources, that is mentioned in Yankelovic article in IEEE Pervasive 'building and<m:linebreak/>employing cross-reality'.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Fayolle, Jacques},
howpublished = {$\backslash$url{\{}http://blogs.openwonderland.org/2011/01/28/remote-laboratories/{\}}},
month = {jan},
number = {28},
title = {{The Concept of the Remote Laboratory}},
url = {http://blogs.openwonderland.org/2011/01/28/remote-laboratories/},
year = {2011}
}
@phdthesis{Lifton2007a,
address = {Department of Media Arts and Sciences},
annote = {From Duplicate 1 ( Dual Reality: An Emerging Medium - Lifton, Joshua )

Lifton's PhD thesis, essentially the inaugural piece of work on cross
reality. He called it 'dual reality' at this point but it's exactly the
same thing (which he confirms). Has probably the very first
definition of dual reality, definition of sensor networks/ubicomp/VWs,
identifies the bidirectional nature of cross reality, discusses mapping
between real {\&}amp; virtual (whether it should be one-to-one or not), has a
survey of the earliest projects that did augmented virtuality, reference
to the 'second earth' concept, introduces the concept of 'virtual
sensing' which is a much better way to go about controlling actuation
from within the VW, identifies the platform-dependency of the Plug but
mentions that there is not much to stop it from being adapted to
different platforms, identifies that HTTP is pretty much the only means
of communicating with SL because XML-RPC is so useless, identifies the
lack of a standard middleware (with which to compare Plug etc. against),
mentions people maintaining an online presence, identifies that this
piece of work is 'framing dual reality as a new application domain for
sensor networks, virtual words {\&}amp; media creation' {\&}amp; identifies the
importance of automatic support to identify phenomena based on readings
from multiple sensed modalities.},
author = {Lifton, Joshua},
month = {sep},
school = {Massachusetts Institute of Technology},
title = {{Dual Reality: An Emerging Medium}},
type = {Ph.D. Dissertation},
year = {2007}
}
@inproceedings{lifton:merging,
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Dual Reality: Merging the Real and Virtual</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Lifton, Joshua; Paradiso, Joseph )<m:linebreak/>        </m:bold>        <m:linebreak/>Essentially a paper about the PhD. Good citation for dual reality<m:linebreak/>comprising 2 worlds that are complete unto themselves, but affect each<m:linebreak/>other through linkage by sensor/actuator infrastructure.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Lifton, Joshua and Paradiso, Joseph},
booktitle = {Proceedings of the First International ICST Conference on Facets of Virtual Environments (FaVE)},
month = {jul},
title = {{Dual Reality: Merging the Real and Virtual}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.147.9419},
year = {2009}
}
@misc{ITU2010,
annote = {<m:note><m:note>        <m:bold>From Duplicate 2 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Req.ITU-T Y.2221 Requirements for support of ubiquitous sensor network (USN) applications and services in the NGN environment</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - ITU )<m:linebreak/>        </m:bold>        <m:linebreak/>Provides a description {\&}amp; general characteristics of USN {\&}amp; USN applicati-<m:linebreak/>-ons {\&}amp; services. Also analyses the service requirements of USN applicat-<m:linebreak/>-ions {\&}amp; services {\&}amp; specifies the extended or new NGN capability require-<m:linebreak/>-ments based on the service requirements.<m:linebreak/>        <m:linebreak/>Good definition/description of what a USN is - conceptual network built<m:linebreak/>over existing physical networks which makes use of sensed data {\&}amp; provid-<m:linebreak/>-es knowledge services to anyone, anywhere {\&}amp; at any time {\&}amp; where inform-<m:linebreak/>-ation is generated by using context awareness.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {{International Telecommunication Union (ITU)}},
month = {jan},
title = {{Req.ITU-T Y.2221 Requirements for support of ubiquitous sensor network (USN) applications and services in the NGN environment}},
year = {2010}
}
@article{Baronti2007,
address = {Newton, MA, USA},
annote = {<m:note>Definition/description/background of Wireless Sensor Networks.</m:note>},
author = {Baronti, Paolo and Pillai, Prashant and Chook, Vince and Chessa, Stefano and Gotta, Alberto and Hu, Fun},
doi = {http://dx.doi.org/10.1016/j.comcom.2006.12.020},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baronti et al. - 2007 - Wireless sensor networks A survey on the state of the art and the 802.15.4 and ZigBee standards.pdf:pdf},
issn = {0140-3664},
journal = {Comput. Commun.},
number = {7},
pages = {1655--1695},
publisher = {Butterworth-Heinemann},
title = {{Wireless sensor networks: A survey on the state of the art and the 802.15.4 and ZigBee standards}},
volume = {30},
year = {2007}
}
@inproceedings{griffin:recovering,
address = {New York, NY, USA},
annote = {<m:note>Only an abstract of a talk about applying new technologies to helping cultural heritage, so
not particularly useful, but a nice quote about the usefulness of alternate realities for
cultural heritage;

{\&}quot;Many ancient artefacts are scattered about the world and reside in public and private collections, inaccessible to scholars and far removed from their original location and context of creation.{\&}quot;
</m:note>},
author = {Griffin, Stephen M.},
booktitle = {Proceedings of the international conference on Multimedia information retrieval},
doi = {http://doi.acm.org/10.1145/1743384.1743394},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Griffin - 2010 - Recovering the past through computation.pdf:pdf},
isbn = {978-1-60558-815-5},
keywords = {computing,culture,heritages},
month = {mar},
pages = {13--14},
publisher = {ACM},
series = {MIR '10},
title = {{Recovering the past through computation: new techniques for cultural heritage}},
url = {http://dl.acm.org/citation.cfm?id=1743384.1743394 http://doi.acm.org/10.1145/1743384.1743394},
year = {2010}
}
@misc{MIT,
annote = {From Duplicate 1 ( Responsive Environments Group - MIT )

MIT's Media Laboratory (particularly the Responsive Environments group
under the leadership of Joseph Paradiso) was responsible for essentially
the inaugural work in cross reality, with Joshua Lifton's PhD {\&}amp; the
associated projects in the group framing 'dual reality', as it was
originally known, as a new application domain for sensor/actuator
networks, virtual worlds {\&}amp; media creation. Lifton himself confirms that
cross reality {\&}amp; dual reality are the same thing by different names.},
author = {MIT},
howpublished = {$\backslash$url{\{}http://www.media.mit.edu/resenv/{\}}},
title = {{Responsive Environments Group}},
url = {http://www.media.mit.edu/resenv/}
}
@inproceedings{ardito:combining,
address = {New York, NY, USA},
annote = {Introduces the CHeR model, for creating, converting into digital form {\&}amp; maintaining the multitude of data related to cultural heritage sites. Observes that cultural heritage sites often arouse little involvement in young people, particularly when presented with the ruins of ancient settlements whose current appearance no longer reflects their original aspect and purpose.},
author = {Ardito, Carmelo and Costabile, Maria Francesca and Lanzilotti, Rosa and Simeone, Adalberto Lafcadio},
booktitle = {Proceedings of the 2010 ACM workshop on Social, adaptive and personalized multimedia interaction and access},
doi = {http://doi.acm.org/10.1145/1878061.1878077},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ardito et al. - 2010 - Combining multimedia resources for an engaging experience of cultural heritage.pdf:pdf},
isbn = {978-1-4503-0171-8},
keywords = {cultural heritage,multimedia},
month = {oct},
pages = {45--48},
publisher = {ACM},
series = {SAPMIA '10},
title = {{Combining multimedia resources for an engaging experience of cultural heritage}},
url = {http://dl.acm.org/citation.cfm?id=1878061.1878077 http://doi.acm.org/10.1145/1878061.1878077},
year = {2010}
}
@article{lee:distributed,
abstract = {This paper details a framework developed at NIST that highlights the standardization efforts going on within the various levels of an Internet-based distributed measurement and control (DMC) system. The framework highlights state-of-the-art hardware and software techniques used at NIST to design, implement, and deploy next-generation Internet-based DMC applications and systems. The framework targets three important areas of standardization including transducer interfaces, open network communication, and distributed application development. An implementation of a DMC application on the Internet based on the NIST framework is also described. The paper concludes with a brief introduction to other research activities at NIST culminating from this core Internet-based DMC research},
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Distributed measurement and control based on the IEEE 1451 smart transducer interface standards</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Lee, K.B.; Schneeman, R.D. )<m:linebreak/>        </m:bold>        <m:linebreak/>Describes the application of IEEE 1451 to Distributed Measurement {\&}amp;<m:linebreak/>Control systems in an open standards way rather than based on<m:linebreak/>proprietary approaches that had been the norm in industry before 2000.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Lee, Kang K.B. and Schneeman, Richard R.D.},
doi = {10.1109/19.850405},
issn = {0018-9456},
journal = {Instrumentation and Measurement, IEEE Transactions on},
keywords = {API,Ethernet,IEEE 1451,Internet-based system,TCP/I},
month = {jun},
number = {3},
pages = {621--627},
title = {{Distributed measurement and control based on the IEEE 1451 smart transducer interface standards}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=850405},
volume = {49},
year = {2000}
}
@article{Krueger2009,
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Universal Design for Virtual Worlds</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Krueger, Alice; Ludwig, Ann; Ludwig, David )<m:linebreak/>        </m:bold>        <m:linebreak/>A slightly strange article, talks about the importance of designing virtual worlds to be accessible<m:linebreak/>to the disabled (eg by having no steps in virtual worlds, just ramps, so that if a disabled person<m:linebreak/>represents themselves in the virtual world by an avatar restricted to a wheel chair they will still<m:linebreak/>be able to move around). Essentially an emphasis that virtual world locations should represent their<m:linebreak/>real ones accurately when it comes to access, tangentially related to the mimicing of a real world<m:linebreak/>location with a virtual environment simulation a la cross reality.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Krueger, Alice and Ludwig, Ann and Ludwig, David},
issn = {1941-8477},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Universal Design for Virtual Worlds}},
url = {http://journals.tdl.org/jvwr/article/view/674},
volume = {2},
year = {2009}
}
@inproceedings{deamicis:gamebased,
address = {New York, NY, USA},
annote = {From Duplicate 2 ( Game based technology to enhance the learning of history and cultural heritage - De Amicis, Raffaele; Girardi, Gabrio; Andreolli, Michele; Conti, Giuseppe )

Abstract only that talks about the use of game technologies to support learning of users within cultural heritage sites. Says that the level of realism is ideal to visualise cultural heritage if a string focus on the environment's atmosphere {\&}amp; immersion is required, {\&}quot;emphasising environmental effects such as fog, sky, water, particles{\&}quot;, all of which self-proclaimed virtual worlds aren't as good at.

Uses Unity3D! Mentions that it can produce web browser based applications as well as standalone ones, has a simple authoring interface {\&}amp; {\&}quot;exploits the latest graphical hardware by making extensive use of shaders to deliver high quality graphics{\&}quot;.},
author = {{De Amicis}, Raffaele and Girardi, Gabrio and Andreolli, Michele and Conti, Giuseppe and Amicis, Raffaele De},
booktitle = {Proceedings of the International Conference on Advances in Computer Enterntainment Technology},
doi = {http://doi.acm.org/10.1145/1690388.1690499},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Amicis et al. - 2009 - Game based technology to enhance the learning of history and cultural heritage.pdf:pdf},
isbn = {978-1-60558-864-3},
keywords = {3D reconstruction,cultural heritage,entertainment,game engine,interactive navigation,multimedia contents,virtual reality},
month = {oct},
pages = {451},
publisher = {ACM},
series = {ACE '09},
title = {{Game based technology to enhance the learning of history and cultural heritage}},
url = {http://doi.acm.org/10.1145/1690388.1690499 http://dl.acm.org/citation.cfm?id=1690388.1690499},
year = {2009}
}
@misc{UgoTrade2007,
annote = {From Duplicate 1 ( EOLUS Makes Leap To 3D Internet On Second Life - UgoTrade )

Background/history of the EOLUS One cross-reality real-estate mgmt project. Mediated between various different building
monitoring {\&}amp; automation platforms, represented in Second Life {\&}amp; had a
measurable beneficial effect on th energy usage of the buildings.},
author = {UgoTrade},
howpublished = {$\backslash$url{\{}http://www.ugotrade.com/2007/07/02/eolus-makes-leap-to-3d-internet-on-second-life/{\}}},
month = {jul},
number = {2},
title = {{EOLUS Makes Leap To 3D Internet On Second Life}},
url = {http://www.ugotrade.com/2007/07/02/eolus-makes-leap-to-3d-internet-on-second-life/},
year = {2007}
}
@inproceedings{wright:duality,
address = {New York, NY, USA},
author = {Wright, Mark and Ekeus, Henrik and Coyne, Richard and Stewart, James and Travlou, Penny and Williams, Robin},
booktitle = {Proceedings of the 2008 International Conference on Advances in Computer Entertainment Technology},
doi = {http://doi.acm.org/10.1145/1501750.1501812},
isbn = {978-1-60558-393-8},
keywords = {Second Life,augmented reality,metaverses,mobile phones,social networking},
pages = {263--266},
publisher = {ACM},
series = {ACE '08},
title = {{Augmented duality: overlapping a metaverse with the real world}},
url = {http://doi.acm.org/10.1145/1501750.1501812},
year = {2008}
}
@inproceedings{levoy:digitalmichelangelolong,
address = {New York, NY, USA},
annote = {<m:note>From Duplicate 1 ( The digital Michelangelo project - Levoy, Marc; Ginsberg, Jeremy; Shade, Jonathan; Fulk, Duane; Pulli, Kari; Curless, Brian; Rusinkiewicz, Szymon; Koller, David; Pereira, Lucas; Ginzton, Matt; Anderson, Sean; Davis, James )

More detail than in the 1999 paper.</m:note>},
author = {Levoy, Marc and Pulli, Kari and Curless, Brian and Rusinkiewicz, Szymon and Koller, David and Pereira, Lucas and Ginzton, Matt and Anderson, Sean and Davis, James and Ginsberg, Jeremy and Shade, Jonathan and Fulk, Duane},
booktitle = {Proceedings of the 27th annual conference on Computer graphics and interactive techniques},
doi = {http://dx.doi.org/10.1145/344779.344849},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Levoy et al. - 2000 - The digital Michelangelo project.pdf:pdf},
isbn = {1-58113-208-5},
keywords = {3D scanning,cultural heritage,graphics systems,mesh generation,range images,rangefinding,reflectance and shading models,sensor fusion},
month = {jul},
pages = {131--144},
publisher = {ACM Press/Addison-Wesley Publishing Co.},
series = {SIGGRAPH '00},
title = {{The digital Michelangelo project: 3D scanning of large statues}},
url = {http://dl.acm.org/citation.cfm?id=344779.344849 http://dx.doi.org/10.1145/344779.344849},
year = {2000}
}
@article{Paradiso2009,
abstract = {In this article, we define cross-reality as the union between ubiquitous sensor/actuator networks and shared online virtual worlds-a place where collective human perception meets the machines' view of pervasive computing. We describe how five of the articles in this issue expand on aspects of this theme.},
annote = {<m:note><m:note>        <m:bold>From Duplicate 2 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Guest Editors' Introduction: Cross-Reality Environments</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Paradiso, Joseph A.; Landay, James A. )<m:linebreak/>        </m:bold>        <m:linebreak/>Joseph Paradiso as guest editor introduces the section of the issue all<m:linebreak/>about cross reality. Has a few references to the technologies involved,<m:linebreak/>overviews of some of the articles, etc.<m:linebreak/>        <m:linebreak/>Definition of cross reality as 'the ubiquitous mixed reality environment<m:linebreak/>that comes from the fusion of these two technologies' (referring to<m:linebreak/>sensor/actuator networks {\&}amp; 3D virtual environments).<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Paradiso, Joseph A. and Landay, James A.},
doi = {10.1109/MPRV.2009.47},
issn = {1536-1268},
journal = {Pervasive Computing, IEEE},
month = {jul},
number = {3},
pages = {14--15},
title = {{Cross-Reality Environments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165555},
volume = {8},
year = {2009}
}
@inproceedings{lifton:adoption,
annote = {From Duplicate 1 ( Consumer Adoption of Cross Reality Systems - Lifton, Joshua )

Retrospective piece written by Lifton after moving from academia (MIT)
to industry (Electric Sheep Company) {\&}amp; then on to consultant {\&}amp; educator.
Lists observations of what has marred the wider uptake of cross reality.

{\&}gt; Second Life failed to achieve the consumer uptake it promised
{\&}gt; Adoption of hardware required for cross reality is slow; even now we
only have a smattering of sensors in common use (passport RFID, mobile
phone location/orientation, body-gesture in games consoles)
{\&}gt; Virtual worlds do not allow as much expression of identity as online
social networks, soon social networks may begin to fit the bill of VWs

Confirmation from Lifton himself that 'dual reality' {\&}amp; 'cross reality'
are the same thing under different names.},
author = {Lifton, Joshua},
booktitle = {Proceedings of the International Symposium on Ubiquitous Virtual Reality 2010 (ISUVR 2010)},
doi = {10.1109/ISUVR.2010.26},
isbn = {978-1-4244-7702-9},
keywords = {cross reality,dual reality,ubiquitous computing,ubiquitous virtual reality,virtual worlds},
month = {jul},
pages = {9--11},
publisher = {IEEE},
title = {{Consumer Adoption of Cross Reality Systems}},
url = {http://dl.acm.org/citation.cfm?id=1848072.1848338},
year = {2010}
}
@inproceedings{eishita:layar,
address = {New York, NY, USA},
author = {Eishita, Farjana and Stanley, Kevin},
booktitle = {Proceedings of the International Academic Conference on the Future of Game Design and Technology},
doi = {http://doi.acm.org/10.1145/1920778.1920811},
isbn = {978-1-4503-0235-7},
keywords = {APK,POI,augment reality (AR)},
pages = {219--222},
publisher = {ACM},
series = {Futureplay '10},
title = {{THEEMPA: simple AR games using layar}},
url = {http://doi.acm.org/10.1145/1920778.1920811},
year = {2010}
}
@article{Thomas2009,
abstract = {Looks at how through-walls collaboration lets users in the field work in real time with users indoors who have access to reference materials, a global picture, and advanced technology. The concept leverages ubiquitous workspaces, augmented reality, and wearable computers.},
annote = {<m:note><m:linebreak/>        <m:bold>From Duplicate 1 ( </m:bold><m:linebreak/>        <m:bold/><m:linebreak/>        <m:bold><m:linebreak/>          <m:italic>Through-Walls Collaboration</m:italic><m:linebreak/>        </m:bold><m:linebreak/>        <m:bold/><m:linebreak/>        <m:bold> - Piekarski, Wayne; Thomas, Bruce H. )<m:linebreak/><m:linebreak/>        </m:bold><m:linebreak/>        <m:linebreak/>An example more of augmented reality rather than cross reality, but<m:linebreak/>interesting nonetheless. Again, some of the wearable technologies<m:linebreak/>featured could be useful for a wearable virtual world client/interface.<m:linebreak/><m:linebreak/>        <m:linebreak/><m:linebreak/>      </m:note>},
author = {Thomas, Bruce H. and Piekarski, Wayne},
doi = {10.1109/MPRV.2009.59},
issn = {1536-1268},
journal = {Pervasive Computing, IEEE},
keywords = {augmented reality,input devices,mobile AR X-ray vi},
month = {jul},
number = {3},
pages = {42--49},
title = {{Through-Walls Collaboration}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165559},
volume = {8},
year = {2009}
}
@misc{UniversityofStAndrewsComputerScienceblog2011,
author = {{University of St Andrews Computer Science blog} and {of St Andrews}, School of Computer Science Blog},
howpublished = {$\backslash$url{\{}http://blogs.cs.st-andrews.ac.uk/csblog/2011/09/07/virtual-reconstruction-of-the-acropolis-basilica/{\}}},
month = {sep},
number = {7},
title = {{Virtual reconstruction of the Acropolis Basilica}},
url = {http://blogs.cs.st-andrews.ac.uk/csblog/2011/09/07/virtual-reconstruction-of-the-acropolis-basilica/},
year = {2011}
}
@article{Gelissen2009,
annote = {From Duplicate 1 ( Introduction to MPEG-V - Gelissen, Jean )

Written in 2009 when MPEG-V was still in development, it wouldn't be published as the ISO/IEC 23005 standard
until 2011. Serves nicely now as a retrospective as to the justification behind MPEG-V {\&}amp; to cross reality in
general. Lists many things that virtual worlds will be used for, which can essentially be seen as areas that
cross reality might be applicable.},
author = {Gelissen, Jean},
issn = {1941-8477},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Introduction to MPEG-V}},
url = {http://journals.tdl.org/jvwr/article/view/742/533},
volume = {2},
year = {2009}
}
@inproceedings{brandherm:simulation,
address = {Richland, SC},
annote = {From Duplicate 1 ( Simulation of sensor-based tracking in Second Life - Brandherm, Boris; Ullrich, Sebastian; Prendinger, Helmut )

Justification {\&}amp; demonstration of using Second Life as a platform for simulating sensor networks.},
author = {Brandherm, Boris and Ullrich, Sebastian and Prendinger, Helmut},
booktitle = {Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems: demo papers},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brandherm, Ullrich, Prendinger - 2008 - Simulation of sensor-based tracking in Second Life.pdf:pdf},
keywords = {Second Life,sensor networks,simulation,testbed},
month = {may},
pages = {1689--1690},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
series = {AAMAS '08},
title = {{Simulation of sensor-based tracking in Second Life}},
url = {http://dl.acm.org/citation.cfm?id=1402744.1402767},
year = {2008}
}
@article{Rosendale2009,
annote = {From Duplicate 1 ( Virtual Worlds, Collaboratively Built - Rosendale, Philip )

Short retrospective written by one of the Second Life developers about the importance of
standards {\&}amp; openness to the creation {\&}amp; continued development of Second Life, has some good
stuff about the importance that virtual worlds will hopefully represent in the future.},
author = {Rosendale, Philip},
issn = {1941-8477},
journal = {Journal of Virtual Worlds Research},
number = {3},
title = {{Virtual Worlds, Collaboratively Built}},
url = {http://journals.tdl.org/jvwr/article/view/670/507},
volume = {2},
year = {2009}
}
@article{Bishop2009,
address = {Inderscience Publishers, Geneva, SWITZERLAND},
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Enhancing the understanding of genres of web-based communities: the role of the ecological cognition framework</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Bishop, Jonathan )<m:linebreak/>        </m:bold>        <m:linebreak/>Definition of a virtual world as {\&}quot;a genre of online community comprising<m:linebreak/>three-dimensional graphical environments in which multiple users<m:linebreak/>interact with each other in addition to creating and interacting with<m:linebreak/>objects and the virtual environment around them{\&}quot;.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Bishop, Jonathan},
doi = {10.1504/IJWBC.2009.021558},
issn = {1477-8394},
journal = {Int. J. Web Based Communities},
keywords = {based communities,blogs,chat groups,classification,ecological cognition,genre theory,genres,message boards,online communities,subgenres,virtual communities,web{\&}{\#}45,web-based communities,weblogs},
month = {nov},
number = {1},
pages = {4--17},
publisher = {Inderscience Publishers},
title = {{Enhancing the understanding of genres of web{\&}{\#}45;based communities{\&}{\#}58; the role of the ecological cognition framework}},
url = {http://dl.acm.org/citation.cfm?id=1463643.1463644},
volume = {5},
year = {2009}
}
@misc{mit:doppel,
author = {MIT},
howpublished = {$\backslash$url{\{}http://www.media.mit.edu/resenv/doppellab/{\}}},
title = {{DoppelLab - Exploring Dense Sensor Network Data Through A Game Engine}}
}
@inproceedings{kim:practical,
address = {New York, NY, USA},
annote = {From Duplicate 1 ( Practical RFID + sensor convergence toward context-aware X-reality - Kim, Marie; Gak, Hwang Jae; Pyo, Cheol Sig )

Identifies that the main challenge of integrating RFID/sensor tech with
Second Life is the heterogeneity of the hardware {\&}amp; thus a Ubiquitous
Sensor Middleware (USN) is needed. Presents such a USN, COSMOS, which
integrates with RFID reader networks, sensor {\&}amp; actuator network {\&}amp; shows
how it functions as part of a cross reality system. COSMOS is tested
using software simulations of hardware.

Also one of the authors who use 'x-reality' more than 'cross reality'.

Nice quote {\&}quot;The important point of X-reality is a conceptiual paradigm
shift from single-directional information flows to bidirectional
information flows between two worlds.{\&}quot; etc.},
author = {Kim, Marie and Gak, Hwang Jae and Pyo, Cheol Sig},
booktitle = {Proceedings of the 2nd International Conference on Interaction Sciences: Information Technology, Culture and Human},
doi = {http://doi.acm.org/10.1145/1655925.1656115},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Gak, Pyo - 2009 - Practical RFID sensor convergence toward context-aware X-reality.pdf:pdf},
isbn = {978-1-60558-710-3},
keywords = {RFID,USN,actuator,middleware,sensor,x-reality},
month = {nov},
pages = {1049--1055},
publisher = {ACM},
series = {ICIS '09},
title = {{Practical RFID + sensor convergence toward context-aware X-reality}},
url = {http://dl.acm.org/citation.cfm?id=1655925.1656115 http://doi.acm.org/10.1145/1655925.1656115},
year = {2009}
}
@inproceedings{mcnamara:lightness,
address = {London, UK},
annote = {<m:note>From Duplicate 1 ( Comparing Real {\&}amp; Synthetic Scenes using Human Judgements of Lightness - McNamara, Ann; Chalmers, Alan; Troscianko, Tom; Gilchrist, Iain )

Compares how realistic computer generated scenes are compared to their real counterparts, by creating a scene
{\&}amp; lighting it in the real world {\&}amp; creating a computer simulation of the same {\&}amp; asking participants to
classify the two according to some system.

{\&}quot;...the ultimate goal being to create images which are perceptually indistinguishable from an actual scene.{\&}quot;</m:note>},
author = {McNamara, Ann and Chalmers, Alan and Troscianko, Tom and Gilchrist, Iain},
booktitle = {Proceedings of the Eurographics Workshop on Rendering Techniques 2000},
isbn = {3-211-83535-0},
month = {jun},
pages = {207--218},
publisher = {Springer-Verlag},
title = {{Comparing Real {\&} Synthetic Scenes using Human Judgements of Lightness}},
url = {http://dl.acm.org/citation.cfm?id=647652.732122},
year = {2000}
}
@article{Sivan2009,
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Overview: State of Virtual Worlds Standards in 2009</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Sivan, Yesha )<m:linebreak/>        </m:bold>        <m:linebreak/>Mainly just an overview/introduction to the issue, but has several useful definitions of concepts including virtual worlds themselves.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Sivan, Yesha},
issn = {1941-8477},
journal = {Journal of Virtual Worlds Research2},
number = {3},
title = {{Overview: State of Virtual Worlds Standards in 2009}},
url = {http://journals.tdl.org/jvwr/article/view/671/539},
volume = {2},
year = {2009}
}
@inproceedings{musolesi:thesecond,
author = {{Mirco Musolesi}, Emiliano Miluzzo and Musolesi, Mirco and Miluzzo, Emiliano and Lane, Nicholas D and Eisenman, Shane B and Choudhury, Tanzeem and Campbell, Andrew T},
booktitle = {In Proc. of HotEmNets ’08},
month = {jun},
title = {{The Second Life of a Sensor: Integrating Real-world Experience in Virtual Worlds using Mobile Phones}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.147.1457},
year = {2008}
}
@inproceedings{cabral:x3dexperience,
address = {New York, NY, USA},
author = {Cabral, Marcio and Zuffo, Marcelo and Ghirotti, Silvia and Belloc, Olavo and Nomura, Leonardo and Nagamura, Mario and Andrade, Fernanda and Faria, Regis and Ferraz, Leandro},
booktitle = {Proceedings of the twelfth international conference on 3D web technology},
doi = {http://doi.acm.org/10.1145/1229390.1229419},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cabral et al. - 2007 - An experience using X3D for virtual cultural heritage.pdf:pdf},
isbn = {978-1-59593-652-3},
keywords = {X3D,cultural heritage,interaction,virtual reality},
pages = {161--164},
publisher = {ACM},
series = {Web3D '07},
title = {{An experience using X3D for virtual cultural heritage}},
url = {http://doi.acm.org/10.1145/1229390.1229419},
year = {2007}
}
@inproceedings{coutrix:interaction,
address = {New York, NY, USA},
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Mixed reality</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Coutrix, C{\'{e}}line; Nigay, Laurence )<m:linebreak/>        </m:bold>        <m:linebreak/>Presents the Mixed Interaction model, that focuses on the link between<m:linebreak/>physical {\&}amp; digital worlds, providing a framework for guiding designers<m:linebreak/>to create interactive systems. Classified by descriptive/classification<m:linebreak/>power, generative power {\&}amp; comparative power. Unifies several approaches<m:linebreak/>to mixed reality systems (including augmented reality {\&}amp; augmented virtu-<m:linebreak/>-ality).<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Coutrix, C{\'{e}}line and Nigay, Laurence},
booktitle = {Proceedings of the working conference on Advanced visual interfaces},
doi = {http://doi.acm.org/10.1145/1133265.1133274},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Coutrix, Nigay - 2006 - Mixed reality.pdf:pdf},
isbn = {1-59593-353-0},
keywords = {augmented reality-virtuality,instrumental model,interaction modality,interaction model,mixed reality,multimodality},
month = {may},
pages = {43--50},
publisher = {ACM},
series = {AVI '06},
title = {{Mixed reality: a model of mixed interaction}},
url = {http://dl.acm.org/citation.cfm?id=1133265.1133274 http://doi.acm.org/10.1145/1133265.1133274},
year = {2006}
}
@article{Laycock2008,
address = {New York, NY, USA},
annote = {<m:note>From Duplicate 1 ( Exploring cultural heritage sites through space and time - Laycock, R. G.; Drinkwater, D.; Day, A. M. )

Using virtual cultural heritage to visualise the changes to a heritage site/object
with advancing time. Semi-automatic approach to creating a large virtual city using
replication of common buildings/building features.</m:note>},
author = {Laycock, R. G. and Drinkwater, D. and Day, A. M.},
doi = {http://doi.acm.org/10.1145/1434763.1434768},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laycock, Drinkwater, Day - 2008 - Exploring cultural heritage sites through space and time.pdf:pdf},
issn = {1556-4673},
journal = {J. Comput. Cult. Herit.},
keywords = {Urban modeling,interfaces},
month = {nov},
number = {2},
pages = {11:1----11:15},
publisher = {ACM},
title = {{Exploring cultural heritage sites through space and time}},
url = {http://dl.acm.org/citation.cfm?id=1434763.1434768 http://doi.acm.org/10.1145/1434763.1434768},
volume = {1},
year = {2008}
}
@misc{OpenGeospatialConsortiuma,
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>Welcome to the GSN Project</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Open Geospatial Consortium, Inc. )<m:linebreak/>        </m:bold>        <m:linebreak/>Homepage on the Web for the OGC GSN.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {{Open Geospatial Consortium}, Inc.},
howpublished = {$\backslash$url{\{}http://sourceforge.net/apps/trac/gsn/{\}}},
title = {{Welcome to the GSN Project}},
url = {http://sourceforge.net/apps/trac/gsn/}
}
@inproceedings{willmott:largecomplex,
address = {New York, NY, USA},
annote = {From Duplicate 1 ( Rendering of large and complex urban environments for real time heritage reconstructions - Willmott, J.; Wright, L. I.; Arnold, D. B.; Day, A. M. )

Presents a rendering package with heavy focus on optimizations such as not rendering buildings
that are obscured by buildings in front of them, rendering buildings features like windows into
the wall textures so from a distance it looks as though the windows are there so they only need to
actually be rendered at closer range {\&}amp; the difference is less noticeable.},
author = {Willmott, J. and Wright, L. I. and Arnold, D. B. and Day, A. M.},
booktitle = {Proceedings of the 2001 conference on Virtual reality, archeology, and cultural heritage},
doi = {http://doi.acm.org/10.1145/584993.585012},
file = {:home/cj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Willmott et al. - 2001 - Rendering of large and complex urban environments for real time heritage reconstructions.pdf:pdf},
isbn = {1-58113-447-9},
keywords = {ROAM,avatars,culling,level of detail,occluder shadows,openGL,urban environments,view frustum culling},
month = {nov},
pages = {111--120},
publisher = {ACM},
series = {VAST '01},
title = {{Rendering of large and complex urban environments for real time heritage reconstructions}},
url = {http://dl.acm.org/citation.cfm?id=584993.585012 http://doi.acm.org/10.1145/584993.585012},
year = {2001}
}
@article{Gintautas2007,
abstract = {We present experimental data on the limiting behavior of an interreality system comprising a virtual horizontally driven pendulum coupled to its real-world counterpart, where the interaction time scale is much shorter than the time scale of the dynamical system. We present experimental evidence that, if the physical parameters of the simplified virtual system match those of the real system within a certain tolerance, there is a transition from an uncorrelated dual reality state to a mixed reality state of the system in which the motion of the two pendula is highly correlated. The region in parameter space for stable solutions has an Arnold tongue structure for both the experimental data and a numerical simulation. As virtual systems better approximate real ones, even weak coupling in other interreality systems may produce sudden changes to mixed reality states.},
annote = {From Duplicate 1 ( Experimental evidence for mixed reality states in an interreality system. - Gintautas, Vadas; H{\"{u}}bler, Alfred W )

Physics paper presented results from an experiment involving a real
pendulum {\&}amp; a virtual pendulum that are linked together, moving from a
dual reality state where reality {\&}amp; virtual reality are uncorrelated, to
a mixed reality state in which reality {\&}amp; virtual reality are highly corre-
-lated.},
author = {Gintautas, Vadas and H{\"{u}}bler, Alfred W},
doi = {10.1103/PhysRevE.75.057201},
institution = {Center for Complex Systems Research, Department of Physics, University of Illinois at Urbana-Champaign, Urbana, Illinois 61801, USA. vgintau2@uiuc.edu},
journal = {Phys. Rev. E},
month = {may},
number = {5},
pages = {57201},
pmid = {17677199},
publisher = {American Physical Society},
title = {{Experimental evidence for mixed reality states in an interreality system}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17677199},
volume = {75},
year = {2007}
}
@article{Lukowicz2009,
abstract = {Do smart phones render wearable computers obsolete? Where does the rise of the smart phone leave wearable computing research? We answer these questions by examining past, present, and future of wearable platform research.},
annote = {<m:note><m:note>        <m:bold>From Duplicate 1 ( </m:bold>                <m:bold>          </m:bold><m:bold><m:italic>From Backpacks to Smartphones: Past, Present, and Future of Wearable Computers</m:italic></m:bold><m:bold>        </m:bold>                <m:bold> - Amft, Oliver; Lukowicz, Paul )<m:linebreak/>        </m:bold>        <m:linebreak/>Not really related to cross reality, but the wearable technologies<m:linebreak/>discussed could be useful parts of a wearable interface to a virtual<m:linebreak/>world.<m:linebreak/>        <m:linebreak/>      </m:note></m:note>},
author = {Lukowicz, Paul and Amft, Oliver},
doi = {10.1109/MPRV.2009.44},
issn = {1536-1268},
journal = {Pervasive Computing, IEEE},
keywords = {bi,smartphone,wearable computer,wearable computing},
month = {jul},
number = {3},
pages = {8--13},
title = {{From Backpacks to Smartphones: Past, Present, and Future of Wearable Computers}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165554},
volume = {8},
year = {2009}
}
