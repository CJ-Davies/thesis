<?xml version="1.0" encoding="UTF-8"?><xml><records><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Aberer, Karl</author><author>Hauswirth, Manfred</author><author>Salehi, Ali</author></authors></contributors><titles><title>The Global Sensor Networks middleware for efficient and flexible deployment and interconnection of sensor networks</title></titles><periodical/><keywords><keyword>NCCR-MICS</keyword><keyword>NCCR-MICS/CL4</keyword><keyword>sensor internetworking</keyword><keyword>sensor middleware</keyword><keyword>sensor networks</keyword></keywords><dates><year>2006</year></dates><notes>Good background/history/overview of GSN from EPFL, covering the arch-
-itecture &amp; an interesting example deployment. Also gives analysis of
performance/scalability.</notes><research-notes>Good background/history/overview of GSN from EPFL, covering the arch-
-itecture &amp; an interesting example deployment. Also gives analysis of
performance/scalability.</research-notes><urls/></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Ardito, Carmelo</author><author>Costabile, Maria Francesca</author><author>Lanzilotti, Rosa</author><author>Simeone, Adalberto Lafcadio</author></authors></contributors><titles><title>Combining multimedia resources for an engaging experience of cultural heritage</title><secondary-title>Proceedings of the 2010 ACM workshop on Social, adaptive and personalized multimedia interaction and access</secondary-title></titles><periodical><full-title>Proceedings of the 2010 ACM workshop on Social, adaptive and personalized multimedia interaction and access</full-title></periodical><pages>45-48</pages><keywords><keyword>cultural heritage</keyword><keyword>multimedia</keyword></keywords><dates><year>2010</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-4503-0171-8</isbn><electronic-resource-num>http://doi.acm.org/10.1145/1878061.1878077</electronic-resource-num><notes>        From Duplicate 1 (                           Combining multimedia resources for an engaging experience of cultural heritage                         - Ardito, Carmelo; Costabile, Maria Francesca; Lanzilotti, Rosa; Simeone, Adalberto Lafcadio )
                
Introduces the CHeR model, for creating, converting into digital form &amp; maintaining the
multitude of data related to cultural heritage sites. Observes that cultural heritage sites
often arouse little involvement in young people, particularly when presented with the ruins
of ancient settlements whose current appearance no longer reflects their original aspect and purpose.
        
      </notes><research-notes>        From Duplicate 1 (                           Combining multimedia resources for an engaging experience of cultural heritage                         - Ardito, Carmelo; Costabile, Maria Francesca; Lanzilotti, Rosa; Simeone, Adalberto Lafcadio )
                
Introduces the CHeR model, for creating, converting into digital form &amp; maintaining the
multitude of data related to cultural heritage sites. Observes that cultural heritage sites
often arouse little involvement in young people, particularly when presented with the ruins
of ancient settlements whose current appearance no longer reflects their original aspect and purpose.
        
      </research-notes><urls><pdf-urls><url>internal-pdf://Ardito et al. - 2010 - Combining multimedia resources for an engaging experience of cultural heritage.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1878061.1878077</url><url>http://doi.acm.org/10.1145/1878061.1878077</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Arduino</author></authors></contributors><titles><title>Arduino - HomePage</title></titles><periodical/><keywords/><urls><web-urls><url>http://www.arduino.cc/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Arvind, D K</author><author>Wong, K J</author></authors></contributors><titles><title>Speckled computing: disruptive technology for networked information appliances</title><secondary-title>Consumer Electronics, 2004 IEEE International Symposium on</secondary-title></titles><periodical><full-title>Consumer Electronics, 2004 IEEE International Symposium on</full-title></periodical><pages>219-223</pages><keywords/><dates><year>2004</year></dates><electronic-resource-num>10.1109/ISCE.2004.1375940</electronic-resource-num><notes>        From Duplicate 1 (                           Speckled Computing: Disruptive Technology for Networked Information Appliances                         - Wong, K J; Arvind, D K )
                
Presents an emmerging technology in which data will be sensed in minute
(ultimately around 1mm^3) semiconductor grains called Specks. The emmer-
-gence of such a technology would allow truly ubiquitous sensing which
would be great for cross reality systems.
        
      </notes><research-notes>        From Duplicate 1 (                           Speckled Computing: Disruptive Technology for Networked Information Appliances                         - Wong, K J; Arvind, D K )
                
Presents an emmerging technology in which data will be sensed in minute
(ultimately around 1mm^3) semiconductor grains called Specks. The emmer-
-gence of such a technology would allow truly ubiquitous sensing which
would be great for cross reality systems.
        
      </research-notes><urls/></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Baronti, Paolo</author><author>Pillai, Prashant</author><author>Chook, Vince</author><author>Chessa, Stefano</author><author>Gotta, Alberto</author><author>Hu, Fun</author></authors></contributors><titles><title>Wireless sensor networks: A survey on the state of the art and the 802.15.4 and ZigBee standards</title><secondary-title>Comput. Commun.</secondary-title></titles><periodical><full-title>Comput. Commun.</full-title></periodical><pages>1655-1695</pages><volume>30</volume><issue>7</issue><keywords/><dates><year>2007</year></dates><pub-location>Newton, MA, USA</pub-location><publisher>Butterworth-Heinemann</publisher><electronic-resource-num>http://dx.doi.org/10.1016/j.comcom.2006.12.020</electronic-resource-num><notes>Definition/description/background of Wireless Sensor Networks.</notes><research-notes>Definition/description/background of Wireless Sensor Networks.</research-notes><urls><pdf-urls><url>internal-pdf://Baronti et al. - 2007 - Wireless sensor networks A survey on the state of the art and the 802.15.4 and ZigBee standards.pdf</url></pdf-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Benko, Hrvoje</author><author>Ishak, Edward W</author><author>Feiner, Steven</author></authors></contributors><titles><title>Collaborative Mixed Reality Visualization of an Archaeological Excavation</title><secondary-title>Proceedings of the 3rd IEEE/ACM International Symposium on Mixed and Augmented Reality</secondary-title></titles><periodical><full-title>Proceedings of the 3rd IEEE/ACM International Symposium on Mixed and Augmented Reality</full-title></periodical><pages>132-140</pages><keywords/><dates><year>2004</year></dates><pub-location>Washington, DC, USA</pub-location><publisher>IEEE Computer Society</publisher><isbn>0-7695-2191-6</isbn><electronic-resource-num>http://dx.doi.org/10.1109/ISMAR.2004.23</electronic-resource-num><notes>        From Duplicate 2 (                           Collaborative Mixed Reality Visualization of an Archaeological Excavation                         - Benko, H.; Ishak, E.W.; Feiner, S. )
                
Presents VITA (Visual Interaction Tool for Archaeology), a collaborative mixed reality system for
archaeological excavations.
        
      </notes><research-notes>        From Duplicate 2 (                           Collaborative Mixed Reality Visualization of an Archaeological Excavation                         - Benko, H.; Ishak, E.W.; Feiner, S. )
                
Presents VITA (Visual Interaction Tool for Archaeology), a collaborative mixed reality system for
archaeological excavations.
        
      </research-notes><urls><web-urls><url>http://dx.doi.org/10.1109/ISMAR.2004.23</url><url>http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1383050</url></web-urls></urls><abstract>We present VITA (visual interaction tool for archaeology), an experimental collaborative mixed reality system for offsite visualization of an archaeological dig. Our system allows multiple users to visualize the dig site in a mixed reality environment in which tracked, see-through, head-worn displays are combined with a multi-user, multi-touch, projected table surface, a large screen display, and tracked hand-held displays. We focus on augmenting existing archaeological analysis methods with new ways to organize, visualize, and combine the standard 2D information available from an excavation (drawings, pictures, and notes) with textured, laser range-scanned 3D models of objects and the site itself. Users can combine speech, touch, and 3D hand gestures to interact multimodally with the environment. Preliminary user tests were conducted with archaeology researchers and students, and their feedback is presented here.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Berthelot, Rozenn</author><author>Duval, Thierry</author><author>Royan, Jérôme</author><author>Arnaldi, Bruno</author></authors></contributors><titles><title>Improving Reusability of Assets for Virtual Worlds while Preserving 3D Formats Features</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>4</volume><issue>3</issue><keywords/><dates><year>2011</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/6123</url></web-urls></urls><abstract>We propose a generic architecture that allows mixing several 3D formats in a single viewer whatever the rendering engine used by the virtual world. Our goal is to solve the issue raised by the multiplicity of 3D formats and rendering engines through an interoperability solution inspired by the web model. Our architecture relies on the Scene Graph Adapter, a component which aims at interfacing communication between virtual world inputs (e.g. 3D files) and outputs (e.g. the interactive visualization window). For this purpose, the Scene Graph Adapter is made up of two APIs that leverages similarities between 3D formats and 3D rendering engines, the Format Adapter API and the Renderer Adapter API.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Bishop, Jonathan</author></authors></contributors><titles><title>Enhancing the understanding of genres of web&amp;#45;based communities&amp;#58; the role of the ecological cognition framework</title><secondary-title>Int. J. Web Based Communities</secondary-title></titles><periodical><full-title>Int. J. Web Based Communities</full-title></periodical><pages>4-17</pages><volume>5</volume><issue>1</issue><keywords><keyword>based communities</keyword><keyword>blogs</keyword><keyword>chat groups</keyword><keyword>classification</keyword><keyword>ecological cognition</keyword><keyword>genre theory</keyword><keyword>genres</keyword><keyword>message boards</keyword><keyword>online communities</keyword><keyword>subgenres</keyword><keyword>virtual communities</keyword><keyword>web&amp;#45</keyword><keyword>web-based communities</keyword><keyword>weblogs</keyword></keywords><dates><year>2009</year></dates><pub-location>Inderscience Publishers, Geneva, SWITZERLAND</pub-location><publisher>Inderscience Publishers</publisher><electronic-resource-num>10.1504/IJWBC.2009.021558</electronic-resource-num><notes>        From Duplicate 1 (                           Enhancing the understanding of genres of web-based communities: the role of the ecological cognition framework                         - Bishop, Jonathan )
                
Definition of a virtual world as &quot;a genre of online community comprising
three-dimensional graphical environments in which multiple users
interact with each other in addition to creating and interacting with
objects and the virtual environment around them&quot;.
        
      </notes><research-notes>        From Duplicate 1 (                           Enhancing the understanding of genres of web-based communities: the role of the ecological cognition framework                         - Bishop, Jonathan )
                
Definition of a virtual world as &quot;a genre of online community comprising
three-dimensional graphical environments in which multiple users
interact with each other in addition to creating and interacting with
objects and the virtual environment around them&quot;.
        
      </research-notes><urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1463643.1463644</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Bloomfield, Robert</author></authors></contributors><titles><title>World of Bizcraft</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>Long piece on the possible creation of a future virtual world usable for simulating complex
real world business/financial interactions. Has a lot of background about virtual worlds &amp;
an account of first experience with Second Life as well.</notes><research-notes>Long piece on the possible creation of a future virtual world usable for simulating complex
real world business/financial interactions. Has a lot of background about virtual worlds &amp;
an account of first experience with Second Life as well.</research-notes><urls><web-urls><url>http://journals.tdl.org/jvwr/article/view/743/535</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Bose, Faja</author><author>Bose, Raja</author></authors></contributors><titles><title>Sensor Networks Motes, Smart Spaces, and Beyond</title><secondary-title>Pervasive Computing, IEEE</secondary-title></titles><periodical><full-title>Pervasive Computing, IEEE</full-title></periodical><pages>84-90</pages><volume>8</volume><issue>3</issue><keywords><keyword>ad-hoc network</keyword><keyword>remote base station</keyword><keyword>scientific appl</keyword></keywords><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.55</electronic-resource-num><notes>        From Duplicate 1 (                           Sensor Networks Motes, Smart Spaces, and Beyond                         - Bose, Raja )
                
A nice history of (wireless) sensor networks &amp; what current research
into the paradigm is focused on. Has a section about 'first generation
sensor platforms' which includes Berkeley Motes (which includes the
Telos platform which the Tmotes I used for my SH Project are) &amp; the
TinyOS operating system (including an identification that it is not
designed for easy &amp; rapid application development nor for supporting
sophisticated applications. Also has a section on Phidgets, which I also
used in my SH Project.
        
      </notes><research-notes>        From Duplicate 1 (                           Sensor Networks Motes, Smart Spaces, and Beyond                         - Bose, Raja )
                
A nice history of (wireless) sensor networks &amp; what current research
into the paradigm is focused on. Has a section about 'first generation
sensor platforms' which includes Berkeley Motes (which includes the
Telos platform which the Tmotes I used for my SH Project are) &amp; the
TinyOS operating system (including an identification that it is not
designed for easy &amp; rapid application development nor for supporting
sophisticated applications. Also has a section on Phidgets, which I also
used in my SH Project.
        
      </research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165565</url></web-urls></urls><abstract>Sensor networks have come a long way since their humble beginnings in DARPA-funded academic research projects in the 1990s and have morphed into a significant research area in their own right. Over the last decade or so, networked sensing devices have become embedded all around us. In this article we look at how sensor network research and applications have evolved and how emerging trends could determine where they're headed.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Botts, Mike</author><author>Percivall, George</author><author>Reed, Carl</author><author>Davidson, John</author></authors><secondary-authors><author>Nittel, S</author><author>Labrinidis, A</author><author>Stefanidis, A</author></secondary-authors></contributors><titles><title>OGC Sensor Web Enablement: Overview and High Level Architecture</title><secondary-title>Lecture Notes in Computer Science</secondary-title></titles><periodical><full-title>Lecture Notes in Computer Science</full-title></periodical><pages>175-190</pages><volume>4540</volume><issue>175</issue><keywords/><dates><year>2008</year></dates><publisher>Springer</publisher><isbn>9783540799955</isbn><urls><web-urls><url>http://www.springerlink.com/index/ux1224j76264g8j4.pdf</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Book">6</ref-type><contributors><authors><author>Botts, Mike</author><author>Percivall, George</author><author>Reed, Carl</author><author>Davidson, John</author><author>Nittel, Silvia</author><author>Labrinidis, Alexandros</author><author>Stefanidis, Anthony</author></authors><secondary-authors><author>Nittel, Silvia</author><author>Labrinidis, Alexandros</author><author>Stefanidis, Anthony</author></secondary-authors></contributors><titles><title>GeoSensor Networks</title></titles><periodical/><pages>175-190</pages><volume>4540</volume><keywords><keyword>Computer Science</keyword></keywords><dates><year>2008</year></dates><pub-location>Berlin, Heidelberg</pub-location><publisher>Springer Berlin Heidelberg</publisher><isbn>978-3-540-79995-5</isbn><electronic-resource-num>10.1007/978-3-540-79996-2</electronic-resource-num><notes>High level overview, gives details about interesting real world deployment (dirty bomb scenario).</notes><research-notes>High level overview, gives details about interesting real world deployment (dirty bomb scenario).</research-notes><urls><web-urls><url>http://www.springerlink.com/content/ux1224j76264g8j4/</url></web-urls></urls><abstract>The Open Geospatial Consortium (OGC) standards activities that focus on sensors and sensor networks comprise an OGC focus area known as Sensor Web Enablement (SWE). Readers interested in greater technical and architecture details can download the OGC SWE Architecture Discussion Paper titled “The OGC Sensor Web Enablement Architecture” (OGC document 06-021r1).</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Brandherm, Boris</author><author>Ullrich, Sebastian</author><author>Prendinger, Helmut</author></authors></contributors><titles><title>Simulation of sensor-based tracking in Second Life</title><secondary-title>Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems: demo papers</secondary-title></titles><periodical><full-title>Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems: demo papers</full-title></periodical><pages>1689-1690</pages><keywords><keyword>Second Life</keyword><keyword>sensor networks</keyword><keyword>simulation</keyword><keyword>testbed</keyword></keywords><dates><year>2008</year></dates><pub-location>Richland, SC</pub-location><publisher>International Foundation for Autonomous Agents and Multiagent Systems</publisher><notes>        From Duplicate 1 (                           Simulation of sensor-based tracking in Second Life                         - Brandherm, Boris; Ullrich, Sebastian; Prendinger, Helmut )
                
Justification &amp; demonstration of using Second Life as a platform for simulating sensor networks.
        
      </notes><research-notes>        From Duplicate 1 (                           Simulation of sensor-based tracking in Second Life                         - Brandherm, Boris; Ullrich, Sebastian; Prendinger, Helmut )
                
Justification &amp; demonstration of using Second Life as a platform for simulating sensor networks.
        
      </research-notes><urls><pdf-urls><url>internal-pdf://Brandherm, Ullrich, Prendinger - 2008 - Simulation of sensor-based tracking in Second Life.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1402744.1402767</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Bretaudière, Treveur</author><author>Cruz-Lara, Samuel</author><author>Barahona, Lina</author></authors></contributors><titles><title>Associating Automatic Natural Language Processing to Serious Games and Virtual Worlds</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>4</volume><issue>3</issue><keywords/><dates><year>2011</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/6124</url></web-urls></urls><abstract>We present our current research activities associating automatic natural language processing to serious games and virtual worlds. Several interesting scenarios have been developed: language learning, natural language generation, multilingual information, emotion detection, real-time translations, and non-intrusive access to linguistic information such as definitions or synonyms. Part of our work has contributed to the specification of the Multi Lingual Information Framework [ISO FDIS 24616], (MLIF,2011). Standardization will grant stability, interoperability and sustainability of an important part of our research activities, in particular, in the framework of representing and managing multilingual textual information.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Caballero, María</author><author>Chang, Ting-Ray</author><author>Menéndez, María</author><author>Occhialini, Valentina</author></authors></contributors><titles><title>Behand: augmented virtuality gestural interaction for mobile phones</title><secondary-title>Proceedings of the 12th international conference on Human computer interaction with mobile devices and services</secondary-title></titles><periodical><full-title>Proceedings of the 12th international conference on Human computer interaction with mobile devices and services</full-title></periodical><pages>451-454</pages><keywords><keyword> augmented virtuality</keyword><keyword> gestural interfaces</keyword><keyword> interaction strategies</keyword><keyword> manipulation</keyword><keyword> mixed reality</keyword><keyword> mobile devices</keyword><keyword>3D</keyword></keywords><dates><year>2010</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-60558-835-3</isbn><electronic-resource-num>http://doi.acm.org/10.1145/1851600.1851704</electronic-resource-num><urls><web-urls><url>http://doi.acm.org/10.1145/1851600.1851704</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Cabello, Jose Manuel</author><author>Franco, Jose Maria</author><author>Collado, Antonio</author><author>Janer, Jordi</author><author>Cruz-Lara, Samuel</author><author>Oyarzun, David</author><author>Armisen, Albert</author><author>Geraerts, Roland</author></authors></contributors><titles><title>Standards in Virtual Worlds Virtual Travel Use Case Metaverse1 Project</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>4</volume><issue>3</issue><keywords/><dates><year>2011</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/6129</url></web-urls></urls><abstract>Nowadays, tourism has become a very important industry in the international economy. Information and communication technologies are in constant development; they progress worldwide and across sectors. Their applications in tourism and tourist resources is rapidly increasing, reaching new, innovative and sometimes amazing results in terms of effectiveness, productivity, quality, and customer satisfaction. Exploring the interaction between technologies and tourism is difficult and challenging. Specifically, using virtual world technologies as a new means of information for potential tourists is a big challenge where the actual methods, goals and needs still need to be exactly identified. This paper aims at analyzing why and how virtual worlds can become an important platform for tourism-oriented areas to promote a destination in general, and their local heritage and tourist added-value services in particular. The document will also introduce the design of the first prototypes and the validation results of the four specific technologies tested at the Virtual Travel Use Case (Soundscape generation, Multilinguality, Video streaming and Path and Camera Planning). Finally, the contribution to the MPEG-V standard will also be detailed in the paper.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Cabral, Marcio</author><author>Zuffo, Marcelo</author><author>Ghirotti, Silvia</author><author>Belloc, Olavo</author><author>Nomura, Leonardo</author><author>Nagamura, Mario</author><author>Andrade, Fernanda</author><author>Faria, Regis</author><author>Ferraz, Leandro</author></authors></contributors><titles><title>An experience using X3D for virtual cultural heritage</title><secondary-title>Proceedings of the twelfth international conference on 3D web technology</secondary-title></titles><periodical><full-title>Proceedings of the twelfth international conference on 3D web technology</full-title></periodical><pages>161-164</pages><keywords><keyword> cultural heritage</keyword><keyword> interaction</keyword><keyword> virtual reality</keyword><keyword>X3D</keyword></keywords><dates><year>2007</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-59593-652-3</isbn><electronic-resource-num>http://doi.acm.org/10.1145/1229390.1229419</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Cabral et al. - 2007 - An experience using X3D for virtual cultural heritage.pdf</url></pdf-urls><web-urls><url>http://doi.acm.org/10.1145/1229390.1229419</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Christou, Chris</author><author>Angus, Cameron</author><author>Loscos, Celine</author><author>Dettori, Andrea</author><author>Roussou, Maria</author></authors></contributors><titles><title>A versatile large-scale multimodal VR system for cultural heritage visualization</title><secondary-title>Proceedings of the ACM symposium on Virtual reality software and technology - VRST '06</secondary-title></titles><periodical><full-title>Proceedings of the ACM symposium on Virtual reality software and technology - VRST '06</full-title></periodical><pages>133</pages><keywords><keyword>haptics</keyword><keyword>multimodal Interfaces</keyword><keyword>virtual heritage</keyword></keywords><dates><year>2006</year></dates><pub-location>New York, New York, USA</pub-location><publisher>ACM Press</publisher><isbn>1595933212</isbn><electronic-resource-num>10.1145/1180495.1180523</electronic-resource-num><notes>Uses a CAVE with a 2-armed haptic interface. Applicability of haptic interfaces for cross
reality?
        
Useful quote for the shortcomings of self-proclaimed virtual worlds - &quot;Such environments suffer
either from a lack of realism or a low degree of interactivity, due to technological and
methodological constraints.&quot;.</notes><research-notes>Uses a CAVE with a 2-armed haptic interface. Applicability of haptic interfaces for cross
reality?
        
Useful quote for the shortcomings of self-proclaimed virtual worlds - &quot;Such environments suffer
either from a lack of realism or a low degree of interactivity, due to technological and
methodological constraints.&quot;.</research-notes><urls><pdf-urls><url>internal-pdf://Christou et al. - 2006 - A versatile large-scale multimodal VR system for cultural heritage visualization.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1180495.1180523</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Coleman, Beth</author></authors></contributors><titles><title>Using Sensor Inputs to Affect Virtual and Real Environments</title><secondary-title>Pervasive Computing, IEEE</secondary-title></titles><periodical><full-title>Pervasive Computing, IEEE</full-title></periodical><pages>16-23</pages><volume>8</volume><issue>3</issue><keywords><keyword>3D application design</keyword><keyword>3D graphical object</keyword><keyword>3D inter</keyword></keywords><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.60</electronic-resource-num><notes>        From Duplicate 1 (                           Using Sensor Inputs to Affect Virtual and Real Environments                         - Coleman, Beth )
                
Beth Coleman (MIT Comparative Media Studies &amp; Program in Writing &amp;
Humanistic Studies)
        
Definition of cross reality &amp; use of the term x-reality.
        
Discusses 3 examples;Eolus One (real-estate), Green Phosphor (3D Interface Design,
world oil map example) &amp; Parsec (control of a virtual environment using
voice).
        
      </notes><research-notes>        From Duplicate 1 (                           Using Sensor Inputs to Affect Virtual and Real Environments                         - Coleman, Beth )
                
Beth Coleman (MIT Comparative Media Studies &amp; Program in Writing &amp;
Humanistic Studies)
        
Definition of cross reality &amp; use of the term x-reality.
        
Discusses 3 examples;Eolus One (real-estate), Green Phosphor (3D Interface Design,
world oil map example) &amp; Parsec (control of a virtual environment using
voice).
        
      </research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165556</url></web-urls></urls><abstract>This article discusses several networked media projects that use sensor technology to transmit data from real-world environments to virtual environments. The Eolus One project uses an experimental virtual control room to run building systems and provide a better communication network among its users. A 3D application design group called green phosphor creates code for translating n-dimensional information into 3D interactive formats for real-time effects. The Parsec voice controller system uses sonic inputs to control 3D graphical objects on the second life virtual platform. This article focuses on the design principles applied by the three projects at this experimental stage of x-reality design.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Coutrix, Céline</author><author>Nigay, Laurence</author></authors></contributors><titles><title>Mixed reality: a model of mixed interaction</title><secondary-title>Proceedings of the working conference on Advanced visual interfaces</secondary-title></titles><periodical><full-title>Proceedings of the working conference on Advanced visual interfaces</full-title></periodical><pages>43-50</pages><keywords><keyword>augmented reality-virtuality</keyword><keyword>instrumental model</keyword><keyword>interaction modality</keyword><keyword>interaction model</keyword><keyword>mixed reality</keyword><keyword>multimodality</keyword></keywords><dates><year>2006</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>1-59593-353-0</isbn><electronic-resource-num>http://doi.acm.org/10.1145/1133265.1133274</electronic-resource-num><notes>        From Duplicate 1 (                           Mixed reality                         - Coutrix, Céline; Nigay, Laurence )
                
Presents the Mixed Interaction model, that focuses on the link between
physical &amp; digital worlds, providing a framework for guiding designers
to create interactive systems. Classified by descriptive/classification
power, generative power &amp; comparative power. Unifies several approaches
to mixed reality systems (including augmented reality &amp; augmented virtu-
-ality).
        
      </notes><research-notes>        From Duplicate 1 (                           Mixed reality                         - Coutrix, Céline; Nigay, Laurence )
                
Presents the Mixed Interaction model, that focuses on the link between
physical &amp; digital worlds, providing a framework for guiding designers
to create interactive systems. Classified by descriptive/classification
power, generative power &amp; comparative power. Unifies several approaches
to mixed reality systems (including augmented reality &amp; augmented virtu-
-ality).
        
      </research-notes><urls><pdf-urls><url>internal-pdf://Coutrix, Nigay - 2006 - Mixed reality.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1133265.1133274</url><url>http://doi.acm.org/10.1145/1133265.1133274</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Cruz-Lara, Samuel</author><author>Bellalem, Nadia</author><author>Bellalem, Lotfi</author><author>Osswald, Tarik</author></authors></contributors><titles><title>Immersive 3D Environments and Multilinguality: Some Non-Intrusive and Dynamic e-learning-oriented Scenarios based on Textual Information</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/727/526</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>De Amicis, Raffaele</author><author>Girardi, Gabrio</author><author>Andreolli, Michele</author><author>Conti, Giuseppe</author><author>Amicis, Raffaele De</author></authors></contributors><titles><title>Game based technology to enhance the learning of history and cultural heritage</title><secondary-title>Proceedings of the International Conference on Advances in Computer Enterntainment Technology</secondary-title></titles><periodical><full-title>Proceedings of the International Conference on Advances in Computer Enterntainment Technology</full-title></periodical><pages>451</pages><keywords><keyword>3D reconstruction</keyword><keyword>cultural heritage</keyword><keyword>entertainment</keyword><keyword>game engine</keyword><keyword>interactive navigation</keyword><keyword>multimedia contents</keyword><keyword>virtual reality</keyword></keywords><dates><year>2009</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-60558-864-3</isbn><electronic-resource-num>http://doi.acm.org/10.1145/1690388.1690499</electronic-resource-num><notes>        From Duplicate 2 (                           Game based technology to enhance the learning of history and cultural heritage                         - De Amicis, Raffaele; Girardi, Gabrio; Andreolli, Michele; Conti, Giuseppe )
                
Abstract only that talks about the use of game technologies to support learning of users
within cultural heritage sites. Says that the level of realism is ideal to visualise cultural
heritage if a string focus on the environment's atmosphere &amp; immersion is required, &quot;emphasising
environmental effects such as fog, sky, water, particles&quot;, all of which self-proclaimed virtual
worlds aren't as good at.
        
Uses Unity3D! Mentions that it can produce web browser based applications as well as standalone
ones, has a simple authoring interface &amp; &quot;exploits the latest graphical hardware by making extensive
use of shaders to deliver high quality graphics&quot;.
        
      </notes><research-notes>        From Duplicate 2 (                           Game based technology to enhance the learning of history and cultural heritage                         - De Amicis, Raffaele; Girardi, Gabrio; Andreolli, Michele; Conti, Giuseppe )
                
Abstract only that talks about the use of game technologies to support learning of users
within cultural heritage sites. Says that the level of realism is ideal to visualise cultural
heritage if a string focus on the environment's atmosphere &amp; immersion is required, &quot;emphasising
environmental effects such as fog, sky, water, particles&quot;, all of which self-proclaimed virtual
worlds aren't as good at.
        
Uses Unity3D! Mentions that it can produce web browser based applications as well as standalone
ones, has a simple authoring interface &amp; &quot;exploits the latest graphical hardware by making extensive
use of shaders to deliver high quality graphics&quot;.
        
      </research-notes><urls><pdf-urls><url>internal-pdf://De Amicis et al. - 2009 - Game based technology to enhance the learning of history and cultural heritage.pdf</url></pdf-urls><web-urls><url>http://doi.acm.org/10.1145/1690388.1690499</url><url>http://dl.acm.org/citation.cfm?id=1690388.1690499</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Dikaiakou, M</author><author>Efthymiou, A</author><author>Chrysanthou, Yiorgos</author></authors></contributors><titles><title>Modelling the Walled City of Nicosia</title><secondary-title>VAST</secondary-title></titles><periodical><full-title>VAST</full-title></periodical><pages>61-70</pages><keywords><keyword>automatic reconstruction</keyword><keyword>component based modelling</keyword><keyword>Typology</keyword><keyword>urban environment</keyword></keywords><dates><year>2003</year></dates><electronic-resource-num>http://dx.doi.org/10.2312/VAST/VAST03/061-070</electronic-resource-num><notes>Accurate 3D model/recreation of a substantial urban area, using partly automated construction/rendering
of similar building styles/types.</notes><research-notes>Accurate 3D model/recreation of a substantial urban area, using partly automated construction/rendering
of similar building styles/types.</research-notes><urls><web-urls><url>http://dx.doi.org/10.2312/VAST/VAST03/061-070</url></web-urls></urls><abstract>This paper presents our initial results in producing a 3D model of the Chrysaliniotisa Quarter in Nicosia using the GIS data of the region, and an analysis of the structure of the areas buildings. We tried to create a partly-automatic system, which was aimed at producing a realistic model of the geometry and architectural style of the district, rather than an exact reconstruction of every detail. The residential buildings of the particular area follow some well defined architectural styles, which allows us to follow an automatic building generation, based on the 2D digital data and a library of predefined 3D building blocks. Starting from the GIS file, the data is sorted, examined and processed to detect the houses features and style as accurately as possible. The 3D model is then constructed by stitching together the appropriate blocks from the component library. Besides the automatic-generation method, we have used ImageModeler from RealViz to create accurate 3D representations of landmarks and exceptional buildings as well as for the building blocks.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Dindar, Nihal</author><author>Balkesen, Çagri</author><author>Kromwijk, Katina</author><author>Tatbul, Nesime</author></authors></contributors><titles><title>Event Processing Support for Cross-Reality Environments</title><secondary-title>IEEE Pervasive Computing</secondary-title></titles><periodical><full-title>IEEE Pervasive Computing</full-title></periodical><pages>34-41</pages><volume>8</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.43</electronic-resource-num><notes>Discusses the importance of higher level inference techniques to make
sense of phenomena detected by sensor networks, presenting it as an
essential functionality of cross reality environments. Lifton touched
on such a thing in his PhD, talking about how looking at vibration data
could tell you whether a lamp was plugged in before being turned on etc.
        
Presents DejaVu, an event processing system, that works along with an
example cross reality application that feeds real world RFID data into
a virtual library in Second Life.</notes><research-notes>Discusses the importance of higher level inference techniques to make
sense of phenomena detected by sensor networks, presenting it as an
essential functionality of cross reality environments. Lifton touched
on such a thing in his PhD, talking about how looking at vibration data
could tell you whether a lamp was plugged in before being turned on etc.
        
Presents DejaVu, an event processing system, that works along with an
example cross reality application that feeds real world RFID data into
a virtual library in Second Life.</research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165558</url></web-urls></urls><abstract>Complex event processing (CEP) is an essential functionality for cross-reality environments. Through CEP, we can turn raw sensor data generated in the real world into more meaningful information that has some significance for the virtual world. In this article, the authors present DejaVu, a general-purpose event processing system built at ETH Zurich. SmartRFLib, a cross-reality application, builds on DejaVu and enables real-time event detection over RFID data streams feeding a virtual library on second life.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Dunkels, Adam</author></authors></contributors><titles><title>The Contiki OS</title></titles><periodical/><keywords/><urls><web-urls><url>http://www.contiki-os.org/p/about-contiki.html</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Ebling, Maria</author><author>Corner, Mark</author></authors></contributors><titles><title>Virtual Learning, Decorating, and Skateboarding</title><secondary-title>Pervasive Computing, IEEE</secondary-title></titles><periodical><full-title>Pervasive Computing, IEEE</full-title></periodical><pages>6-7</pages><volume>8</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.61</electronic-resource-num><notes>        From Duplicate 1 (                           Virtual Learning, Decorating, and Skateboarding                         - Ebling, Maria; Corner, Mark )
                
Describes some virtual reality &amp; augmented reality products. Not really
that related to cross reality.
        
      </notes><research-notes>        From Duplicate 1 (                           Virtual Learning, Decorating, and Skateboarding                         - Ebling, Maria; Corner, Mark )
                
Describes some virtual reality &amp; augmented reality products. Not really
that related to cross reality.
        
      </research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165553</url></web-urls></urls><abstract>New products related to the special issue on cross-reality environments are discussed including the Second Life island of learning created by Memorial University in Newfoundland, Canada, an iPhone application called iLiving, the new video game Tony Hawk: Ride, the nPower Personal Energy Generator, and the Bomo Baby Carriage.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Eishita, Farjana</author><author>Stanley, Kevin</author></authors></contributors><titles><title>THEEMPA: simple AR games using layar</title><secondary-title>Proceedings of the International Academic Conference on the Future of Game Design and Technology</secondary-title></titles><periodical><full-title>Proceedings of the International Academic Conference on the Future of Game Design and Technology</full-title></periodical><pages>219-222</pages><keywords><keyword> augment reality (AR)</keyword><keyword> POI</keyword><keyword>APK</keyword></keywords><dates><year>2010</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-4503-0235-7</isbn><electronic-resource-num>http://doi.acm.org/10.1145/1920778.1920811</electronic-resource-num><urls><web-urls><url>http://doi.acm.org/10.1145/1920778.1920811</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Elmenreich, Wilfried</author><author>Pitzek, Stefan</author><author>Wilfried Elmenreich, Stefan Pitzek</author></authors></contributors><titles><title>Smart Transducers - Principles, Communications, and Configuration</title><secondary-title>In Proceedings of the 7th IEEE International Conference on Intelligent Engineering Systems</secondary-title></titles><periodical><full-title>In Proceedings of the 7th IEEE International Conference on Intelligent Engineering Systems</full-title></periodical><pages>510-515</pages><keywords/><dates><year>2003</year></dates><notes>        From Duplicate 1 (                           Smart Transducers - Principles, Communications, and Configuration                         - Wilfried Elmenreich, Stefan Pitzek )
                
Definition of 'smart transducer'.
        
      </notes><research-notes>        From Duplicate 1 (                           Smart Transducers - Principles, Communications, and Configuration                         - Wilfried Elmenreich, Stefan Pitzek )
                
Definition of 'smart transducer'.
        
      </research-notes><urls><web-urls><url>http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.8516</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Falk, Markus</author><author>Besemann, Daniel</author><author>Bosson, James</author></authors></contributors><titles><title>Payback of Mining Activities Within Entropia Universe</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/647/514</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Book">6</ref-type><contributors><authors><author>Faludi, Robert</author></authors><secondary-authors><author>Jepson, Brian</author></secondary-authors></contributors><titles><title>Building Wireless Sensor Networks</title></titles><periodical/><edition>1</edition><keywords/><dates><year>2010</year></dates><pub-location>Sebastopol</pub-location><publisher>O'Reilly Media Inc.</publisher><isbn>978-0-596-80773-3</isbn><urls><web-urls><url>http://www.faludi.com/bwsn/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Farr, Will</author><author>Hut, Piet</author><author>Ames, Jeff</author><author>Johnson, Adam</author></authors></contributors><titles><title>An experiment in Using Virtual Worlds for Scientific Visualization of Self-Gravitating Systems</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/659/518</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Fayolle, Jacques</author></authors></contributors><titles><title>The Concept of the Remote Laboratory</title></titles><periodical/><issue>28</issue><keywords/><dates><year>2011</year></dates><notes>        From Duplicate 1 (                           The Concept of the Remote Laboratory                         - Fayolle, Jacques )
                
A citation to the concept of using Project Wonderland's application sharing feature to control lab
equipment remotely &amp; then visualise the results (eg in 3D in the virtual world) by interacting with
external data sources, that is mentioned in Yankelovic article in IEEE Pervasive 'building and
employing cross-reality'.
        
      </notes><research-notes>        From Duplicate 1 (                           The Concept of the Remote Laboratory                         - Fayolle, Jacques )
                
A citation to the concept of using Project Wonderland's application sharing feature to control lab
equipment remotely &amp; then visualise the results (eg in 3D in the virtual world) by interacting with
external data sources, that is mentioned in Yankelovic article in IEEE Pervasive 'building and
employing cross-reality'.
        
      </research-notes><urls><web-urls><url>http://blogs.openwonderland.org/2011/01/28/remote-laboratories/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Fillinger, Antoine</author><author>Hamchi, Imad</author><author>Degre, Stéphane</author><author>Diduch, Lukas L.</author><author>Rose, Travis</author><author>Fiscus, Jonathan</author><author>Stanford, Vincent</author></authors></contributors><titles><title>Middleware and Metrology for the Pervasive Future</title><secondary-title>IEEE Pervasive Computing</secondary-title></titles><periodical><full-title>IEEE Pervasive Computing</full-title></periodical><pages>74-83</pages><volume>8</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.50</electronic-resource-num><notes>Rather technical discussion of NIST's middleware for distributed sensor
data aquisition &amp; processing. Heavily focused on data-flow, not of
particular interest to cross reality but does have a nice 1 paragraph
summary/description of Global Sensor Networks (GSN).</notes><research-notes>Rather technical discussion of NIST's middleware for distributed sensor
data aquisition &amp; processing. Heavily focused on data-flow, not of
particular interest to cross reality but does have a nice 1 paragraph
summary/description of Global Sensor Networks (GSN).</research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165564</url></web-urls></urls><abstract>Looks at the data and metrology tools developed by The National Institute of Standards and Technology for the research community, including common middleware for distributed sensor data acquisition and processing.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Foundation, Raspberry Pi</author></authors></contributors><titles><title>Raspberry Pi | An ARM GNU/Linux box for $25. Take a byte!</title></titles><periodical/><keywords/><urls><web-urls><url>http://www.raspberrypi.org/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Garcia, Linda</author><author>LeMasters, Garrison</author></authors></contributors><titles><title>Synthetic Excellence: Standards, Play, and Unintended Outcomes</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>Can't tell if serious...</notes><research-notes>Can't tell if serious...</research-notes><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/665/534</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Gelissen, Jean</author></authors></contributors><titles><title>Summary of MPEG-V</title></titles><periodical/><keywords/><dates><year>2008</year></dates><publisher>International Organization for Standardization</publisher><urls><web-urls><url>http://mpeg.chiariglione.org/working_documents.php</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Gelissen, Jean</author></authors></contributors><titles><title>Introduction to MPEG-V</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>
        From Duplicate 1 ( 
        
        
          Introduction to MPEG-V
        
        
         - Gelissen, Jean )

        
        
Written in 2009 when MPEG-V was still in development, it wouldn't be published as the ISO/IEC 23005 standard
until 2011. Serves nicely now as a retrospective as to the justification behind MPEG-V &amp; to cross reality in
general. Lists many things that virtual worlds will be used for, which can essentially be seen as areas that
cross reality might be applicable.

        

      </notes><research-notes>
        From Duplicate 1 ( 
        
        
          Introduction to MPEG-V
        
        
         - Gelissen, Jean )

        
        
Written in 2009 when MPEG-V was still in development, it wouldn't be published as the ISO/IEC 23005 standard
until 2011. Serves nicely now as a retrospective as to the justification behind MPEG-V &amp; to cross reality in
general. Lists many things that virtual worlds will be used for, which can essentially be seen as areas that
cross reality might be applicable.

        

      </research-notes><urls><web-urls><url>http://journals.tdl.org/jvwr/article/view/742/533</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Gelissen, Jean</author><author>Preda, Marius</author><author>Cruz-Lara, Samuel</author><author>Sivan, Yesha</author></authors></contributors><titles><title>Issue Editors' Corner: The Current and Future Angles of Standards</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>4</volume><issue>3</issue><keywords/><dates><year>2011</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/6139</url></web-urls></urls><abstract>In this issue, we report on the first phase of MPEG-V, a work that started in 2007. MPEG-V was conceived as a unified effort to develop standards within virtual worlds, and between virtual worlds and real worlds. This work culminated in the publication of the ISO/IEC MPEG-V 'Media context and control' standards in January 2011. The papers in this issue of the Journal of Virtual World Research expose both the many current standards for virtual worlds, as well as the many missing standards. As such, the issue hints at many more places where standards are needed. To fulfill the potential of virtual worlds much more standardization (MPEG-V, and other standards) is needed.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Gelissen, Jean</author><author>Sivan, Yesha</author></authors></contributors><titles><title>The Metaverse1 Case: Historical Review of Making One Virtual Worlds Standard (MPEG-V)</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>4</volume><issue>3</issue><keywords/><dates><year>2011</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/6066</url></web-urls></urls><abstract>This paper takes an historical perspective on the Metaverse1 project. A group of about 30 EU-based organizations totalling about 100 people worked together from 2008 to 2011 to develop a global standard that will connect virtual worlds and real worlds. The project, which was under the Eureka/ITEA2 framework, was one of the key contributors to the MPEG-V 'Media context and control' standard published by ISO/IEC in January 2011. The review includes the need for virtual worlds stadnards, the formation of the research team and plan, internal research results, main outcome (MPEG-V standard). We will conclude with some reflective notes. The ITEA2 Metaverse1 project has developed a standardized global framework enabling interoperability between virtual worlds such as Second Life, IMVU, OpenSim, Active Worlds, Google Earth and with the real world in terms of sensors and actuators, vision and rendering systems, and applications in areas like social and welfare systems, banking, insurance, tourism and real estate. Results of the project drove the MPEG-V 'Media context and control' standard published by ISO/IEC in January 2011.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Getchell, K</author><author>Miller, A</author><author>Nicoll, R</author><author>Sweetman, R</author><author>Allison, C</author></authors></contributors><titles><title>Games Methodologies and Immersive Environments for Virtual Fieldwork</title><secondary-title>IEEE Transactions on Learning Technologies</secondary-title></titles><periodical><full-title>IEEE Transactions on Learning Technologies</full-title></periodical><pages>281-293</pages><volume>3</volume><issue>4</issue><keywords/><dates><year>2010</year></dates><electronic-resource-num>10.1109/TLT.2010.25</electronic-resource-num><urls><web-urls><url>http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5557838</url></web-urls></urls><abstract>The construction and consolidation of knowledge through the practical application of concepts and processes can be difficult to support for subjects where practice is an integral component of competence and expertise in that domain. For example, participation in an archaeological excavation is not readily available to students, although a detailed understanding of what processes this involves is deemed to be core to the subject. The Laconia Acropolis Virtual Archaeology (LAVA) project has created a cooperative exploratory learning environment that addresses the need for students to engage with the complex practice of excavation. By leveraging the progressive nature of games methodologies and the immersive engagement provided by 3D multiuser virtual environments, LAVA facilitates the adoption of exploratory learning for excavation scenarios which have previously been inaccessible due to barriers of travel, time, and cost. A virtual environment based on real world data has been developed where groups of users are faced with a series of dynamic challenges with which they engage until such time that a certain level of competence is shown. Once a series of domain-specific objectives has been met, users are able to progress forward to the next level of the simulation. The excavation simulator enhances the student learning experience by providing opportunities for students to engage with the process in a customizable, virtual environment. Not only does this provide students with an opportunity to put the theories they are familiar with into practice, but it also allows students to gain experience in applying their skills in a bid to manage an excavation process, thereby making it possible for a greater emphasis to be placed on the practical application of knowledge that the excavation process necessitates. The potential of this approach has been confirmed by a positive user evaluation. LAVA contributes toward the progress of technology-enhanced learning by illustrating the- - instantiation of a framework which demonstrates how to integrate games methods with learning management systems and virtual worlds in order to support higher order learning behaviors such as applying, analyzing, evaluating, and creating.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Gilsinn, J.D.</author><author>Lee, K.</author></authors></contributors><titles><title>Wireless interfaces for IEEE 1451 sensor networks</title><secondary-title>SIcon/01. Sensors for Industry Conference. Proceedings of the First ISA/IEEE. Sensors for Industry Conference (Cat. No.01EX459)</secondary-title></titles><periodical><full-title>SIcon/01. Sensors for Industry Conference. Proceedings of the First ISA/IEEE. Sensors for Industry Conference (Cat. No.01EX459)</full-title></periodical><pages>45-50</pages><keywords/><publisher>IEEE</publisher><isbn>0-7803-6659-X</isbn><electronic-resource-num>10.1109/SFICON.2001.968497</electronic-resource-num><notes>Discusses the IEEE 1451 standard for smart sensors, emerging wireless
communication technologies &amp; possible solutions for creating a wireless
interface for the IEEE 1451 standard.
        
*** Did such a wireless interface already come into being since this '91
paper &amp; before the 2008 paper above? I suspect that the integration with
bluetooth/zigbee/whatever is this '91 paper realised? Check.***</notes><research-notes>Discusses the IEEE 1451 standard for smart sensors, emerging wireless
communication technologies &amp; possible solutions for creating a wireless
interface for the IEEE 1451 standard.
        
*** Did such a wireless interface already come into being since this '91
paper &amp; before the 2008 paper above? I suspect that the integration with
bluetooth/zigbee/whatever is this '91 paper realised? Check.***</research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=968497</url></web-urls></urls><abstract>NIST started working with industry and the Institute of Electrical and Electronics Engineers (IEEE) in the mid 90's to develop a standardized interface to network smart sensors. With the spread of wireless technology, more industries are looking to incorporate wireless communications into their products and manufacturing processes. This paper discusses the IEEE 1451 standard interface for smart sensors, emerging wireless communication technologies, and possible solutions for creating a wireless interface for the IEEE 1451 standard</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Gintautas, Vadas</author><author>Hübler, Alfred W</author></authors></contributors><titles><title>Experimental evidence for mixed reality states in an interreality system</title><secondary-title>Phys. Rev. E</secondary-title></titles><periodical><full-title>Phys. Rev. E</full-title></periodical><pages>57201</pages><volume>75</volume><issue>5</issue><keywords/><dates><year>2007</year></dates><publisher>American Physical Society</publisher><accession-num>17677199</accession-num><electronic-resource-num>10.1103/PhysRevE.75.057201</electronic-resource-num><notes>        From Duplicate 1 (                           Experimental evidence for mixed reality states in an interreality system.                         - Gintautas, Vadas; Hübler, Alfred W )
                
Physics paper presented results from an experiment involving a real
pendulum &amp; a virtual pendulum that are linked together, moving from a
dual reality state where reality &amp; virtual reality are uncorrelated, to
a mixed reality state in which reality &amp; virtual reality are highly corre-
-lated.
        
      </notes><research-notes>        From Duplicate 1 (                           Experimental evidence for mixed reality states in an interreality system.                         - Gintautas, Vadas; Hübler, Alfred W )
                
Physics paper presented results from an experiment involving a real
pendulum &amp; a virtual pendulum that are linked together, moving from a
dual reality state where reality &amp; virtual reality are uncorrelated, to
a mixed reality state in which reality &amp; virtual reality are highly corre-
-lated.
        
      </research-notes><urls><web-urls><url>http://www.ncbi.nlm.nih.gov/pubmed/17677199</url></web-urls></urls><abstract>We present experimental data on the limiting behavior of an interreality system comprising a virtual horizontally driven pendulum coupled to its real-world counterpart, where the interaction time scale is much shorter than the time scale of the dynamical system. We present experimental evidence that, if the physical parameters of the simplified virtual system match those of the real system within a certain tolerance, there is a transition from an uncorrelated dual reality state to a mixed reality state of the system in which the motion of the two pendula is highly correlated. The region in parameter space for stable solutions has an Arnold tongue structure for both the experimental data and a numerical simulation. As virtual systems better approximate real ones, even weak coupling in other interreality systems may produce sudden changes to mixed reality states.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Griffin, Stephen</author></authors></contributors><titles><title>Recovering the past through computation: new techniques for cultural heritage</title><secondary-title>Proceedings of the international conference on Multimedia information retrieval</secondary-title></titles><periodical><full-title>Proceedings of the international conference on Multimedia information retrieval</full-title></periodical><pages>13-14</pages><keywords><keyword> culture</keyword><keyword> heritages</keyword><keyword>computing</keyword></keywords><dates><year>2010</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-60558-815-5</isbn><electronic-resource-num>http://doi.acm.org/10.1145/1743384.1743394</electronic-resource-num><urls><web-urls><url>http://doi.acm.org/10.1145/1743384.1743394</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Griffin, Stephen M.</author></authors></contributors><titles><title>Recovering the past through computation</title><secondary-title>Proceedings of the international conference on Multimedia information retrieval - MIR '10</secondary-title></titles><periodical><full-title>Proceedings of the international conference on Multimedia information retrieval - MIR '10</full-title></periodical><pages>13</pages><keywords><keyword>computing</keyword><keyword>culture</keyword><keyword>heritages</keyword></keywords><dates><year>2010</year></dates><pub-location>New York, New York, USA</pub-location><publisher>ACM Press</publisher><isbn>9781605588155</isbn><electronic-resource-num>10.1145/1743384.1743394</electronic-resource-num><notes>Only an abstract of a talk about applying new technologies to helping cultural heritage, so
not particularly useful, but a nice quote about the usefulness of alternate realities for
cultural heritage;
        
&quot;Many ancient artefacts are scattered about the world and reside in public and private
collections, inaccessible to scholars and far removed from their original location and context
of creation.&quot;</notes><research-notes>Only an abstract of a talk about applying new technologies to helping cultural heritage, so
not particularly useful, but a nice quote about the usefulness of alternate realities for
cultural heritage;
        
&quot;Many ancient artefacts are scattered about the world and reside in public and private
collections, inaccessible to scholars and far removed from their original location and context
of creation.&quot;</research-notes><urls><pdf-urls><url>internal-pdf://Griffin - 2010 - Recovering the past through computation.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1743384.1743394</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Harrison, Beverly</author><author>Fishkin, Kenneth</author><author>Gujar, Anuj</author><author>Portnov, Dmitriy</author><author>Want, Roy</author></authors></contributors><titles><title>Bridging physical and virtual worlds with tagged documents, objects and locations</title><secondary-title>CHI '99 extended abstracts on Human factors in computing systems</secondary-title></titles><periodical><full-title>CHI '99 extended abstracts on Human factors in computing systems</full-title></periodical><pages>29-30</pages><keywords><keyword> augmented reality</keyword><keyword> phicon</keyword><keyword> physical UI</keyword><keyword> tangible interface</keyword><keyword> ubiquitous computing</keyword><keyword>RFID tag</keyword></keywords><dates><year>1999</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>1-58113-158-5</isbn><electronic-resource-num>http://doi.acm.org/10.1145/632716.632738</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Harrison et al. - 1999 - Bridging physical and virtual worlds with tagged documents, objects and locations.pdf</url></pdf-urls><web-urls><url>http://doi.acm.org/10.1145/632716.632738</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Horn, Daniel</author><author>Cheslack-Postava, Ewen</author><author>Azim, Tahir</author><author>Freedman, Michael J.</author><author>Levis, Philip</author></authors></contributors><titles><title>Scaling Virtual Worlds with a Physical Metaphor</title><secondary-title>IEEE Pervasive Computing</secondary-title></titles><periodical><full-title>IEEE Pervasive Computing</full-title></periodical><pages>50-54</pages><volume>8</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.54</electronic-resource-num><notes>Talks about the scalability problems of todays virtual worlds (both
self proclaimed 'virtual worlds' like Second Life &amp; online games like
WoW &amp; Eve Online). Proposes the Meru Project (Stanford) as a virtual
world architecture that can scale to global scales by modelling the
virtual world after the real world - eg using distance to determine the
detail/bandwidth with which to render an object.
        
Envisages cross reality by a special 'space zero' within which physical
objects can register themselves &amp; thus advertise their presence &amp;
location to users of the virtual world. Nice example of a real person
walking down a street in the real world &amp; an avatar's position in space
zero being updated by GPS, with shop owners who have registered their
shops with space zero able to advertise specials to the avatar.
        
Also makes the point that, just like with the real web, it won't always
be actual users observing the virtual world, it may well be scripts/bots
that, for example, comb/search through specials.</notes><research-notes>Talks about the scalability problems of todays virtual worlds (both
self proclaimed 'virtual worlds' like Second Life &amp; online games like
WoW &amp; Eve Online). Proposes the Meru Project (Stanford) as a virtual
world architecture that can scale to global scales by modelling the
virtual world after the real world - eg using distance to determine the
detail/bandwidth with which to render an object.
        
Envisages cross reality by a special 'space zero' within which physical
objects can register themselves &amp; thus advertise their presence &amp;
location to users of the virtual world. Nice example of a real person
walking down a street in the real world &amp; an avatar's position in space
zero being updated by GPS, with shop owners who have registered their
shops with space zero able to advertise specials to the avatar.
        
Also makes the point that, just like with the real web, it won't always
be actual users observing the virtual world, it may well be scripts/bots
that, for example, comb/search through specials.</research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165560</url></web-urls></urls><abstract>Outlines the Meru Project at Stanford University is designing and implementing an architecture for the virtual worlds of the future. The hope is that we can avoid some of the complexities the Web has encountered by learning how to build applications and services before they are subject to the short-term necessities of commercial development. While Meru cannot compete with the content creation of commercial virtual worlds, it can, like the original World Wide Web at CERN, investigate basic questions about system design. By doing so, the door can be opened to a future where physical sensors in the real world seed their virtual reflections, users can visually browse a sea of information, and virtual avatars convey physical social cues to bring distance interaction to the level of actual presence.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>IBM</author></authors></contributors><titles><title>Made in IBM Labs: IBM 3-D Data Centers Show Virtual Worlds Fit for Business</title></titles><periodical/><keywords/><dates><year>2008</year></dates><notes>Press release for IBM's 3-D Data Center technology and Holographic Enterprise Network middleware.
Used by Implenia (the guys who headed the Eolus One project) to further the ability of their building
management virtual world interface to control HVAC/etc. to effect reductions in energy consumption, etc.</notes><research-notes>Press release for IBM's 3-D Data Center technology and Holographic Enterprise Network middleware.
Used by Implenia (the guys who headed the Eolus One project) to further the ability of their building
management virtual world interface to control HVAC/etc. to effect reductions in energy consumption, etc.</research-notes><urls><web-urls><url>http://www-03.ibm.com/press/us/en/pressrelease/23565.wss</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Ikeuchi, Katsushi</author><author>Nakazawa, Atsushi</author><author>Hasegawa, Kazuhide</author><author>Ohishi, Takeshi</author></authors></contributors><titles><title>The Great Buddha Project: Modeling Cultural Heritage for VR Systems through Observation</title></titles><periodical/><pages>7</pages><keywords/><dates><year>2003</year></dates><isbn>0-7695-2006-5</isbn><notes>Research on digital preservation of cultural assets (in this case statues of Buddha) &amp;
digital restoration of their original appearance. Gets very maths-ey.
        
Usable quote - &quot;Currently, a large number of cultural heritage objects around the world
are deteriorating or being destroyed because of natural weathering, disasters and civil wars.&quot;</notes><research-notes>Research on digital preservation of cultural assets (in this case statues of Buddha) &amp;
digital restoration of their original appearance. Gets very maths-ey.
        
Usable quote - &quot;Currently, a large number of cultural heritage objects around the world
are deteriorating or being destroyed because of natural weathering, disasters and civil wars.&quot;</research-notes><urls><pdf-urls><url>internal-pdf://Ikeuchi et al. - 2003 - The Great Buddha Project Modeling Cultural Heritage for VR Systems through Observation.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=946248.946860</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>International Organization for Standardization (ISO)</author></authors></contributors><titles><title>International harmonized stage codes</title></titles><periodical/><keywords/><urls><web-urls><url>http://www.iso.org/iso/standards_development/processes_and_procedures/stages_description/stages_table.htm#s90</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>International Organization for Standardization</author><author>(ISO)</author></authors></contributors><titles><title>ISO/IEC 23005-1:2011 - Information technology -- Media context and control -- Part 1: Architecture</title></titles><periodical/><keywords/><dates><year>2011</year></dates><urls><web-urls><url>http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=54985</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>ITU</author><author>Union, International Telecommunication</author></authors></contributors><titles><title>Req.ITU-T Y.2221 Requirements for support of ubiquitous sensor network (USN) applications and services in the NGN environment</title></titles><periodical/><keywords/><dates><year>2010</year></dates><notes>        From Duplicate 2 (                           Req.ITU-T Y.2221 Requirements for support of ubiquitous sensor network (USN) applications and services in the NGN environment                         - ITU )
                
Provides a description &amp; general characteristics of USN &amp; USN applicati-
-ons &amp; services. Also analyses the service requirements of USN applicat-
-ions &amp; services &amp; specifies the extended or new NGN capability require-
-ments based on the service requirements.
        
Good definition/description of what a USN is - conceptual network built
over existing physical networks which makes use of sensed data &amp; provid-
-es knowledge services to anyone, anywhere &amp; at any time &amp; where inform-
-ation is generated by using context awareness.
        
      </notes><research-notes>        From Duplicate 2 (                           Req.ITU-T Y.2221 Requirements for support of ubiquitous sensor network (USN) applications and services in the NGN environment                         - ITU )
                
Provides a description &amp; general characteristics of USN &amp; USN applicati-
-ons &amp; services. Also analyses the service requirements of USN applicat-
-ions &amp; services &amp; specifies the extended or new NGN capability require-
-ments based on the service requirements.
        
Good definition/description of what a USN is - conceptual network built
over existing physical networks which makes use of sensed data &amp; provid-
-es knowledge services to anyone, anywhere &amp; at any time &amp; where inform-
-ation is generated by using context awareness.
        
      </research-notes><urls/></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Jakobs, Kai</author></authors></contributors><titles><title>Real Standards for Virtual Worlds – Why and How?</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>Only mentions virtual worlds very briefly in the introduction &amp; the summary, the main bulk of the paper
talks about the organisation of national &amp; international standards organisations &amp; why it is difficult
to come to agreement etc., but in a very discipline-independent way &amp; only brings virtual worlds back
into the discussion in the summary at the very end of the paper. So not overly useful.</notes><research-notes>Only mentions virtual worlds very briefly in the introduction &amp; the summary, the main bulk of the paper
talks about the organisation of national &amp; international standards organisations &amp; why it is difficult
to come to agreement etc., but in a very discipline-independent way &amp; only brings virtual worlds back
into the discussion in the summary at the very end of the paper. So not overly useful.</research-notes><urls><web-urls><url>http://journals.tdl.org/jvwr/article/view/717</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Janer, Jordi</author><author>Finney, Nathaniel</author><author>Roma, Gerard</author><author>Kersten, Stefan</author><author>Serra, Xavier</author></authors></contributors><titles><title>Supporting Soundscape Design in Virtual Environments with Content-based Audio Retrieval</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>Talks about the importance of sound &amp; not just graphics for virtual worlds &amp; how sounds are difficult
when users are creating their own objects, unless a framework is adopted for finding sounds from a
free to access repository using metadata, machine learning, etc. Not particularly useful in general
for cross reality, but emphasises the importance of standards for further virtual world adoption.</notes><research-notes>Talks about the importance of sound &amp; not just graphics for virtual worlds &amp; how sounds are difficult
when users are creating their own objects, unless a framework is adopted for finding sounds from a
free to access repository using metadata, machine learning, etc. Not particularly useful in general
for cross reality, but emphasises the importance of standards for further virtual world adoption.</research-notes><urls><web-urls><url>http://journals.tdl.org/jvwr/article/view/635/523</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Jovanova, Blagica</author><author>Preda, Marius</author><author>Preteux, Françoise</author></authors></contributors><titles><title>The Role of Interoperability in Virtual Worlds, Analysis of the Specific Cases of Avatars</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>Mentions the exact opposite of what I want to do with GPS &amp; avatar movement - moving a robot in the real world according to information from the virtual world.</notes><research-notes>Mentions the exact opposite of what I want to do with GPS &amp; avatar movement - moving a robot in the real world according to information from the virtual world.</research-notes><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/672/508</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Juarez, Alex</author><author>Bartneck, Christoph</author><author>Feijs, Lou</author></authors></contributors><titles><title>On the creation of standards for interaction between real robots and virtual worlds</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>I would consider a robot to be a specific type or grouping of multiple actuators, so I wouldn't agree
that we need standards specifically for allowing communication between robots and virtual worlds, but
that a framework (such as ISO/IEC 23005) that allows media &amp; control information to flow between real
&amp; virtual worlds should allow for the control &amp; interaction of virtual worlds with robots. So this is
an application of cross reality, essentially.</notes><research-notes>I would consider a robot to be a specific type or grouping of multiple actuators, so I wouldn't agree
that we need standards specifically for allowing communication between robots and virtual worlds, but
that a framework (such as ISO/IEC 23005) that allows media &amp; control information to flow between real
&amp; virtual worlds should allow for the control &amp; interaction of virtual worlds with robots. So this is
an application of cross reality, essentially.</research-notes><urls><web-urls><url>http://journals.tdl.org/jvwr/article/view/655</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Kang, Lee</author><author>Lee, Kang</author></authors></contributors><titles><title>IEEE 1451: A standard in support of smart transducer networking</title><secondary-title>Instrumentation and Measurement Technology Conference, 2000. IMTC 2000. Proceedings of the 17th IEEE</secondary-title></titles><periodical><full-title>Instrumentation and Measurement Technology Conference, 2000. IMTC 2000. Proceedings of the 17th IEEE</full-title></periodical><pages>525-528</pages><volume>2</volume><keywords><keyword>IEEE 1451 interface standards</keyword><keyword>IEEE 1451.2</keyword><keyword>P1451.3</keyword></keywords><dates><year>2000</year></dates><publisher>IEEE</publisher><isbn>0-7803-5890-2</isbn><electronic-resource-num>10.1109/IMTC.2000.848791</electronic-resource-num><notes>        From Duplicate 2 (                           IEEE 1451: A standard in support of smart transducer networking                         - Kang, Lee )
                
Published in 2000 when 1451.1 (common object model &amp; interface specs for
components of a networkd smart transducer) &amp; 1451.2 (transducers-to-NCAP
interface &amp; TEDS for point-to-point configuration) were newly adopted
standards &amp; 1451.3 (transducer-to-NCAP interface &amp; TEDS using multi-drop
communication) &amp; 1451.4 (mixed-mode interface for analog transducers
with analog &amp; digital operating modes) were proposed standards. To put
this in context, in 2008 there was 1451.0 to 1451.7.
        
&quot;... the IEEE 1451 project's aim is to reduce industry's effort to
develop and migrate to networked smart transducers&quot;
        
      </notes><research-notes>        From Duplicate 2 (                           IEEE 1451: A standard in support of smart transducer networking                         - Kang, Lee )
                
Published in 2000 when 1451.1 (common object model &amp; interface specs for
components of a networkd smart transducer) &amp; 1451.2 (transducers-to-NCAP
interface &amp; TEDS for point-to-point configuration) were newly adopted
standards &amp; 1451.3 (transducer-to-NCAP interface &amp; TEDS using multi-drop
communication) &amp; 1451.4 (mixed-mode interface for analog transducers
with analog &amp; digital operating modes) were proposed standards. To put
this in context, in 2008 there was 1451.0 to 1451.7.
        
&quot;... the IEEE 1451 project's aim is to reduce industry's effort to
develop and migrate to networked smart transducers&quot;
        
      </research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=848791</url></web-urls></urls><abstract>The IEEE 1451 smart transducer interface standards provide the common interface and enabling technology for the connectivity of transducers to microprocessors, control and field networks, and data acquisition and instrumentation systems. The standardized TEDS specified by IEEE 1451.2 allows the self-description of sensors and the interfaces provide a standardized mechanism to facilitate the “Plug and play ” of sensors to networks. The network-independent smart transducer object model defined by IEEE 1451.1 allows sensor manufacturers to support multiple networks and protocols. Thus, transducer-to-network interoperability is on the horizon. The inclusion of P1451.3 and P1451.4 to the family of 1451 standards will meet the needs of the analog transducer users for high-speed applications. In the long run, transducer vendors and users, system integrators, and network providers can all benefit from the IEEE 1451 interface standards</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Kansal, Aman</author><author>Nath, Suman</author><author>Liu, Jie</author><author>Zhao, Feng</author></authors></contributors><titles><title>SenseWeb: An Infrastructure for Shared Sensing</title><secondary-title>Multimedia, IEEE</secondary-title></titles><periodical><full-title>Multimedia, IEEE</full-title></periodical><pages>8-13</pages><volume>14</volume><issue>4</issue><keywords><keyword>Internet</keyword><keyword>optimal sensor se</keyword><keyword>SenseWeb infrastructure</keyword></keywords><dates><year>2007</year></dates><electronic-resource-num>10.1109/MMUL.2007.82</electronic-resource-num><notes>        From Duplicate 1 (                           SenseWeb: An Infrastructure for Shared Sensing                         - Kansal, Aman; Nath, Suman; Liu, Jie; Zhao, Feng )
                
IEEE Multimedia mag article, provides a background/introduction to MS
SenseWeb, which enables peer production of sensing applications over
existing data networks.
        
      </notes><research-notes>        From Duplicate 1 (                           SenseWeb: An Infrastructure for Shared Sensing                         - Kansal, Aman; Nath, Suman; Liu, Jie; Zhao, Feng )
                
IEEE Multimedia mag article, provides a background/introduction to MS
SenseWeb, which enables peer production of sensing applications over
existing data networks.
        
      </research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4354151</url></web-urls></urls><abstract>Peer-produced systems can achieve what might be infeasible for stand-alone systems developed by a single entity. The SenseWeb's goal is to enable these kinds of capabilities. Using SenseWeb, applications can initiate and access sensor data streams from shared sensors across the entire Internet. The SenseWeb infrastructure helps ensure optimal sensor selection for each application and efficient sharing of sensor streams among multiple applications.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Kimber, Don</author><author>Vaughan, Jim</author><author>Rieffel, Eleanor</author></authors></contributors><titles><title>Augmented Perception through Mirror Worlds</title><secondary-title>Proceedings of the 2nd Augmented Human International Conference</secondary-title></titles><periodical><full-title>Proceedings of the 2nd Augmented Human International Conference</full-title></periodical><pages>36</pages><issue>1</issue><keywords><keyword>augmented</keyword><keyword>mixed reality</keyword><keyword>sensor networks</keyword><keyword>virtual worlds</keyword></keywords><dates><year>2011</year></dates><publisher>ACM</publisher><isbn>9781450304269</isbn><notes>Not cross reality - no virtual to real media/control flow.</notes><research-notes>Not cross reality - no virtual to real media/control flow.</research-notes><urls><web-urls><url>http://portal.acm.org/citation.cfm?id=1959862</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Kim, Kangsoo</author><author>Seo, Byung-Kuk</author><author>Han, Jae-Hyek</author><author>Park, Jong-Il</author></authors></contributors><titles><title>Augmented reality tour system for immersive experience of cultural heritage</title><secondary-title>Proceedings of the 8th International Conference on Virtual Reality Continuum and its Applications in Industry - VRCAI '09</secondary-title></titles><periodical><full-title>Proceedings of the 8th International Conference on Virtual Reality Continuum and its Applications in Industry - VRCAI '09</full-title></periodical><pages>323</pages><keywords><keyword>augmented reality</keyword><keyword>cultural heritage tour system</keyword><keyword>virtual tours</keyword></keywords><dates><year>2009</year></dates><pub-location>New York, New York, USA</pub-location><publisher>ACM Press</publisher><isbn>9781605589121</isbn><electronic-resource-num>10.1145/1670252.1670325</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Kim et al. - 2009 - Augmented reality tour system for immersive experience of cultural heritage.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1670252.1670325</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Kim, Marie</author><author>Gak, Hwang Jae</author><author>Pyo, Cheol Sig</author></authors></contributors><titles><title>Practical RFID + sensor convergence toward context-aware X-reality</title><secondary-title>Proceedings of the 2nd International Conference on Interaction Sciences: Information Technology, Culture and Human</secondary-title></titles><periodical><full-title>Proceedings of the 2nd International Conference on Interaction Sciences: Information Technology, Culture and Human</full-title></periodical><pages>1049-1055</pages><keywords><keyword>actuator</keyword><keyword>middleware</keyword><keyword>RFID</keyword><keyword>sensor</keyword><keyword>USN</keyword><keyword>x-reality</keyword></keywords><dates><year>2009</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-60558-710-3</isbn><electronic-resource-num>http://doi.acm.org/10.1145/1655925.1656115</electronic-resource-num><notes>        From Duplicate 1 (                           Practical RFID + sensor convergence toward context-aware X-reality                         - Kim, Marie; Gak, Hwang Jae; Pyo, Cheol Sig )
                
Identifies that the main challenge of integrating RFID/sensor tech with
Second Life is the heterogeneity of the hardware &amp; thus a Ubiquitous
Sensor Middleware (USN) is needed. Presents such a USN, COSMOS, which
integrates with RFID reader networks, sensor &amp; actuator network &amp; shows
how it functions as part of a cross reality system. COSMOS is tested
using software simulations of hardware.
        
Also one of the authors who use 'x-reality' more than 'cross reality'.
        
Nice quote &quot;The important point of X-reality is a conceptiual paradigm
shift from single-directional information flows to bidirectional
information flows between two worlds.&quot; etc.
        
      </notes><research-notes>        From Duplicate 1 (                           Practical RFID + sensor convergence toward context-aware X-reality                         - Kim, Marie; Gak, Hwang Jae; Pyo, Cheol Sig )
                
Identifies that the main challenge of integrating RFID/sensor tech with
Second Life is the heterogeneity of the hardware &amp; thus a Ubiquitous
Sensor Middleware (USN) is needed. Presents such a USN, COSMOS, which
integrates with RFID reader networks, sensor &amp; actuator network &amp; shows
how it functions as part of a cross reality system. COSMOS is tested
using software simulations of hardware.
        
Also one of the authors who use 'x-reality' more than 'cross reality'.
        
Nice quote &quot;The important point of X-reality is a conceptiual paradigm
shift from single-directional information flows to bidirectional
information flows between two worlds.&quot; etc.
        
      </research-notes><urls><pdf-urls><url>internal-pdf://Kim, Gak, Pyo - 2009 - Practical RFID sensor convergence toward context-aware X-reality.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1655925.1656115</url><url>http://doi.acm.org/10.1145/1655925.1656115</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Koleva, Boriana</author><author>Schnädelbach, Holger</author><author>Benford, Steve</author><author>Greenhalgh, Chris</author></authors></contributors><titles><title>Traversable interfaces between real and virtual worlds</title><secondary-title>Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '00</secondary-title></titles><periodical><full-title>Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '00</full-title></periodical><pages>233-240</pages><keywords><keyword>augmented reality</keyword><keyword>mixed reality</keyword><keyword>tele-embodiment</keyword><keyword>tele-presence</keyword><keyword>virtual environments</keyword></keywords><dates><year>2000</year></dates><pub-location>New York, New York, USA</pub-location><publisher>ACM Press</publisher><isbn>1581132166</isbn><electronic-resource-num>10.1145/332040.332437</electronic-resource-num><notes>Describes different displays (interfaces) between real &amp; virtual worlds,
including fabric curtains, rain curtains, sliding doors &amp; flip-up scree-
-ns.</notes><research-notes>Describes different displays (interfaces) between real &amp; virtual worlds,
including fabric curtains, rain curtains, sliding doors &amp; flip-up scree-
-ns.</research-notes><urls><pdf-urls><url>internal-pdf://Koleva et al. - 2000 - Traversable interfaces between real and virtual worlds.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=332040.332437</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Krevelen, D W F Van</author><author>Poelman, R</author></authors></contributors><titles><title>A Survey of Augmented Reality Technologies, Applications and Limitations</title><secondary-title>The International Journal of Virtual Reality</secondary-title></titles><periodical><full-title>The International Journal of Virtual Reality</full-title></periodical><pages>1-20</pages><volume>9</volume><issue>2</issue><keywords/><dates><year>2010</year></dates><notes>Comprehensive overview of AR field, survey of technologies, applications
, limitations &amp; a survey on frameworks as well as content authorting
tools.</notes><research-notes>Comprehensive overview of AR field, survey of technologies, applications
, limitations &amp; a survey on frameworks as well as content authorting
tools.</research-notes><urls><web-urls><url>http://www.mendeley.com/research/survey-augmented-reality-technologies-applications-limitations/</url></web-urls></urls><abstract>We are on the verge of ubiquitously adopting Augmented Reality (AR) technologies to enhance our percep- tion and help us see, hear, and feel our environments in new and enriched ways. AR will support us in fields such as education, maintenance, design and reconnaissance, to name but a few. This paper describes the field of AR, including a brief definition and development history, the enabling technologies and their characteristics. It surveys the state of the art by reviewing some recent applications of AR technology as well as some known limitations regarding human factors in the use of AR systems that developers will need to overcome</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Krueger, Alice</author><author>Ludwig, Ann</author><author>Ludwig, David</author></authors></contributors><titles><title>Universal Design for Virtual Worlds</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>
        From Duplicate 1 ( 
        
        
          Universal Design for Virtual Worlds
        
        
         - Krueger, Alice; Ludwig, Ann; Ludwig, David )

        
        
A slightly strange article, talks about the importance of designing virtual worlds to be accessible
to the disabled (eg by having no steps in virtual worlds, just ramps, so that if a disabled person
represents themselves in the virtual world by an avatar restricted to a wheel chair they will still
be able to move around). Essentially an emphasis that virtual world locations should represent their
real ones accurately when it comes to access, tangentially related to the mimicing of a real world
location with a virtual environment simulation a la cross reality.

        

      </notes><research-notes>
        From Duplicate 1 ( 
        
        
          Universal Design for Virtual Worlds
        
        
         - Krueger, Alice; Ludwig, Ann; Ludwig, David )

        
        
A slightly strange article, talks about the importance of designing virtual worlds to be accessible
to the disabled (eg by having no steps in virtual worlds, just ramps, so that if a disabled person
represents themselves in the virtual world by an avatar restricted to a wheel chair they will still
be able to move around). Essentially an emphasis that virtual world locations should represent their
real ones accurately when it comes to access, tangentially related to the mimicing of a real world
location with a virtual environment simulation a la cross reality.

        

      </research-notes><urls><web-urls><url>http://journals.tdl.org/jvwr/article/view/674</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Krueger, Alice</author><author>Stineman, Margaret</author></authors></contributors><titles><title>Assistive Technology Interoperability between Virtual and Real Worlds</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>4</volume><issue>3</issue><keywords/><dates><year>2011</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/6125</url></web-urls></urls><abstract>Accessibility is an important area of interoperability between real and virtual worlds that must be considered during standards-setting. The number of persons with disabilities is large and increasing, as is their use of virtual worlds. All elements of virtual worlds must be accessible. Four types of real world disability impact functioning in virtual worlds: keyboard/mouse; print; hearing/speech; and cognitive. Some virtual worlds include accessibility features, such as resizable UI elements and fonts. Alternative keyboards and mice usually work adequately in virtual worlds. However, common text-to-speech, speech-to-text, and screen reader software doesn't interface well with virtual worlds. Existing accessibility guidelines and legislation (Universal Design, Internet accessibility standards and guidelines, and online game accessibility guidelines) might be applicable to virtual worlds. Practical limitations to implementation of these solutions include their complexity and cost. As government agencies, universities, and employers increase their use of virtual worlds, specific standards for virtual world accessibility, including interfacing with common assistive technology, need to be created and enforced.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Laycock, R. G.</author><author>Drinkwater, D.</author><author>Day, A. M.</author></authors></contributors><titles><title>Exploring cultural heritage sites through space and time</title><secondary-title>J. Comput. Cult. Herit.</secondary-title></titles><periodical><full-title>J. Comput. Cult. Herit.</full-title></periodical><pages>11:1--11:15</pages><volume>1</volume><issue>2</issue><keywords><keyword>interfaces</keyword><keyword>Urban modeling</keyword></keywords><dates><year>2008</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><electronic-resource-num>http://doi.acm.org/10.1145/1434763.1434768</electronic-resource-num><notes>        From Duplicate 1 (                           Exploring cultural heritage sites through space and time                         - Laycock, R. G.; Drinkwater, D.; Day, A. M. )
                
Using virtual cultural heritage to visualise the changes to a heritage site/object
with advancing time. Semi-automatic approach to creating a large virtual city using
replication of common buildings/building features.
        
      </notes><research-notes>        From Duplicate 1 (                           Exploring cultural heritage sites through space and time                         - Laycock, R. G.; Drinkwater, D.; Day, A. M. )
                
Using virtual cultural heritage to visualise the changes to a heritage site/object
with advancing time. Semi-automatic approach to creating a large virtual city using
replication of common buildings/building features.
        
      </research-notes><urls><pdf-urls><url>internal-pdf://Laycock, Drinkwater, Day - 2008 - Exploring cultural heritage sites through space and time.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1434763.1434768</url><url>http://doi.acm.org/10.1145/1434763.1434768</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Lee, Kang K.B.</author><author>Schneeman, Richard R.D.</author></authors></contributors><titles><title>Distributed measurement and control based on the IEEE 1451 smart transducer interface standards</title><secondary-title>Instrumentation and Measurement, IEEE Transactions on</secondary-title></titles><periodical><full-title>Instrumentation and Measurement, IEEE Transactions on</full-title></periodical><pages>621-627</pages><volume>49</volume><issue>3</issue><keywords><keyword>API</keyword><keyword>Ethernet</keyword><keyword>IEEE 1451</keyword><keyword>Internet-based system</keyword><keyword>TCP/I</keyword></keywords><dates><year>2000</year></dates><electronic-resource-num>10.1109/19.850405</electronic-resource-num><notes>        From Duplicate 1 (                           Distributed measurement and control based on the IEEE 1451 smart transducer interface standards                         - Lee, K.B.; Schneeman, R.D. )
                
Describes the application of IEEE 1451 to Distributed Measurement &amp;
Control systems in an open standards way rather than based on
proprietary approaches that had been the norm in industry before 2000.
        
      </notes><research-notes>        From Duplicate 1 (                           Distributed measurement and control based on the IEEE 1451 smart transducer interface standards                         - Lee, K.B.; Schneeman, R.D. )
                
Describes the application of IEEE 1451 to Distributed Measurement &amp;
Control systems in an open standards way rather than based on
proprietary approaches that had been the norm in industry before 2000.
        
      </research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=850405</url></web-urls></urls><abstract>This paper details a framework developed at NIST that highlights the standardization efforts going on within the various levels of an Internet-based distributed measurement and control (DMC) system. The framework highlights state-of-the-art hardware and software techniques used at NIST to design, implement, and deploy next-generation Internet-based DMC applications and systems. The framework targets three important areas of standardization including transducer interfaces, open network communication, and distributed application development. An implementation of a DMC application on the Internet based on the NIST framework is also described. The paper concludes with a brief introduction to other research activities at NIST culminating from this core Internet-based DMC research</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Lehtiniemi, Tuukka</author></authors></contributors><titles><title>Measuring Aggregate Production in a Virtual Economy Using Log Data</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>Focuses on virtual envrionments in which the operator designs the goods &amp; the production paths - eg most MMORPGs (WoW, etc.) eg not 'virtual worlds' akin to Second Life &amp; friends.

        
Author says in the conclusion that there is no reason why the same approaches couldn't be used for virtual environments with different economy styles, but this seems a dubious claim &amp; it is just an ending comment - there is no actual research into this presented.</notes><research-notes>Focuses on virtual envrionments in which the operator designs the goods &amp; the production paths - eg most MMORPGs (WoW, etc.) eg not 'virtual worlds' akin to Second Life &amp; friends.

        
Author says in the conclusion that there is no reason why the same approaches couldn't be used for virtual environments with different economy styles, but this seems a dubious claim &amp; it is just an ending comment - there is no actual research into this presented.</research-notes><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/631/512</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Levoy, Marc</author></authors></contributors><titles><title>The digital michelangelo project</title></titles><periodical/><pages>2-11</pages><keywords/><dates><year>1999</year></dates><isbn>0-7695-0062-5</isbn><notes>Very interesting project by Stanford using laser rangefinders/scanners to digitize Michelangelo's David &amp; other
statues as well as other artefacts &amp; parts of the museum buildings themselves. </notes><research-notes>Very interesting project by Stanford using laser rangefinders/scanners to digitize Michelangelo's David &amp; other
statues as well as other artefacts &amp; parts of the museum buildings themselves. </research-notes><urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1889712.1889714</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Levoy, Marc</author><author>Pulli, Kari</author><author>Curless, Brian</author><author>Rusinkiewicz, Szymon</author><author>Koller, David</author><author>Pereira, Lucas</author><author>Ginzton, Matt</author><author>Anderson, Sean</author><author>Davis, James</author><author>Ginsberg, Jeremy</author><author>Shade, Jonathan</author><author>Fulk, Duane</author></authors></contributors><titles><title>The digital Michelangelo project: 3D scanning of large statues</title><secondary-title>Proceedings of the 27th annual conference on Computer graphics and interactive techniques</secondary-title></titles><periodical><full-title>Proceedings of the 27th annual conference on Computer graphics and interactive techniques</full-title></periodical><pages>131-144</pages><keywords><keyword>3D scanning</keyword><keyword>cultural heritage</keyword><keyword>graphics systems</keyword><keyword>mesh generation</keyword><keyword>range images</keyword><keyword>rangefinding</keyword><keyword>reflectance and shading models</keyword><keyword>sensor fusion</keyword></keywords><dates><year>2000</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM Press/Addison-Wesley Publishing Co.</publisher><isbn>1-58113-208-5</isbn><electronic-resource-num>http://dx.doi.org/10.1145/344779.344849</electronic-resource-num><notes>        From Duplicate 1 (                           The digital Michelangelo project                         - Levoy, Marc; Ginsberg, Jeremy; Shade, Jonathan; Fulk, Duane; Pulli, Kari; Curless, Brian; Rusinkiewicz, Szymon; Koller, David; Pereira, Lucas; Ginzton, Matt; Anderson, Sean; Davis, James )
                
More detail than in the 1999 paper.
        
      </notes><research-notes>        From Duplicate 1 (                           The digital Michelangelo project                         - Levoy, Marc; Ginsberg, Jeremy; Shade, Jonathan; Fulk, Duane; Pulli, Kari; Curless, Brian; Rusinkiewicz, Szymon; Koller, David; Pereira, Lucas; Ginzton, Matt; Anderson, Sean; Davis, James )
                
More detail than in the 1999 paper.
        
      </research-notes><urls><pdf-urls><url>internal-pdf://Levoy et al. - 2000 - The digital Michelangelo project.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=344779.344849</url><url>http://dx.doi.org/10.1145/344779.344849</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Lifton, Joshua</author></authors></contributors><titles><title>Dual Reality: An Emerging Medium</title></titles><periodical/><keywords/><dates><year>2007</year></dates><pub-location>Department of Media Arts and Sciences</pub-location><notes>        From Duplicate 1 (                           Dual Reality: An Emerging Medium                         - Lifton, Joshua )
                
Lifton's PhD thesis, essentially the inaugural piece of work on cross
reality. He called it 'dual reality' at this point but it's exactly the
same thing (which he confirms). Has probably the very first
definition of dual reality, definition of sensor networks/ubicomp/VWs,
identifies the bidirectional nature of cross reality, discusses mapping
between real &amp; virtual (whether it should be one-to-one or not), has a
survey of the earliest projects that did augmented virtuality, reference
to the 'second earth' concept, introduces the concept of 'virtual
sensing' which is a much better way to go about controlling actuation
from within the VW, identifies the platform-dependency of the Plug but
mentions that there is not much to stop it from being adapted to
different platforms, identifies that HTTP is pretty much the only means
of communicating with SL because XML-RPC is so useless, identifies the
lack of a standard middleware (with which to compare Plug etc. against),
mentions people maintaining an online presence, identifies that this
piece of work is 'framing dual reality as a new application domain for
sensor networks, virtual words &amp; media creation' &amp; identifies the
importance of automatic support to identify phenomena based on readings
from multiple sensed modalities.
        
      </notes><research-notes>        From Duplicate 1 (                           Dual Reality: An Emerging Medium                         - Lifton, Joshua )
                
Lifton's PhD thesis, essentially the inaugural piece of work on cross
reality. He called it 'dual reality' at this point but it's exactly the
same thing (which he confirms). Has probably the very first
definition of dual reality, definition of sensor networks/ubicomp/VWs,
identifies the bidirectional nature of cross reality, discusses mapping
between real &amp; virtual (whether it should be one-to-one or not), has a
survey of the earliest projects that did augmented virtuality, reference
to the 'second earth' concept, introduces the concept of 'virtual
sensing' which is a much better way to go about controlling actuation
from within the VW, identifies the platform-dependency of the Plug but
mentions that there is not much to stop it from being adapted to
different platforms, identifies that HTTP is pretty much the only means
of communicating with SL because XML-RPC is so useless, identifies the
lack of a standard middleware (with which to compare Plug etc. against),
mentions people maintaining an online presence, identifies that this
piece of work is 'framing dual reality as a new application domain for
sensor networks, virtual words &amp; media creation' &amp; identifies the
importance of automatic support to identify phenomena based on readings
from multiple sensed modalities.
        
      </research-notes><urls/></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Lifton, Joshua</author></authors></contributors><titles><title>Consumer Adoption of Cross Reality Systems</title><secondary-title>Proceedings of the International Symposium on Ubiquitous Virtual Reality 2010 (ISUVR 2010)</secondary-title></titles><periodical><full-title>Proceedings of the International Symposium on Ubiquitous Virtual Reality 2010 (ISUVR 2010)</full-title></periodical><pages>9-11</pages><keywords><keyword>cross reality</keyword><keyword>dual reality</keyword><keyword>ubiquitous computing</keyword><keyword>ubiquitous virtual reality</keyword><keyword>virtual worlds</keyword></keywords><dates><year>2010</year></dates><publisher>IEEE</publisher><isbn>978-1-4244-7702-9</isbn><electronic-resource-num>10.1109/ISUVR.2010.26</electronic-resource-num><notes>        From Duplicate 1 (                           Consumer Adoption of Cross Reality Systems                         - Lifton, Joshua )
                
Retrospective piece written by Lifton after moving from academia (MIT)
to industry (Electric Sheep Company) &amp; then on to consultant &amp; educator.
Lists observations of what has marred the wider uptake of cross reality.
        
&gt; Second Life failed to achieve the consumer uptake it promised
&gt; Adoption of hardware required for cross reality is slow; even now we
only have a smattering of sensors in common use (passport RFID, mobile
phone location/orientation, body-gesture in games consoles)
&gt; Virtual worlds do not allow as much expression of identity as online
social networks, soon social networks may begin to fit the bill of VWs
        
Confirmation from Lifton himself that 'dual reality' &amp; 'cross reality'
are the same thing under different names.
        
      </notes><research-notes>        From Duplicate 1 (                           Consumer Adoption of Cross Reality Systems                         - Lifton, Joshua )
                
Retrospective piece written by Lifton after moving from academia (MIT)
to industry (Electric Sheep Company) &amp; then on to consultant &amp; educator.
Lists observations of what has marred the wider uptake of cross reality.
        
&gt; Second Life failed to achieve the consumer uptake it promised
&gt; Adoption of hardware required for cross reality is slow; even now we
only have a smattering of sensors in common use (passport RFID, mobile
phone location/orientation, body-gesture in games consoles)
&gt; Virtual worlds do not allow as much expression of identity as online
social networks, soon social networks may begin to fit the bill of VWs
        
Confirmation from Lifton himself that 'dual reality' &amp; 'cross reality'
are the same thing under different names.
        
      </research-notes><urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1848072.1848338</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Lifton, Joshua</author><author>Feldmeier, Mark</author><author>Ono, Yasuhiro</author><author>Lewis, Cameron</author><author>Paradiso, Joseph A.</author></authors></contributors><titles><title>A platform for ubiquitous sensor deployment in occupational and domestic environments</title><secondary-title>Proceedings of the 6th international conference on Information processing in sensor networks - IPSN '07</secondary-title></titles><periodical><full-title>Proceedings of the 6th international conference on Information processing in sensor networks - IPSN '07</full-title></periodical><pages>119</pages><keywords/><dates><year>2007</year></dates><pub-location>New York, New York, USA</pub-location><publisher>ACM Press</publisher><isbn>978159593638X</isbn><electronic-resource-num>10.1145/1236360.1236377</electronic-resource-num><notes>Paper about the Plug sensor/actuator platform developed by the Media Lab for Lifton's research. Published before Lifton's PhD so doesn't contain as much information as the PhD does about Plug &amp; its uses.</notes><research-notes>Paper about the Plug sensor/actuator platform developed by the Media Lab for Lifton's research. Published before Lifton's PhD so doesn't contain as much information as the PhD does about Plug &amp; its uses.</research-notes><urls><pdf-urls><url>internal-pdf://Lifton et al. - 2007 - A platform for ubiquitous sensor deployment in occupational and domestic environments.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1236360.1236377</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Lifton, Joshua</author><author>Laibowitz, Mathew</author><author>Harry, Drew</author><author>Gong, Nan-wei</author><author>Mittal, Manas</author><author>Paradiso, Joseph A.</author></authors></contributors><titles><title>Metaphor and Manifestation - Cross-Reality with Ubiquitous Sensor/Actuator Networks</title><secondary-title>IEEE Pervasive Computing: Mobile and Ubiquitous Systems</secondary-title></titles><periodical><full-title>IEEE Pervasive Computing: Mobile and Ubiquitous Systems</full-title></periodical><pages>24-33</pages><volume>8</volume><issue>3</issue><keywords><keyword>augmented reality</keyword><keyword>IEEE</keyword><keyword>mixed reality</keyword><keyword>mobile computing</keyword><keyword>pervasive computing</keyword><keyword>privacy</keyword><keyword>sensor networks</keyword><keyword>ubiquitous media</keyword><keyword>virtual worlds</keyword></keywords><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.49</electronic-resource-num><notes>        From Duplicate 1 (                           Metaphor and Manifestation Cross-Reality with Ubiquitous Sensor/Actuator Networks                         - Lifton, Joshua; Laibowitz, Mathew; Harry, Drew; Gong, Nan-Wei; Mittal, Manas; Paradiso, Joseph A. )
                
Article from volume 8 issue 3 of IEEE Pervasive Computing magazine (the
one all about cross reality environments) that again essentially just
covers Lifton's PhD &amp; the associated work/projects at the Media Lab.
        
Identifies commercial implementations of cross reality (IBM's data cent-
er operation visualization &amp; VRContext's ProcessLife technology).
        
'wormholes' quote!
        
      </notes><research-notes>        From Duplicate 1 (                           Metaphor and Manifestation Cross-Reality with Ubiquitous Sensor/Actuator Networks                         - Lifton, Joshua; Laibowitz, Mathew; Harry, Drew; Gong, Nan-Wei; Mittal, Manas; Paradiso, Joseph A. )
                
Article from volume 8 issue 3 of IEEE Pervasive Computing magazine (the
one all about cross reality environments) that again essentially just
covers Lifton's PhD &amp; the associated work/projects at the Media Lab.
        
Identifies commercial implementations of cross reality (IBM's data cent-
er operation visualization &amp; VRContext's ProcessLife technology).
        
'wormholes' quote!
        
      </research-notes><urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1591886.1592128</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Lifton, Joshua</author><author>Mittal, Manas</author><author>Lapinski, Michael</author><author>Paradiso, Joseph</author></authors></contributors><titles><title>Tricorder: A mobile sensor network browser</title><secondary-title>Proceedings of the ACM CHI 2007 Conference - Mobile Spatial Interaction Workshop</secondary-title></titles><periodical><full-title>Proceedings of the ACM CHI 2007 Conference - Mobile Spatial Interaction Workshop</full-title></periodical><keywords/><dates><year>2007</year></dates><notes>Paper about the Tricorder handheld sensor network browser. Again, published before Lifton's PhD so more/up-to-date information about Tricorder is in the PhD.</notes><research-notes>Paper about the Tricorder handheld sensor network browser. Again, published before Lifton's PhD so more/up-to-date information about Tricorder is in the PhD.</research-notes><urls/></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Lifton, Joshua</author><author>Paradiso, Joseph</author></authors></contributors><titles><title>Dual Reality: Merging the Real and Virtual</title><secondary-title>Proceedings of the First International ICST Conference on Facets of Virtual Environments (FaVE)</secondary-title></titles><periodical><full-title>Proceedings of the First International ICST Conference on Facets of Virtual Environments (FaVE)</full-title></periodical><keywords/><dates><year>2009</year></dates><notes>        From Duplicate 1 (                           Dual Reality: Merging the Real and Virtual                         - Lifton, Joshua; Paradiso, Joseph )
                
Essentially a paper about the PhD. Good citation for dual reality
comprising 2 worlds that are complete unto themselves, but affect each
other through linkage by sensor/actuator infrastructure.
        
      </notes><research-notes>        From Duplicate 1 (                           Dual Reality: Merging the Real and Virtual                         - Lifton, Joshua; Paradiso, Joseph )
                
Essentially a paper about the PhD. Good citation for dual reality
comprising 2 worlds that are complete unto themselves, but affect each
other through linkage by sensor/actuator infrastructure.
        
      </research-notes><urls><web-urls><url>http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.147.9419</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Lindman, Ludvaig</author></authors></contributors><titles><title>Lindman Design: Virtual World Experiences</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/728/537</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Lukowicz, Paul</author><author>Amft, Oliver</author></authors></contributors><titles><title>From Backpacks to Smartphones: Past, Present, and Future of Wearable Computers</title><secondary-title>Pervasive Computing, IEEE</secondary-title></titles><periodical><full-title>Pervasive Computing, IEEE</full-title></periodical><pages>8-13</pages><volume>8</volume><issue>3</issue><keywords><keyword>bi</keyword><keyword>smartphone</keyword><keyword>wearable computer</keyword><keyword>wearable computing</keyword></keywords><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.44</electronic-resource-num><notes>        From Duplicate 1 (                           From Backpacks to Smartphones: Past, Present, and Future of Wearable Computers                         - Amft, Oliver; Lukowicz, Paul )
                
Not really related to cross reality, but the wearable technologies
discussed could be useful parts of a wearable interface to a virtual
world.
        
      </notes><research-notes>        From Duplicate 1 (                           From Backpacks to Smartphones: Past, Present, and Future of Wearable Computers                         - Amft, Oliver; Lukowicz, Paul )
                
Not really related to cross reality, but the wearable technologies
discussed could be useful parts of a wearable interface to a virtual
world.
        
      </research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165554</url></web-urls></urls><abstract>Do smart phones render wearable computers obsolete? Where does the rise of the smart phone leave wearable computing research? We answer these questions by examining past, present, and future of wearable platform research.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>marketwire</author></authors></contributors><titles><title>IBM 3-D Data Centers Show Virtual Worlds Fit for Business</title></titles><periodical/><keywords/><dates><year>2008</year></dates><notes>News site coverage of the announcement of IBM's 3-D Data Center technology, mostly just repeats what's
in the official press release.</notes><research-notes>News site coverage of the announcement of IBM's 3-D Data Center technology, mostly just repeats what's
in the official press release.</research-notes><urls><web-urls><url>http://www.marketwire.com/press-release/ibm-3-d-data-centers-show-virtual-worlds-fit-for-business-nyse-ibm-823627.htm</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>McKinnon, Lynn D.</author><author>North, Max M.</author></authors></contributors><titles><title>A comparative study of presence in virtual reality vs. presence in the real world</title><secondary-title>Proceedings of the 42nd annual Southeast regional conference on - ACM-SE 42</secondary-title></titles><periodical><full-title>Proceedings of the 42nd annual Southeast regional conference on - ACM-SE 42</full-title></periodical><pages>253</pages><keywords><keyword>sense of presence</keyword><keyword>virtual environments</keyword><keyword>virtual reality</keyword></keywords><dates><year>2004</year></dates><pub-location>New York, New York, USA</pub-location><publisher>ACM Press</publisher><isbn>1581138709</isbn><electronic-resource-num>10.1145/986537.986597</electronic-resource-num><notes>Presents 2 experiments studying sense of presence in virtual reality &amp; real world, see 'extent of prescence metaphor'.</notes><research-notes>Presents 2 experiments studying sense of presence in virtual reality &amp; real world, see 'extent of prescence metaphor'.</research-notes><urls><pdf-urls><url>internal-pdf://McKinnon, North - 2004 - A comparative study of presence in virtual reality vs. presence in the real world.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=986537.986597</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>McNamara, Ann</author><author>Chalmers, Alan</author><author>Troscianko, Tom</author><author>Gilchrist, Iain</author></authors></contributors><titles><title>Comparing Real &amp; Synthetic Scenes using Human Judgements of Lightness</title><secondary-title>Proceedings of the Eurographics Workshop on Rendering Techniques 2000</secondary-title></titles><periodical><full-title>Proceedings of the Eurographics Workshop on Rendering Techniques 2000</full-title></periodical><pages>207-218</pages><keywords/><dates><year>2000</year></dates><pub-location>London, UK</pub-location><publisher>Springer-Verlag</publisher><isbn>3-211-83535-0</isbn><notes>        From Duplicate 1 (                           Comparing Real &amp; Synthetic Scenes using Human Judgements of Lightness                         - McNamara, Ann; Chalmers, Alan; Troscianko, Tom; Gilchrist, Iain )
                
Compares how realistic computer generated scenes are compared to their real counterparts, by creating a scene
&amp; lighting it in the real world &amp; creating a computer simulation of the same &amp; asking participants to
classify the two according to some system.
        
&quot;...the ultimate goal being to create images which are perceptually indistinguishable from an actual scene.&quot;
        
      </notes><research-notes>        From Duplicate 1 (                           Comparing Real &amp; Synthetic Scenes using Human Judgements of Lightness                         - McNamara, Ann; Chalmers, Alan; Troscianko, Tom; Gilchrist, Iain )
                
Compares how realistic computer generated scenes are compared to their real counterparts, by creating a scene
&amp; lighting it in the real world &amp; creating a computer simulation of the same &amp; asking participants to
classify the two according to some system.
        
&quot;...the ultimate goal being to create images which are perceptually indistinguishable from an actual scene.&quot;
        
      </research-notes><urls><web-urls><url>http://dl.acm.org/citation.cfm?id=647652.732122</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Metzger, P.J.</author></authors></contributors><titles><title>Adding reality to the virtual</title><secondary-title>Proceedings of IEEE Virtual Reality Annual International Symposium</secondary-title></titles><periodical><full-title>Proceedings of IEEE Virtual Reality Annual International Symposium</full-title></periodical><pages>7-13</pages><keywords/><publisher>IEEE</publisher><isbn>0-7803-1363-1</isbn><electronic-resource-num>10.1109/VRAIS.1993.380805</electronic-resource-num><notes>Describes a system that is capable of overlaying images of the real wor-
-ld on top of a virtual world scene &amp; overlaying virtual world imagery
onto a real world scene, with applications for both presented.
        
&quot;The merging of these two areas will result in virtual world experiences
more realistic than any available today.&quot;
        
&quot;It will be quite some time before the line separating the real world &amp;
the virtual world disappears completely. However, systems have been cre-
-ated which demonstrate thatit is possible to make the distinction betw-
-een what is real and wha tis virtual a bit more difficult to determine&quot;</notes><research-notes>Describes a system that is capable of overlaying images of the real wor-
-ld on top of a virtual world scene &amp; overlaying virtual world imagery
onto a real world scene, with applications for both presented.
        
&quot;The merging of these two areas will result in virtual world experiences
more realistic than any available today.&quot;
        
&quot;It will be quite some time before the line separating the real world &amp;
the virtual world disappears completely. However, systems have been cre-
-ated which demonstrate thatit is possible to make the distinction betw-
-een what is real and wha tis virtual a bit more difficult to determine&quot;</research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=380805</url></web-urls></urls><abstract>Distributed interactive simulation provides an environment for realistic participation in virtual worlds. Humans interact with the virtual world through interface devices such as switches and knobs, keyboards and mice, touch screens and data gloves. The time has come for the seamless integration of these physical, real-world human interface devices with the systems that generate and display the virtual environments. The merging of these two areas will result in virtual world experiences more realistic than any available today</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Microsoft Research</author></authors></contributors><titles><title>SenseWeb Tutorial</title></titles><periodical/><keywords/><dates><year>2008</year></dates><notes>An introduction to working with SenseWeb, including background on how it
works &amp; the system's architecture.</notes><research-notes>An introduction to working with SenseWeb, including background on how it
works &amp; the system's architecture.</research-notes><urls><web-urls><url>http://research.microsoft.com/en-us/products/senseweb/SenseWebTutorial.pdf</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Milgram, Paul</author><author>Jr., Herman Colquhoun</author></authors></contributors><titles><title>A Taxonomy of Real and Virtual World Display Integration</title></titles><periodical/><keywords/><dates><year>1999</year></dates><urls><pdf-urls><url>internal-pdf://Milgram, Jr. - 1999 - A Taxonomy of Real and Virtual World Display Integration.pdf</url></pdf-urls><web-urls><url>http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.6230</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Milgram, Paul</author><author>Kishino, Fumio</author></authors></contributors><titles><title>A Taxonomy of Mixed Reality Visual Displays</title><secondary-title>IEICE Trans. Information Systems</secondary-title></titles><periodical><full-title>IEICE Trans. Information Systems</full-title></periodical><pages>1321-1329</pages><volume>E77-D</volume><issue>12</issue><keywords><keyword>augmented reality (AR)</keyword><keyword>mixed reality (MR)</keyword><keyword>virtual reality (VR)</keyword></keywords><dates><year>1994</year></dates><notes>Professor at University of Toronoto, responsible for coming up with the
virtuality continuum in all of its different versions. Provides some
fairly high-level theoretical discussion of what distinguishes the
different alternate realities that computer science has come to explore,
including how to determine whether an environment is augmented reality
or augmented virtuality (eg at what point does a scene stop being
augmented reality &amp; become augmented virtuality, etc.).
        
        
        
============
        
        
Brief introduction to mixed reality &amp; to the virtuality continuum
between completely real environments &amp; completely virtual environments.
        
Identifies 3 aspects that distinguish between real &amp; virtual;
&gt; extent of world knowledge
	&quot;how much do we know about the world being displayed?&quot;
	world unmodelled (computer knows nothing about the contents of the
	environment) to world completely modelled (traditional virtual real-
	-ity where the computer has complete knowledge about each object in
	the environment)
&gt; reproduction fidelity
	&quot;how realistically are we able to display it?&quot;
	pertains to both real &amp; virtual objects
&gt; extent of prescence metaphor
	&quot;what is the extent of the illusion that the observer is present
	within that world?&quot;
	mixed reality displays include highly immersive environments with a
	strong presence metaphor, but also exocentric type AR displays
        
Identifies 6 different types of display technology that constitute mixed
reality interfaces.
        
Contains diagrams of virtuality continuum, extent of world knowledge,
reproduction fidelity &amp; extent of presence metaphor (all linear).
        
Definition of virtual reality.</notes><research-notes>Professor at University of Toronoto, responsible for coming up with the
virtuality continuum in all of its different versions. Provides some
fairly high-level theoretical discussion of what distinguishes the
different alternate realities that computer science has come to explore,
including how to determine whether an environment is augmented reality
or augmented virtuality (eg at what point does a scene stop being
augmented reality &amp; become augmented virtuality, etc.).
        
        
        
============
        
        
Brief introduction to mixed reality &amp; to the virtuality continuum
between completely real environments &amp; completely virtual environments.
        
Identifies 3 aspects that distinguish between real &amp; virtual;
&gt; extent of world knowledge
	&quot;how much do we know about the world being displayed?&quot;
	world unmodelled (computer knows nothing about the contents of the
	environment) to world completely modelled (traditional virtual real-
	-ity where the computer has complete knowledge about each object in
	the environment)
&gt; reproduction fidelity
	&quot;how realistically are we able to display it?&quot;
	pertains to both real &amp; virtual objects
&gt; extent of prescence metaphor
	&quot;what is the extent of the illusion that the observer is present
	within that world?&quot;
	mixed reality displays include highly immersive environments with a
	strong presence metaphor, but also exocentric type AR displays
        
Identifies 6 different types of display technology that constitute mixed
reality interfaces.
        
Contains diagrams of virtuality continuum, extent of world knowledge,
reproduction fidelity &amp; extent of presence metaphor (all linear).
        
Definition of virtual reality.</research-notes><urls><web-urls><url>http://etclab.mie.utoronto.ca/people/paul_dir/IEICE94/ieice.html</url></web-urls></urls><abstract>This paper focuses on Mixed Reality (MR) visual displays, a particular subset of Virtual Reality (VR) related technologies that involve the merging of real and virtual worlds somewhere along the &quot;virtuality continuum&quot; which connects completely real environments to completely virtual ones. Probably the best known of these is Augmented Reality (AR), which refers to all cases in which the display of an otherwise real environment is augmented by means of virtual (computer graphic) objects. The converse case on the virtuality continuum is therefore Augmented Virtuality (AV). Six classes of hybrid MR display environments are identified. However, an attempt to distinguish these classes on the basis of whether they are primarily video or computer graphics based, whether the real world is viewed directly or via some electronic display medium, whether the viewer is intended to feel part of the world or on the outside looking in, and whether or not the scale of the display is intended to map orthoscopically onto the real world leads to quite different groupings among the six identified classes, thereby demonstrating the need for an efficient taxonomy, or classification framework, according to which essential differences can be identified. The 'obvious' distinction between the terms &quot;real&quot; and &quot;virtual&quot; is shown to have a number of different aspects, depending on whether one is dealing with real or virtual objects, real or virtual images, and direct or non-direct viewing of these. An (approximately) three dimensional taxonomy is proposed, comprising the following dimensions: Extent of World Knowledge (&quot;how much do we know about the world being displayed?&quot;), Reproduction Fidelity (&quot;how 'realistically' are we able to display it?&quot;), and Extent of Presence Metaphor (&quot;what is the extent of the illusion that the observer is present within that world?&quot;).</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Mirco Musolesi, Emiliano Miluzzo</author><author>Musolesi, Mirco</author><author>Miluzzo, Emiliano</author><author>Lane, Nicholas D</author><author>Eisenman, Shane B</author><author>Choudhury, Tanzeem</author><author>Campbell, Andrew T</author></authors></contributors><titles><title>The Second Life of a Sensor: Integrating Real-world Experience in Virtual Worlds using Mobile Phones</title><secondary-title>In Proc. of HotEmNets ’08</secondary-title></titles><periodical><full-title>In Proc. of HotEmNets ’08</full-title></periodical><keywords/><dates><year>2008</year></dates><urls><web-urls><url>http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.147.1457</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>MIT</author></authors></contributors><titles><title>DoppelLab - Exploring Dense Sensor Network Data Through A Game Engine</title></titles><periodical/><keywords/><urls/></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>MIT</author></authors></contributors><titles><title>Responsive Environments Group</title></titles><periodical/><keywords/><notes>        From Duplicate 1 (                           Responsive Environments Group                         - MIT )
                
MIT's Media Laboratory (particularly the Responsive Environments group
under the leadership of Joseph Paradiso) was responsible for essentially
the inaugural work in cross reality, with Joshua Lifton's PhD &amp; the
associated projects in the group framing 'dual reality', as it was
originally known, as a new application domain for sensor/actuator
networks, virtual worlds &amp; media creation. Lifton himself confirms that
cross reality &amp; dual reality are the same thing by different names.
        
      </notes><research-notes>        From Duplicate 1 (                           Responsive Environments Group                         - MIT )
                
MIT's Media Laboratory (particularly the Responsive Environments group
under the leadership of Joseph Paradiso) was responsible for essentially
the inaugural work in cross reality, with Joshua Lifton's PhD &amp; the
associated projects in the group framing 'dual reality', as it was
originally known, as a new application domain for sensor/actuator
networks, virtual worlds &amp; media creation. Lifton himself confirms that
cross reality &amp; dual reality are the same thing by different names.
        
      </research-notes><urls><web-urls><url>http://www.media.mit.edu/resenv/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>OMG</author></authors></contributors><titles><title>Smart Transducer Interface Specification</title></titles><periodical/><keywords/><dates><year>2007</year></dates><notes>More definition of 'smart transducer', use in combination with elmenreich.</notes><research-notes>More definition of 'smart transducer', use in combination with elmenreich.</research-notes><urls><web-urls><url>http://www.omg.org/docs/formal/03-01-01.pdf</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Open Geospatial Consortium, Inc.</author></authors></contributors><titles><title>OWS-4 Demonstration</title></titles><periodical/><keywords/><notes>Videos/more information on demonostrations of SWE at OWS-4, covers the dirty bomb scenario.</notes><research-notes>Videos/more information on demonostrations of SWE at OWS-4, covers the dirty bomb scenario.</research-notes><urls><web-urls><url>http://www.opengeospatial.org/pub/www/ows4/index.html</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Open Geospatial Consortium, Inc.</author></authors></contributors><titles><title>Welcome to the GSN Project</title></titles><periodical/><keywords/><notes>        From Duplicate 1 (                           Welcome to the GSN Project                         - Open Geospatial Consortium, Inc. )
                
Homepage on the Web for the OGC GSN.
        
      </notes><research-notes>        From Duplicate 1 (                           Welcome to the GSN Project                         - Open Geospatial Consortium, Inc. )
                
Homepage on the Web for the OGC GSN.
        
      </research-notes><urls><web-urls><url>http://sourceforge.net/apps/trac/gsn/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Op'tLand, Ray</author></authors></contributors><titles><title>Another Endless November: AOL, WoW, and the Corporatization of a Niche Market</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>Talks at the end about how standardization within the MMO market appears to be &quot;occurring not through an explicit process with a governing body, but via emulation and iteration&quot; - eg new MMOs copy/mimic a lot of WoW's features/approach/etc. As WoW is the first exposure many gamers have to MMOs, its style of interaction &amp; whatnot becomes the lingua franca of the field &amp; thus future MMOs to be developed will be predicated on its models, until (if?) another MMO comes along &amp; does what WoW did.</notes><research-notes>Talks at the end about how standardization within the MMO market appears to be &quot;occurring not through an explicit process with a governing body, but via emulation and iteration&quot; - eg new MMOs copy/mimic a lot of WoW's features/approach/etc. As WoW is the first exposure many gamers have to MMOs, its style of interaction &amp; whatnot becomes the lingua franca of the field &amp; thus future MMOs to be developed will be predicated on its models, until (if?) another MMO comes along &amp; does what WoW did.</research-notes><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/660/536</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Osborne, Evan</author><author>Schiller, Shu</author></authors></contributors><titles><title>Order and Creativity in Virtual Worlds</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>More economics really.</notes><research-notes>More economics really.</research-notes><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/649/515</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Otte, Marco</author><author>Hoorn, Johan</author></authors></contributors><titles><title>Standardization in Virtual Worlds: Prevention of False Hope and Undue Fear</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>Didn't really seem to talk about 'Standardization in Virtual Worlds' that much... just sort of mentioned it in the last paragraph of the conclusion so as to qualify for this issue of JVWR...</notes><research-notes>Didn't really seem to talk about 'Standardization in Virtual Worlds' that much... just sort of mentioned it in the last paragraph of the conclusion so as to qualify for this issue of JVWR...</research-notes><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/650/509</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Otte, Marco</author><author>Roosendaal, Loren</author><author>Hoorn, Johan</author></authors></contributors><titles><title>Teleportation of Objects between Virtual Worlds: Use Case: Exer-gaming</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>4</volume><issue>3</issue><keywords/><dates><year>2011</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/6127</url></web-urls></urls><abstract>The Internet and virtual worlds are increasingly become a part of our daily lives. Currently these two are not capable of exchanging information, largely because of the lack of a global accepted standard for information exchange. Interaction between the real world and virtual worlds is mostly limited to classic mouse and keyboard devices, and exchange of information between different virtual worlds is virtually non-existent. We present a Use Case in the Metaverse1 project to increase motivation for continued physical exercising for the elderly by connecting real-world devices to virtual worlds, and allow information exchange through the teleportation of virtual objects from Second Life to our custom virtual biking world created in the Logos3D engine. We show that the principle of exchanging information between real and virtual worlds is simple, but the solution is non-trivial and requires not only a globally accepted standard to facilitate information exchange. From the results of a focus-group study, we show that a virtual environment does have the capability to increase motivation for exercising and that users do respond to a virtual exercise coach.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Paradiso, Joseph A.</author><author>Landay, James A.</author></authors></contributors><titles><title>Cross-Reality Environments</title><secondary-title>Pervasive Computing, IEEE</secondary-title></titles><periodical><full-title>Pervasive Computing, IEEE</full-title></periodical><pages>14-15</pages><volume>8</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.47</electronic-resource-num><notes>        From Duplicate 2 (                           Guest Editors' Introduction: Cross-Reality Environments                         - Paradiso, Joseph A.; Landay, James A. )
                
Joseph Paradiso as guest editor introduces the section of the issue all
about cross reality. Has a few references to the technologies involved,
overviews of some of the articles, etc.
        
Definition of cross reality as 'the ubiquitous mixed reality environment
that comes from the fusion of these two technologies' (referring to
sensor/actuator networks &amp; 3D virtual environments).
        
      </notes><research-notes>        From Duplicate 2 (                           Guest Editors' Introduction: Cross-Reality Environments                         - Paradiso, Joseph A.; Landay, James A. )
                
Joseph Paradiso as guest editor introduces the section of the issue all
about cross reality. Has a few references to the technologies involved,
overviews of some of the articles, etc.
        
Definition of cross reality as 'the ubiquitous mixed reality environment
that comes from the fusion of these two technologies' (referring to
sensor/actuator networks &amp; 3D virtual environments).
        
      </research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165555</url></web-urls></urls><abstract>In this article, we define cross-reality as the union between ubiquitous sensor/actuator networks and shared online virtual worlds-a place where collective human perception meets the machines' view of pervasive computing. We describe how five of the articles in this issue expand on aspects of this theme.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Pardue, Laurel</author><author>Dublon, Gershon</author><author>Jethwani, Anisha</author><author>Prouty, Jeffrey</author><author>Turner, Prouty</author><author>Joliat, Nicholas</author><author>Swartz, Noah</author><author>Paradiso, Joseph</author></authors></contributors><titles><title>DoppelLab</title></titles><periodical/><keywords/><urls><web-urls><url>http://www.media.mit.edu/resenv/doppellab/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Park, Kyungeun</author><author>Yun, Jekuk</author><author>Byun, Changhyun</author><author>Kim, Yanggon</author><author>Chang, Juno</author></authors></contributors><titles><title>XCREAM: collaborative middleware framework for RFID/USN-enabled applications</title><secondary-title>Proceedings of the 12th International Conference on Information Integration and Web-based Applications &amp;#38; Services</secondary-title></titles><periodical><full-title>Proceedings of the 12th International Conference on Information Integration and Web-based Applications &amp;#38; Services</full-title></periodical><pages>692-695</pages><keywords><keyword> collaboration</keyword><keyword> middleware framework</keyword><keyword> USN (universal sensor network)</keyword><keyword> XCREAM (XLogic collaborative RFID/USN-Enabled ada</keyword><keyword>RFID (radio frequency identifcation)</keyword></keywords><dates><year>2010</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-4503-0421-4</isbn><electronic-resource-num>http://doi.acm.org/10.1145/1967486.1967597</electronic-resource-num><urls><web-urls><url>http://doi.acm.org/10.1145/1967486.1967597</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Park, Kyungeun</author><author>Yun, Jekuk</author><author>Byun, Changhyun</author><author>Kim, Yanggon</author><author>Chang, Juno</author></authors></contributors><titles><title>XCREAM</title><secondary-title>Proceedings of the 12th International Conference on Information Integration and Web-based Applications &amp; Services - iiWAS '10</secondary-title></titles><periodical><full-title>Proceedings of the 12th International Conference on Information Integration and Web-based Applications &amp; Services - iiWAS '10</full-title></periodical><pages>692</pages><keywords><keyword>collaboration</keyword><keyword>middleware framework</keyword><keyword>RFID (radio frequency identifcation)</keyword><keyword>USN (universal sensor network)</keyword><keyword>XCREAM (XLogic collaborative RFID/USN-Enabled adap</keyword></keywords><dates><year>2010</year></dates><pub-location>New York, New York, USA</pub-location><publisher>ACM Press</publisher><isbn>9781450304214</isbn><electronic-resource-num>10.1145/1967486.1967597</electronic-resource-num><notes>'XLogic Collaborative RFID/USN-Enabled Adaptive Middleware' aims to all-
-ow collaboration between many RFID/USN applications by providing them
with a flexible interface through a web-based service scheme, XML-based
infrastructure &amp; the XLogic sript language. Paper includes simulation
results including performance analysis.
        
'seamlessly orchestrating framework'
        
XCREAM framework sits between various RFID/USN middlewares &amp; application
services.</notes><research-notes>'XLogic Collaborative RFID/USN-Enabled Adaptive Middleware' aims to all-
-ow collaboration between many RFID/USN applications by providing them
with a flexible interface through a web-based service scheme, XML-based
infrastructure &amp; the XLogic sript language. Paper includes simulation
results including performance analysis.
        
'seamlessly orchestrating framework'
        
XCREAM framework sits between various RFID/USN middlewares &amp; application
services.</research-notes><urls><pdf-urls><url>internal-pdf://Park et al. - 2010 - XCREAM.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1967486.1967597</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Phidgets Inc.</author></authors></contributors><titles><title>Phidgets Inc. - Unique and Easy to Use USB Interfaces</title></titles><periodical/><keywords/><urls><web-urls><url>http://www.phidgets.com/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Remondino, Fabio</author><author>Girardi, Stefano</author><author>Rizzi, Alessandro</author><author>Gonzo, Lorenzo</author></authors></contributors><titles><title>3D modeling of complex and detailed cultural heritage using multi-resolution data</title><secondary-title>Journal on Computing and Cultural Heritage</secondary-title></titles><periodical><full-title>Journal on Computing and Cultural Heritage</full-title></periodical><pages>1-20</pages><volume>2</volume><issue>1</issue><keywords><keyword>3D modeling</keyword><keyword>laser scanning</keyword><keyword>photogrammetry</keyword></keywords><dates><year>2009</year></dates><electronic-resource-num>10.1145/1551676.1551678</electronic-resource-num><notes>Virtual digitization of the Great Inscription of Gortyna, Crete, using several different
digitizing techniques/equipments at different resolutions (more detailed the closer to the
area of interest, etc.).</notes><research-notes>Virtual digitization of the Great Inscription of Gortyna, Crete, using several different
digitizing techniques/equipments at different resolutions (more detailed the closer to the
area of interest, etc.).</research-notes><urls><pdf-urls><url>internal-pdf://Remondino et al. - 2009 - 3D modeling of complex and detailed cultural heritage using multi-resolution data.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1551676.1551678</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Rosendale, Philip</author></authors></contributors><titles><title>Virtual Worlds, Collaboratively Built</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>
        From Duplicate 1 ( 
        
        
          Virtual Worlds, Collaboratively Built
        
        
         - Rosendale, Philip )

        
        
Short retrospective written by one of the Second Life developers about the importance of
standards &amp; openness to the creation &amp; continued development of Second Life, has some good
stuff about the importance that virtual worlds will hopefully represent in the future.

        

      </notes><research-notes>
        From Duplicate 1 ( 
        
        
          Virtual Worlds, Collaboratively Built
        
        
         - Rosendale, Philip )

        
        
Short retrospective written by one of the Second Life developers about the importance of
standards &amp; openness to the creation &amp; continued development of Second Life, has some good
stuff about the importance that virtual worlds will hopefully represent in the future.

        

      </research-notes><urls><web-urls><url>http://journals.tdl.org/jvwr/article/view/670/507</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Roush, Wade</author></authors></contributors><titles><title>Second Earth</title><secondary-title>Technology Review</secondary-title></titles><periodical><full-title>Technology Review</full-title></periodical><keywords/><dates><year>2007</year></dates><notes>Discussion about the concept of combining virtual worlds like Second
Life with global mapping software like Google Earth to form a 'Second
Earth'. Cited by Joshua Lifton in his PhD.</notes><research-notes>Discussion about the concept of combining virtual worlds like Second
Life with global mapping software like Google Earth to form a 'Second
Earth'. Cited by Joshua Lifton in his PhD.</research-notes><urls><web-urls><url>http://www.technologyreview.com/Infotech/18911/</url></web-urls></urls><abstract>The World Wide Web will soon be absorbed into the World Wide Sim: an environment combining elements of Second Life and Google Earth.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Roussou, Maria</author></authors></contributors><titles><title>Virtual Heritage : From the Research Lab to the Broad Public</title><secondary-title>VAST 2000 Euroconference</secondary-title></titles><periodical><full-title>VAST 2000 Euroconference</full-title></periodical><pages>93-100</pages><keywords/><dates><year>2002</year></dates><publisher>BAR International Series 1075, Oxford, Archaeopress</publisher><notes>Very good introduction to the use of virtual reality in the realm of heritage, lots of useful definitions.
        
&quot;The use of immersive VR technology accounts almost a decade of research&quot; (as of publication in 2000)
        
&quot;a tool for the study and presentation of the past&quot;
        
&quot;the visualization of abstract concepts and ideas, spaces that are unreachable or no longer exist, or objects
that must be examined from diverse and unique points of view&quot;
        
&quot;heritage refers to the study of human activity not only through the recovery of remains, as is the case
with archaeology, but also through tradition, art &amp; cultural evidences, narratives, etc.&quot;
        
&quot;To virtualize heritage means to atcualize it digitally, to simulate it using computer graphics technology...&quot;
        
Lots more, etc.</notes><research-notes>Very good introduction to the use of virtual reality in the realm of heritage, lots of useful definitions.
        
&quot;The use of immersive VR technology accounts almost a decade of research&quot; (as of publication in 2000)
        
&quot;a tool for the study and presentation of the past&quot;
        
&quot;the visualization of abstract concepts and ideas, spaces that are unreachable or no longer exist, or objects
that must be examined from diverse and unique points of view&quot;
        
&quot;heritage refers to the study of human activity not only through the recovery of remains, as is the case
with archaeology, but also through tradition, art &amp; cultural evidences, narratives, etc.&quot;
        
&quot;To virtualize heritage means to atcualize it digitally, to simulate it using computer graphics technology...&quot;
        
Lots more, etc.</research-notes><urls><web-urls><url>http://www.makebelieve.gr/mr/research/papers/VAST/VAST_00/mroussou_VAST00_press.pdf</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Roussou, Maria</author><author>Drettakis, George</author><author>Maria Roussou, George Drettakis</author></authors></contributors><titles><title>Photorealism and Non-Photorealism in Virtual Heritage Representation</title></titles><periodical/><keywords/><dates><year>2003</year></dates><notes>        From Duplicate 1 (                           Photorealism and Non-Photorealism in Virtual Heritage Representation                         - Maria Roussou, George Drettakis )
                
Definition of virtual heritage - &quot;Virtual heritage, broadly defined, involves the synthesis, conservation,
reproduction, representation, digital reprocessing, and display of cultural evidence with the use of
advanced imaging technology.&quot;
        
&quot;...virtual heritage has long been concentrated on generating digital reconstructions of historical or
archaeological artefacts and sites with enough fidelity to be truly accurate representations of their real
world counterparts.&quot;
        
Contrasts between photorealistic &amp; non-photorealistic computer graphics and that for some users the realism
isn't the most important factor, but rather how believeable &amp; convincing it is, regardless if the imagery
emulates the physical properties of the real world or not. More 'artistic' means of expression can that do
not necessarily hold true to a photographic view of a site can nonetheless be important to a user's understanding.
        
&quot;In virtual heritage representation, architectural walkthroughs and picture-perfect simulations of objects
have defined a practice where photorealism is considered as perhaps the most important measure of a
successful representation.&quot;
        
But...
        
&quot;...the emphasis on achieving a high degree of realism runs the risk of limiting VR reconstruction to the
creation of historically accurate yet static worlds that leave little flexibility for interpretive and/or
educational use.&quot;
        
So advanced realistic modelling techniques are good for accuracy &amp; authenticity, but non-photorealistic methods
can provide appropriate tools for more flexible uses in virtual heritage applications. This paper tries to
combine both photorealism &amp; interactivity into the same virtual reality framework under the CREATE project.
        
&quot;...heritage is 'as much about the living and evolving place, people, and environment as it is about any
single static monument'&quot;
        
&quot;In the case of an archaeology scholar who intends to restore the ancient monument, the goal is to offer
the possibility to try varied reconstruction hypotheses and choose the most plausible.&quot;
        
      </notes><research-notes>        From Duplicate 1 (                           Photorealism and Non-Photorealism in Virtual Heritage Representation                         - Maria Roussou, George Drettakis )
                
Definition of virtual heritage - &quot;Virtual heritage, broadly defined, involves the synthesis, conservation,
reproduction, representation, digital reprocessing, and display of cultural evidence with the use of
advanced imaging technology.&quot;
        
&quot;...virtual heritage has long been concentrated on generating digital reconstructions of historical or
archaeological artefacts and sites with enough fidelity to be truly accurate representations of their real
world counterparts.&quot;
        
Contrasts between photorealistic &amp; non-photorealistic computer graphics and that for some users the realism
isn't the most important factor, but rather how believeable &amp; convincing it is, regardless if the imagery
emulates the physical properties of the real world or not. More 'artistic' means of expression can that do
not necessarily hold true to a photographic view of a site can nonetheless be important to a user's understanding.
        
&quot;In virtual heritage representation, architectural walkthroughs and picture-perfect simulations of objects
have defined a practice where photorealism is considered as perhaps the most important measure of a
successful representation.&quot;
        
But...
        
&quot;...the emphasis on achieving a high degree of realism runs the risk of limiting VR reconstruction to the
creation of historically accurate yet static worlds that leave little flexibility for interpretive and/or
educational use.&quot;
        
So advanced realistic modelling techniques are good for accuracy &amp; authenticity, but non-photorealistic methods
can provide appropriate tools for more flexible uses in virtual heritage applications. This paper tries to
combine both photorealism &amp; interactivity into the same virtual reality framework under the CREATE project.
        
&quot;...heritage is 'as much about the living and evolving place, people, and environment as it is about any
single static monument'&quot;
        
&quot;In the case of an archaeology scholar who intends to restore the ancient monument, the goal is to offer
the possibility to try varied reconstruction hypotheses and choose the most plausible.&quot;
        
      </research-notes><urls><web-urls><url>http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.9.8705</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Ruffaldi, Emanuele</author><author>Evangelista, Chiara</author><author>Neri, Veronica</author><author>Carrozzino, Marcello</author><author>Bergamasco, Massimo</author></authors></contributors><titles><title>Design of information landscapes for cultural heritage content</title><secondary-title>Proceedings of the 3rd international conference on Digital Interactive Media in Entertainment and Arts - DIMEA '08</secondary-title></titles><periodical><full-title>Proceedings of the 3rd international conference on Digital Interactive Media in Entertainment and Arts - DIMEA '08</full-title></periodical><pages>113</pages><keywords><keyword>cultural heritage</keyword><keyword>virtual reality</keyword><keyword>visualization</keyword></keywords><dates><year>2008</year></dates><pub-location>New York, New York, USA</pub-location><publisher>ACM Press</publisher><isbn>9781605582481</isbn><electronic-resource-num>10.1145/1413634.1413659</electronic-resource-num><notes>Presentation of a virtual environment as something available for both desktop &amp; immersive
visualisations. Construction of such 'information landscapes' requires preliminary design
effort by some developer.
        
In the related work section, mentions large scale (city scale) virtual reproductions &amp;
several examples of 3D virtual cultural heritage using various technologies (some even
allowing haptic interfaces) finally mentioning the existence of many virtual cultural
heritage things in Second Life ('applications of real-time 3D graphics... ...which need
dedicated clients').
        
Explains that virtual reality does not anchor to physical reality - 3D environments can
be entirely synthetic, can model a real world location or a museum that doesn't exist in
the real world at all.</notes><research-notes>Presentation of a virtual environment as something available for both desktop &amp; immersive
visualisations. Construction of such 'information landscapes' requires preliminary design
effort by some developer.
        
In the related work section, mentions large scale (city scale) virtual reproductions &amp;
several examples of 3D virtual cultural heritage using various technologies (some even
allowing haptic interfaces) finally mentioning the existence of many virtual cultural
heritage things in Second Life ('applications of real-time 3D graphics... ...which need
dedicated clients').
        
Explains that virtual reality does not anchor to physical reality - 3D environments can
be entirely synthetic, can model a real world location or a museum that doesn't exist in
the real world at all.</research-notes><urls><pdf-urls><url>internal-pdf://Ruffaldi et al. - 2008 - Design of information landscapes for cultural heritage content.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1413634.1413659</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Saiman, Arminas</author></authors></contributors><titles><title>Barriers to Efficient Virtual Business Transactions</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/661/520</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Salmasi, Anna</author><author>Gillam, Lee</author></authors></contributors><titles><title>Machine Ethics for Gambling in the Metaverse: An &quot;EthiCasino&quot;</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>Not really related to cross reality/standards, but has an interesting history of what led to gambling/banking being banned in Seond Life - issues with different laws/jurisdictions depending upon the country of the user/server, what happens if they make the account in one country &amp; then move to another, what if they use a proxy, etc., etc., etc.

        
Standards for the exchange of media/control information between virtual worlds &amp; between virtual worlds &amp; the real world may have to (may already have) take account of these sort of things - the standards can't allow users to do something that is illegal in one country without sufficient measures to prevent it in this country, whatever.</notes><research-notes>Not really related to cross reality/standards, but has an interesting history of what led to gambling/banking being banned in Seond Life - issues with different laws/jurisdictions depending upon the country of the user/server, what happens if they make the account in one country &amp; then move to another, what if they use a proxy, etc., etc., etc.

        
Standards for the exchange of media/control information between virtual worlds &amp; between virtual worlds &amp; the real world may have to (may already have) take account of these sort of things - the standards can't allow users to do something that is illegal in one country without sufficient measures to prevent it in this country, whatever.</research-notes><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/653/513</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Seo, Byung-Kuk</author><author>Kim, Kangsoo</author><author>Park, Jungsik</author><author>Park, Jong-Il</author></authors></contributors><titles><title>A tracking framework for augmented reality tours on cultural heritage sites</title><secondary-title>Proceedings of the 9th ACM SIGGRAPH Conference on Virtual-Reality Continuum and its Applications in Industry - VRCAI '10</secondary-title></titles><periodical><full-title>Proceedings of the 9th ACM SIGGRAPH Conference on Virtual-Reality Continuum and its Applications in Industry - VRCAI '10</full-title></periodical><pages>169</pages><keywords><keyword>augmented reality</keyword><keyword>camera tracking</keyword><keyword>multimedia tour guides</keyword></keywords><dates><year>2010</year></dates><pub-location>New York, New York, USA</pub-location><publisher>ACM Press</publisher><isbn>9781450304597</isbn><electronic-resource-num>10.1145/1900179.1900215</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Seo et al. - 2010 - A tracking framework for augmented reality tours on cultural heritage sites.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1900179.1900215</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Sivan, Yesha</author></authors></contributors><titles><title>Real Virtual Worlds SOS (State of Standards) Q3-2008</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>1</volume><issue>2</issue><keywords/><dates><year>2008</year></dates><notes>Interesting bit about Vuzix iWear VR920 3D goggles which, through a special driver for Second Life, allowed you to view a virtual world simply by turning your head (but of course didn't work for any other virtual world &amp; in fact only a specific version of Second Life) - but shows that controlling the gaze of the avatar/camera from a real-time external data source is possible through modification of the VW server (eg a region module in OpenSim).</notes><research-notes>Interesting bit about Vuzix iWear VR920 3D goggles which, through a special driver for Second Life, allowed you to view a virtual world simply by turning your head (but of course didn't work for any other virtual world &amp; in fact only a specific version of Second Life) - but shows that controlling the gaze of the avatar/camera from a real-time external data source is possible through modification of the VW server (eg a region module in OpenSim).</research-notes><urls><web-urls><url>http://journals.tdl.org/jvwr/article/view/359</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Sivan, Yesha</author></authors></contributors><titles><title>Overview: State of Virtual Worlds Standards in 2009</title><secondary-title>Journal of Virtual Worlds Research2</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research2</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><notes>
        From Duplicate 1 ( 
        
        
          Overview: State of Virtual Worlds Standards in 2009
        
        
         - Sivan, Yesha )

        
        
Mainly just an overview/introduction to the issue, but has several useful definitions of concepts including virtual worlds themselves.

        

      </notes><research-notes>
        From Duplicate 1 ( 
        
        
          Overview: State of Virtual Worlds Standards in 2009
        
        
         - Sivan, Yesha )

        
        
Mainly just an overview/introduction to the issue, but has several useful definitions of concepts including virtual worlds themselves.

        

      </research-notes><urls><web-urls><url>http://journals.tdl.org/jvwr/article/view/671/539</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Sivan, Yesha</author></authors></contributors><titles><title>Managing Editor’s Corner: Celebrating Four Years and Planning for the Next</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>4</volume><issue>3</issue><keywords/><dates><year>2011</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/6140</url></web-urls></urls><abstract>With this issue JVWR celebrates its fourth year. During these years, we have matured to be the prime source of research in our emerging domain. Earlier this month (Dec. 2011), we celebrated, for the first time, by hosting a JVWR workshop at the International Conference on Information Systems (ICIS 2011 Shanghai, China. This issue takes an historical perspective. In many ways, this issue is a direct decedent of Volume 2, Number 3 - Technology, Economy and Standards in Virtual Worlds. The latter has drawn a vision, this one reports on the outcomes. On this note of moving from vision to reality, I wanted to wish us all happy new 2012.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Song, Eugene</author><author>Lee, Kang</author></authors></contributors><titles><title>Understanding IEEE 1451-Networked smart transducer interface standard - What is a smart transducer?</title><secondary-title>IEEE Instrumentation &amp; Measurement Magazine</secondary-title></titles><periodical><full-title>IEEE Instrumentation &amp; Measurement Magazine</full-title></periodical><pages>11-17</pages><volume>11</volume><issue>2</issue><keywords/><dates><year>2008</year></dates><electronic-resource-num>10.1109/MIM.2008.4483728</electronic-resource-num><notes>IEEE Instrumentation &amp; Measurement Magazine article, very good explanat-
-ion of IEEE 1451, TIM &amp; NCAP, definitions of transducer &amp; smart transd-
-ucer, TEDS, integration with bluetooth/zigbee, etc. Very nice article!
        
Definition of 'transducer' &amp; 'smart transducer' (latter is a reference
to elmenreich.</notes><research-notes>IEEE Instrumentation &amp; Measurement Magazine article, very good explanat-
-ion of IEEE 1451, TIM &amp; NCAP, definitions of transducer &amp; smart transd-
-ucer, TEDS, integration with bluetooth/zigbee, etc. Very nice article!
        
Definition of 'transducer' &amp; 'smart transducer' (latter is a reference
to elmenreich.</research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4483728</url></web-urls></urls><abstract>This article introduces the IEEE 1451 standard for networked smart transducers. It discusses the concepts of smart transducers, IEEE 1451 smart transducers, the architecture of the IEEE 1451 family of standards, application of IEEE 1451, and example implementations of the IEEE 1451 standards. In conclusion, the IEEE 1451 suite of standards provides a set of standard interfaces for networked smart transducers, helping to achieve sensor plug and play and interoperability for industry and government.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Sundstedt, Veronica</author><author>Chalmers, Alan</author><author>Martinez, Philippe</author></authors></contributors><titles><title>High fidelity reconstruction of the ancient Egyptian temple of Kalabsha</title><secondary-title>Proceedings of the 3rd international conference on Computer graphics, virtual reality, visualisation and interaction in Africa - AFRIGRAPH '04</secondary-title></titles><periodical><full-title>Proceedings of the 3rd international conference on Computer graphics, virtual reality, visualisation and interaction in Africa - AFRIGRAPH '04</full-title></periodical><pages>107</pages><keywords><keyword>ancient Egypt</keyword><keyword>high fidelity graphics</keyword><keyword>virtual archaeology</keyword></keywords><dates><year>2004</year></dates><pub-location>New York, New York, USA</pub-location><publisher>ACM Press</publisher><isbn>1581138636</isbn><electronic-resource-num>10.1145/1029949.1029970</electronic-resource-num><notes>Talks about the importance of accuracy to archaeology &amp; the practical methodology that should be adopted to
create a truly high fidelity reconstruction of an archaeological site, paying particular interest to the
accuracy of the lighting (measuring emission spectra of different oils burning &amp; everything!). Spurred by the
fact that &quot;there are very few high fidelity reconstructions that attempt to authentically represent how a
site may have been perceived in the past. Crucial to this accurate perception is the need to correctly
model the ancient lighting.&quot;
        
Most self-defined virtual worlds (eg Second Life, OpenSim, etc.) don't have complex enough rendering/lighitng
engines for this (except Avatar Reality, based on some version of CryEngine).
        
Used Maya in combination with Radiance, a suite of tools for lighting simulation. Allows archaeologists to
determine how light would have fallen on different parts of structures in their original (non-ruined) conditions
&amp; in their original locations (the Kalabsha was moved) to make new discoveries about the role of light in
these structures.</notes><research-notes>Talks about the importance of accuracy to archaeology &amp; the practical methodology that should be adopted to
create a truly high fidelity reconstruction of an archaeological site, paying particular interest to the
accuracy of the lighting (measuring emission spectra of different oils burning &amp; everything!). Spurred by the
fact that &quot;there are very few high fidelity reconstructions that attempt to authentically represent how a
site may have been perceived in the past. Crucial to this accurate perception is the need to correctly
model the ancient lighting.&quot;
        
Most self-defined virtual worlds (eg Second Life, OpenSim, etc.) don't have complex enough rendering/lighitng
engines for this (except Avatar Reality, based on some version of CryEngine).
        
Used Maya in combination with Radiance, a suite of tools for lighting simulation. Allows archaeologists to
determine how light would have fallen on different parts of structures in their original (non-ruined) conditions
&amp; in their original locations (the Kalabsha was moved) to make new discoveries about the role of light in
these structures.</research-notes><urls><pdf-urls><url>internal-pdf://Sundstedt, Chalmers, Martinez - 2004 - High fidelity reconstruction of the ancient Egyptian temple of Kalabsha.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=1029949.1029970</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Tamura, H</author><author>Yamamoto, H</author><author>Katayama, A</author></authors></contributors><titles><title>Mixed reality: future dreams seen at the border between real and virtual worlds</title><secondary-title>IEEE Computer Graphics and Applications</secondary-title></titles><periodical><full-title>IEEE Computer Graphics and Applications</full-title></periodical><pages>64-70</pages><volume>21</volume><issue>6</issue><keywords/><dates><year>2001</year></dates><electronic-resource-num>10.1109/38.963462</electronic-resource-num><notes>IEEE Computer Graphics and Applications magazine article.
        
Agrees with Paul Milgram's definition of mixed reaity as encompassing
augmented reality &amp; augmented virtuality. Describes some of the research
conducted at the Mixed Reality Systems Laboratory funded by Canon &amp; the
Japanese government from 1997 - 2001. Results were presented in conjunc-
-tion with IEEE Virtual Reality 2001 &amp; the Second International Symposi-
-um on Mixed Reality (ISMR). Led to many research projects in image
rendering in VR space, visualization of large spaces, see-through HMD.</notes><research-notes>IEEE Computer Graphics and Applications magazine article.
        
Agrees with Paul Milgram's definition of mixed reaity as encompassing
augmented reality &amp; augmented virtuality. Describes some of the research
conducted at the Mixed Reality Systems Laboratory funded by Canon &amp; the
Japanese government from 1997 - 2001. Results were presented in conjunc-
-tion with IEEE Virtual Reality 2001 &amp; the Second International Symposi-
-um on Mixed Reality (ISMR). Led to many research projects in image
rendering in VR space, visualization of large spaces, see-through HMD.</research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=963462</url></web-urls></urls><abstract>Mixed reality (MR) is a kind of virtual reality (VR), but a broader concept than augmented reality (AR), which augments the real world with synthetic electronic data. On the opposite side, augmented virtuality (AV) enhances or augments virtual environment with data from real world. MR covers a continuum from AR to AV.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Technology, United States Institute for Theatre</author></authors></contributors><titles><title>DMX512</title></titles><periodical/><keywords/><urls><web-urls><url>http://www.usitt.org/Resources/Standards2/DMX512/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>The Mendeley Support Team</author></authors></contributors><titles><title>Getting Started with Mendeley</title><secondary-title>Mendeley Desktop</secondary-title></titles><periodical><full-title>Mendeley Desktop</full-title></periodical><pages>1-16</pages><keywords><keyword>how-to</keyword><keyword>Mendeley</keyword><keyword>user manual</keyword></keywords><dates><year>2011</year></dates><pub-location>London</pub-location><publisher>Mendeley Ltd.</publisher><urls><pdf-urls><url>internal-pdf://The Mendeley Support Team - 2011 - Getting Started with Mendeley.pdf</url></pdf-urls><web-urls><url>http://www.mendeley.com</url></web-urls></urls><abstract>A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Thomas, Bruce H.</author><author>Piekarski, Wayne</author></authors></contributors><titles><title>Through-Walls Collaboration</title><secondary-title>Pervasive Computing, IEEE</secondary-title></titles><periodical><full-title>Pervasive Computing, IEEE</full-title></periodical><pages>42-49</pages><volume>8</volume><issue>3</issue><keywords><keyword>augmented reality</keyword><keyword>input devices</keyword><keyword>mobile AR X-ray vi</keyword></keywords><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.59</electronic-resource-num><notes>        From Duplicate 1 (                           Through-Walls Collaboration                         - Piekarski, Wayne; Thomas, Bruce H. )
                
An example more of augmented reality rather than cross reality, but
interesting nonetheless. Again, some of the wearable technologies
featured could be useful for a wearable virtual world client/interface.
        
      </notes><research-notes>        From Duplicate 1 (                           Through-Walls Collaboration                         - Piekarski, Wayne; Thomas, Bruce H. )
                
An example more of augmented reality rather than cross reality, but
interesting nonetheless. Again, some of the wearable technologies
featured could be useful for a wearable virtual world client/interface.
        
      </research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165559</url></web-urls></urls><abstract>Looks at how through-walls collaboration lets users in the field work in real time with users indoors who have access to reference materials, a global picture, and advanced technology. The concept leverages ubiquitous workspaces, augmented reality, and wearable computers.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>Timmerer, Christian</author></authors></contributors><titles><title>Representation of Sensory Effects: Call for Proposals</title></titles><periodical/><keywords/><dates><year>2008</year></dates><urls><web-urls><url>http://multimediacommunication.blogspot.com/2008/05/representation-of-sensory-effects-call.html</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Timmerer, Christian</author><author>Gelissen, Jean</author><author>Waltl, Markus</author><author>Hellwagner, Hermann</author></authors></contributors><titles><title>Interfacing with Virtual Worlds</title><secondary-title>Proceedings of the 2009 NEM Summit</secondary-title></titles><periodical><full-title>Proceedings of the 2009 NEM Summit</full-title></periodical><pages>28-30</pages><keywords><keyword>interoperability</keyword><keyword>mpeg v</keyword><keyword>virtual world</keyword></keywords><dates><year>2009</year></dates><notes>Provides an overview of MPEG-V &amp; its intended standardization areas. Id-
-entifies the requirement for a standardized framework to allow existin-
-g &amp; emerging metaverses to be bridged.</notes><research-notes>Provides an overview of MPEG-V &amp; its intended standardization areas. Id-
-entifies the requirement for a standardized framework to allow existin-
-g &amp; emerging metaverses to be bridged.</research-notes><urls><pdf-urls><url>internal-pdf://Timmerer et al. - 2009 - Interfacing with Virtual Worlds.pdf</url></pdf-urls><web-urls><url>http://www-itec.uni-klu.ac.at/~timse/research/publications/NEM_MPEG-V_v.4.0.pdf</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>TinyOS Alliance</author></authors></contributors><titles><title>TinyOS Home Page</title></titles><periodical/><keywords/><urls><web-urls><url>http://www.tinyos.net/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>UgoTrade</author></authors></contributors><titles><title>EOLUS Makes Leap To 3D Internet On Second Life</title></titles><periodical/><issue>2</issue><keywords/><dates><year>2007</year></dates><notes>        From Duplicate 1 (                           EOLUS Makes Leap To 3D Internet On Second Life                         - UgoTrade )
                
Background/history of the EOLUS One cross-reality real-estate mgmt project. Mediated between various different building
monitoring &amp; automation platforms, represented in Second Life &amp; had a
measurable beneficial effect on th energy usage of the buildings.
        
      </notes><research-notes>        From Duplicate 1 (                           EOLUS Makes Leap To 3D Internet On Second Life                         - UgoTrade )
                
Background/history of the EOLUS One cross-reality real-estate mgmt project. Mediated between various different building
monitoring &amp; automation platforms, represented in Second Life &amp; had a
measurable beneficial effect on th energy usage of the buildings.
        
      </research-notes><urls><web-urls><url>http://www.ugotrade.com/2007/07/02/eolus-makes-leap-to-3d-internet-on-second-life/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><contributors><authors><author>University of St Andrews Computer Science blog</author><author>of St Andrews, School of Computer Science Blog</author></authors></contributors><titles><title>Virtual reconstruction of the Acropolis Basilica</title></titles><periodical/><issue>7</issue><keywords/><dates><year>2011</year></dates><urls><web-urls><url>http://blogs.cs.st-andrews.ac.uk/csblog/2011/09/07/virtual-reconstruction-of-the-acropolis-basilica/</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>van Broeck, S</author><author>van den Broeck, M</author><author>Lou, Zhe</author></authors></contributors><titles><title>Content Level Gateway for Online Virtual Worlds</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/651/532</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>van der Land, Sarah</author><author>Schouten, Alexandeer</author><author>van den Hooff, Bart</author><author>Feldberg, Frans</author></authors></contributors><titles><title>Modeling the Metaverse: A Theoretical Model of Effective Team Collaboration in 3D Virtual Environments</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>4</volume><issue>3</issue><keywords/><dates><year>2011</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/6126</url></web-urls></urls><abstract>In this paper, a theoretical model of effective team collaboration in 3D virtual environments is presented. The aim of this model is to enhance our understanding of the capabilities exerting influence on effective 3D virtual team collaboration. The model identifies a number of specific capabilities of 3D virtual worlds that can contribute to this team effectiveness. Compared to &quot;traditional&quot; computer-mediated collaboration technologies, 3D virtual environments support team collaboration primarily through (a) the shared virtual environment, and (b) avatar-based interaction. Through the shared virtual environment, users experience higher levels of presence (a feeling of actually &quot;being there&quot;), realism and interactivity. These capabilities increase the users' level of information processing. Avatar-based interaction induces greater feelings of social presence (being with others) and control over self-presentation (how one wants to be perceived by others), thus increasing the level of communication support in the 3D environment. Through greater levels of information and communication support, a higher level of shared understanding is reached, which in turn positively influences team performance. Our paper concludes by presenting several propositions which allow further empirical testing, implications for research and practice, and suggestions for future research. The insights obtained from this paper can help developers of these virtual worlds to design standards for the capabilities that influence effective team collaboration in 3D virtual environments.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Verdot, Vincent</author><author>Saidi, Adel</author></authors></contributors><titles><title>Virtual Hybrid Communications – A Telecom Infrastructure for the Metaverse</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>4</volume><issue>3</issue><keywords/><dates><year>2011</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/6128</url></web-urls></urls><abstract>More and more people dive into Virtual Worlds, experiencing the reality of parallel universes in almost every sector. Moreover, these virtual environments actually generate &quot;real money&quot; directly but also indirectly by selling virtual goods. Yet the current landscape consists in a huge number of siloed Virtual Worlds. We believe that addressing this lack of interoperability could greatly improve the user experience, ease the deployment of new worlds and open up market opportunities. Bell Labs' Applications domain is contributing with Virtual Hybrid Communications, a mature Web technology based on communication hyperlinks that enables the bridging of real and virtual worlds. This technology allows people to remain connected to legacy telecom infrastructures wherever they are (in real or virtual) and to safely expose their communication means without disclosing any personal detail (name, phone number, etc). Thanks to open and standard API, it will also allow virtual service providers and Telecom operators to provide efficient communication solutions and innovative services.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Vlahakis, Vassilios</author><author>Ioannidis, Nikos</author><author>Karigiannis, John</author><author>Tsotros, Manolis</author><author>Gounaris, Michael</author><author>Almeida, Luis</author><author>Stricker, Didier</author><author>Gleue, Tim</author><author>Christou, Ioannis T.</author><author>Carlucci, Renzo</author></authors></contributors><titles><title>Archeoguide: first results of an augmented reality, mobile computing system in cultural heritage sites</title><secondary-title>Proceedings of the 2001 conference on Virtual reality, archeology, and cultural heritage</secondary-title></titles><periodical><full-title>Proceedings of the 2001 conference on Virtual reality, archeology, and cultural heritage</full-title></periodical><pages>131-140</pages><keywords><keyword>augmented reality</keyword><keyword>avatars</keyword><keyword>image rendering</keyword><keyword>mobile computing</keyword><keyword>position tracking</keyword></keywords><dates><year>2001</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>1-58113-447-9</isbn><electronic-resource-num>http://doi.acm.org/10.1145/584993.585015</electronic-resource-num><notes>        From Duplicate 2 (                           Archeoguide                         - Vlahakis, Vassilios; Ioannidis, Nikos; Karigiannis, John; Tsotros, Manolis; Gounaris, Michael; Almeida, Luis; Stricker, Didier; Gleue, Tim; Christou, Ioannis T.; Carlucci, Renzo )
                
A system that provides on-site help &amp; augmented reality reconstructions of ancient ruins. Claims to have
applications ranging from archaeological research to education to multimedia publishing and cultural
tourism.
        
Had a laptop, tablet computer &amp; PDA version of the system, used GPS in some to ascertain location, compass
to ascertain direction &amp; to augment reality accordingly.
        
      </notes><research-notes>        From Duplicate 2 (                           Archeoguide                         - Vlahakis, Vassilios; Ioannidis, Nikos; Karigiannis, John; Tsotros, Manolis; Gounaris, Michael; Almeida, Luis; Stricker, Didier; Gleue, Tim; Christou, Ioannis T.; Carlucci, Renzo )
                
A system that provides on-site help &amp; augmented reality reconstructions of ancient ruins. Claims to have
applications ranging from archaeological research to education to multimedia publishing and cultural
tourism.
        
Had a laptop, tablet computer &amp; PDA version of the system, used GPS in some to ascertain location, compass
to ascertain direction &amp; to augment reality accordingly.
        
      </research-notes><urls><pdf-urls><url>internal-pdf://Vlahakis et al. - 2001 - Archeoguide.pdf</url></pdf-urls><web-urls><url>http://doi.acm.org/10.1145/584993.585015</url><url>http://dl.acm.org/citation.cfm?id=584993.585015</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Walczak, Krzysztof</author><author>White, Martin</author></authors></contributors><titles><title>Cultural heritage applications of virtual reality</title><secondary-title>Proceedings of the eighth international conference on 3D Web technology</secondary-title></titles><periodical><full-title>Proceedings of the eighth international conference on 3D Web technology</full-title></periodical><pages>182-183</pages><keywords/><dates><year>2003</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>1-58113-644-7</isbn><electronic-resource-num>http://doi.acm.org/10.1145/636593.636623</electronic-resource-num><notes>        From Duplicate 1 (                           Cultural heritage applications of virtual reality                         - Walczak, Krzysztof; White, Martin )
                
Summary/introduction to the Web3D 2003 Workshop W3, giving brief summaries of the presentations that took place, which included ARECHOGUIDE.
        
      </notes><research-notes>        From Duplicate 1 (                           Cultural heritage applications of virtual reality                         - Walczak, Krzysztof; White, Martin )
                
Summary/introduction to the Web3D 2003 Workshop W3, giving brief summaries of the presentations that took place, which included ARECHOGUIDE.
        
      </research-notes><urls><pdf-urls><url>internal-pdf://Walczak, White - 2003 - Cultural heritage applications of virtual reality.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=636593.636623</url><url>http://doi.acm.org/10.1145/636593.636623</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Want, Roy</author></authors></contributors><titles><title>Through Tinted Eyeglasses</title><secondary-title>IEEE Pervasive Computing</secondary-title></titles><periodical><full-title>IEEE Pervasive Computing</full-title></periodical><pages>2-4</pages><volume>8</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.58</electronic-resource-num><notes>        From Duplicate 1 (                           Through Tinted Eyeglasses                         - Want, Roy )
                
Introduction to the issue about cross reality, tries to define the
different types of alternate realities (VR, AR, ER, MR) but I believe
his definition of cross reality to be wrong (he describes what I
consider augmented virtuality).
        
Features a 2x2 matrix that shows the relation between the different
alternate realities. Where he has cross reality (top left) I would place
augmented virtuality.
        
      </notes><research-notes>        From Duplicate 1 (                           Through Tinted Eyeglasses                         - Want, Roy )
                
Introduction to the issue about cross reality, tries to define the
different types of alternate realities (VR, AR, ER, MR) but I believe
his definition of cross reality to be wrong (he describes what I
consider augmented virtuality).
        
Features a 2x2 matrix that shows the relation between the different
alternate realities. Where he has cross reality (top left) I would place
augmented virtuality.
        
      </research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165551</url></web-urls></urls><abstract>EIC Roy Want introduces the special issue on cross-reality environments and discusses alternate realities including virtual reality, augmented reality, embodied virtuality, cross-reality, and mixed reality.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Watte, Jon</author></authors></contributors><titles><title>Virtual World Interoperability: Let Use Cases Drive Design</title><secondary-title>Journal of Virtual Worlds Research</secondary-title></titles><periodical><full-title>Journal of Virtual Worlds Research</full-title></periodical><volume>2</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><urls><web-urls><url>https://journals.tdl.org/jvwr/article/view/727/526</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Willmott, J.</author><author>Wright, L. I.</author><author>Arnold, D. B.</author><author>Day, A. M.</author></authors></contributors><titles><title>Rendering of large and complex urban environments for real time heritage reconstructions</title><secondary-title>Proceedings of the 2001 conference on Virtual reality, archeology, and cultural heritage</secondary-title></titles><periodical><full-title>Proceedings of the 2001 conference on Virtual reality, archeology, and cultural heritage</full-title></periodical><pages>111-120</pages><keywords><keyword>avatars</keyword><keyword>culling</keyword><keyword>level of detail</keyword><keyword>occluder shadows</keyword><keyword>openGL</keyword><keyword>ROAM</keyword><keyword>urban environments</keyword><keyword>view frustum culling</keyword></keywords><dates><year>2001</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>1-58113-447-9</isbn><electronic-resource-num>http://doi.acm.org/10.1145/584993.585012</electronic-resource-num><notes>        From Duplicate 1 (                           Rendering of large and complex urban environments for real time heritage reconstructions                         - Willmott, J.; Wright, L. I.; Arnold, D. B.; Day, A. M. )
                
Presents a rendering package with heavy focus on optimizations such as not rendering buildings
that are obscured by buildings in front of them, rendering buildings features like windows into
the wall textures so from a distance it looks as though the windows are there so they only need to
actually be rendered at closer range &amp; the difference is less noticeable.
        
      </notes><research-notes>        From Duplicate 1 (                           Rendering of large and complex urban environments for real time heritage reconstructions                         - Willmott, J.; Wright, L. I.; Arnold, D. B.; Day, A. M. )
                
Presents a rendering package with heavy focus on optimizations such as not rendering buildings
that are obscured by buildings in front of them, rendering buildings features like windows into
the wall textures so from a distance it looks as though the windows are there so they only need to
actually be rendered at closer range &amp; the difference is less noticeable.
        
      </research-notes><urls><pdf-urls><url>internal-pdf://Willmott et al. - 2001 - Rendering of large and complex urban environments for real time heritage reconstructions.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=584993.585012</url><url>http://doi.acm.org/10.1145/584993.585012</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Wojciechowski, Rafal</author><author>Walczak, Krzysztof</author><author>White, Martin</author><author>Cellary, Wojciech</author></authors></contributors><titles><title>Building Virtual and Augmented Reality museum exhibitions</title><secondary-title>Proceedings of the ninth international conference on 3D Web technology - Web3D '04</secondary-title></titles><periodical><full-title>Proceedings of the ninth international conference on 3D Web technology - Web3D '04</full-title></periodical><pages>135</pages><keywords><keyword>augmented reality</keyword><keyword>cultural heritage</keyword><keyword>virtual reality</keyword><keyword>VRML</keyword></keywords><dates><year>2004</year></dates><pub-location>New York, New York, USA</pub-location><publisher>ACM Press</publisher><isbn>1581138458</isbn><electronic-resource-num>10.1145/985040.985060</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Wojciechowski et al. - 2004 - Building Virtual and Augmented Reality museum exhibitions(2).pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=985040.985060</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Conference Proceedings">10</ref-type><contributors><authors><author>Wright, Mark</author><author>Ekeus, Henrik</author><author>Coyne, Richard</author><author>Stewart, James</author><author>Travlou, Penny</author><author>Williams, Robin</author></authors></contributors><titles><title>Augmented duality: overlapping a metaverse with the real world</title><secondary-title>Proceedings of the 2008 International Conference on Advances in Computer Entertainment Technology</secondary-title></titles><periodical><full-title>Proceedings of the 2008 International Conference on Advances in Computer Entertainment Technology</full-title></periodical><pages>263-266</pages><keywords><keyword> augmented reality</keyword><keyword> metaverses</keyword><keyword> mobile phones</keyword><keyword> social networking</keyword><keyword>Second Life</keyword></keywords><dates><year>2008</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-60558-393-8</isbn><electronic-resource-num>http://doi.acm.org/10.1145/1501750.1501812</electronic-resource-num><urls><web-urls><url>http://doi.acm.org/10.1145/1501750.1501812</url></web-urls></urls></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Yankelovich, Nicole</author><author>Slott, Jordan</author><author>Hill, Alex</author><author>Bonner, Matt</author><author>Schiefer, Jacob</author><author>MacIntyre, Blair</author><author>Mugellini, Elena</author><author>Khaled, Omar Abou</author><author>Barras, Frédéric</author><author>Bapst, Jacques</author><author>Back, Maribeth</author><author>Aviles-Lopez, Edgardo</author><author>Garcia-Macias, J. Antonio</author></authors></contributors><titles><title>Building and Employing Cross-Reality</title><secondary-title>IEEE Pervasive Computing</secondary-title></titles><periodical><full-title>IEEE Pervasive Computing</full-title></periodical><pages>55-57</pages><volume>8</volume><issue>3</issue><keywords/><dates><year>2009</year></dates><electronic-resource-num>10.1109/MPRV.2009.41</electronic-resource-num><notes>Briefly discusses 5 current &amp; future applications of cross reality,
however by my definitions none of these 5 are cross reality but just
augmented reality or augmented virtuality. The chocolate factory example
is however interesting - taking real time sensor data from the real
factory &amp; using it to update a virtual simulation of the factory.</notes><research-notes>Briefly discusses 5 current &amp; future applications of cross reality,
however by my definitions none of these 5 are cross reality but just
augmented reality or augmented virtuality. The chocolate factory example
is however interesting - taking real time sensor data from the real
factory &amp; using it to update a virtual simulation of the factory.</research-notes><urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5165561</url></web-urls></urls><abstract>Considers present and future practical applications of cross-reality. From tools to build new 3D virtual worlds to the products of those tools, cross-reality is becoming a staple of our everyday reality. Practical applications of cross-reality include the ability to virtually visit a factory to manage and maintain resources from the comfort of your laptop or desktop PC as well as sentient visors that augment reality with additional information so that users can make more informed choices. Tools and projects considered are:Project Wonderland for multiuser mixed reality;ClearWorlds: mixed- reality presence through virtual clearboards; VICI (Visualization of Immersive and Contextual Information) for ubiquitous augmented reality based on a tangible user interface; Mirror World Chocolate Factory; and sentient visors for browsing the world.</abstract></record><record><database name="endnote.enl" path="endnote.enl">endnote.enl</database><ref-type name="Generic">13</ref-type><titles><title>Open source 3D virtual collaboration toolkit | Open Wonderland</title></titles><periodical/><keywords/><urls><web-urls><url>http://openwonderland.org/</url></web-urls></urls></record></records></xml>
